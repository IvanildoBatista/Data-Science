# Data-science

Nesse repositório constam projetos de *data science* com algoritmos de *machine learning* de aprendizado supervisionado (regressão e classificação) e de aprendizado não supervisionado (*clustering*).

# Projetos

**Projeto 1 - Censo**
Aplicação de modelos de machine learning para classificação de renda de indivíduos com base nas características do censo. Foram utilizados 11 modelos de classificação e, desses modelos, o de melhor desempenho foi o **XGBoost Classifer** que obteve uma **acurácia de 88.77% e um AUC de 0.96**;

**Projeto 2 - Campanha bancária**
Usando o modelo Gradient Boosting para classificar indivíduos de uma campanha bancária, o modelo teve um desempenho superior à baseline (0.498), tendo uma **acurácia média de 81% e AUC de 0.9**;

**Projeto 3 - Diabetes**
Classificando ocorrência de diabetes. Foram usados 8 modelos de classificação (sendo 6 do tipo árvore) e destes modelos o que apresentou melhor desempenho na classificação da doença de diabetes foi a Extra Tree com uma **acurácia de 85%** e uma **AUC de 88%**;

**Projeto 4 - Competição Kaggle (Titanic)**
Usando modelos de machine learning para prever a sobrevivência de passageiros do Titanic. Foram usados 21 modelos de classificação, desses, o de melhor desempenho na competição da Kaggle, foi o **MPL Classifier com 80.32%** de  acurácia;

**Projeto 5 - Planos de Saúde**
Usando regressão linear para prever/calculer preços de planos de saúde a partir das características dos indivíduos

**Projeto 6 - AutoML para classificação**
Aplicação da biblioteca de AutoML TPOT para classificação de preços de celulares. Com o uso dessa biblioteca foi gerado um modelo com uma acurácia de **97.4%**.

**Projeto 7 - Identificação de tumores**
Aplicando uma árvore de decisão para identificação de tipos de tumores. Com a Árvore de Decisão obtemos uma precisão de 97% para a classe de tumores beningnos e de 93% de precisão para a classe de tumores malignos.

**Projeto 8 - Aplicação de Auto Machine Learning em competição Kaggle**
Utilização da biblioteca TPOT para modelagem de problema de regressão da competição Kaggle de previsão do preços de casas. O modelo gerado teve um **RMSE** (raiz quadrada do erro média quadrado) de 0.15742.

**Projeto 9 - *Clusterização* de ações**
Usando dados de indicadores fundamentalistas extraídos do *site Fundamentus* agrupei ações de empresas listadas na Bovespa. Geramos com o modelo *Mini Batch Kmeans* 5 grupos similares.
