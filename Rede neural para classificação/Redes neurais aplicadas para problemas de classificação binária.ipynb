{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HfJehneAPIkt"
   },
   "source": [
    "# Aplicação de redes neurais para de clientes para contratação de empréstimo pessoal\n",
    "\n",
    "## Contexto do problema\n",
    "\n",
    "Este caso é sobre um banco (*Thera Bank*) que possui uma base de clientes crescente. A maioria desses clientes são clientes passivos (depositantes) com depósitos de tamanhos variados. O número de clientes que também são devedores (clientes de ativos) é bastante pequeno, e o banco está interessado em expandir essa base rapidamente para trazer mais negócios de crédito e, no processo, ganhar mais com os juros dos empréstimos. Em particular, a administração deseja explorar maneiras de converter seus clientes passivos em clientes de empréstimos pessoais (enquanto os mantém como depositantes). Uma campanha realizada pelo banco para clientes passivos mostrou uma taxa de conversão saudável de mais de 9% de sucesso. Isso encorajou o departamento de *marketing* de varejo a elaborar campanhas para melhor direcionar o *marketing* para aumentar a taxa de sucesso com um orçamento mínimo.\n",
    "\n",
    "O departamento quer construir um modelo que os ajude a identificar os clientes potenciais com maior probabilidade de adquirir o empréstimo. Isso aumentará a taxa de sucesso e, ao mesmo tempo, reduzirá o custo da campanha.\n",
    "\n",
    "## Modelo\n",
    "\n",
    "Nesse problema será usado um modelo de redes neurais artificiais, que são modelos de *Deep Learning* (uma área do *Machine Learning*) que estão se tornando bastante usados, principalmente em grandes conjuntos de dados, onde possuem um desempenho melhor que algoritmos de *machine learning*. Redes neurais são modelos computacionais que foram inspirados no sistema nervoso central de um ser vivo e utiliza-se de várias camadas de neurônios artificiais (camadas de entradas, camadas ocultas e camadas de saídas) e esses neurônios artificais nada mais são estruturas onde valores são *inputados* multiplicados por um conjunto de pesos, aplicados a uma função que chamamos de *Soma* e aplicados a uma função de ativação.\n",
    "\n",
    "## Dados\n",
    "\n",
    "Os dados que serão usados nesse projeto podem ser encontrados [aqui](https://www.kaggle.com/itsmesunil/bank-loan-modelling?select=Bank_Personal_Loan_Modelling.xlsx).\n",
    "\n",
    "Essa base possui as seguintes *features*:\n",
    "\n",
    "1) *ID*\t - ID do Cliente; \n",
    "\n",
    "2) *Age* -\tIdade do cliente em anos completos;\n",
    "\n",
    "3) *Experience* - Anos de experiência profissional;\n",
    "\n",
    "4) *Income\tAnnual* -  Renda anual do cliente;\n",
    "\n",
    "5) *ZIP Code*\t- CEP do endereço residencial;\n",
    "\n",
    "6) *Family*\t- Tamanho da família do cliente;\n",
    "\n",
    "7) *CCAvg*\t-  gastos médios com cartões de crédito por mês;\n",
    "\n",
    "8) *Education* - Nível de escolaridade. 1: sem Graduação; 2: Graduação; 3: Avançado / Profissional;\n",
    "\n",
    "9) *Mortgage*\t- Valor da hipoteca da casa, se houver;\n",
    "\n",
    "10) *Personal Loan*\t- Este cliente aceitou o empréstimo pessoal oferecido na última campanha?\n",
    "\n",
    "11) *Securities Account*\t-  O cliente possui conta de valores mobiliários no banco?\n",
    "\n",
    "12) *CD Account*\t- O cliente possui uma conta de certificado de depósito (CD) no banco?\n",
    "\n",
    "13) *Online*\t- O cliente usa serviços de internet banking? \n",
    "\n",
    "14) *CreditCard*\t- O cliente usa um cartão de crédito emitido pelo UniversalBank?\n",
    "\n",
    "## Etapas\n",
    "\n",
    "1) Importação das bibliotecas;\n",
    "\n",
    "2) Importação da base de dados;\n",
    "\n",
    "3) Análise dos dados;\n",
    "\n",
    "4) Análise exploratória dos dados;\n",
    "\n",
    "5) Separar dados de treino e teste;\n",
    "\n",
    "6) Criação da rede neural;\n",
    "\n",
    "7) Avaliação da rede neural;\n",
    "\n",
    "8) Testes de outras redes neurais;\n",
    "\n",
    "9) Comparação dos resultados;\n",
    "\n",
    "10) Conclusão.\n",
    "\n",
    "## Importando as bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rUQ32fi4OmRJ"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import keras \n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.metrics import plot_confusion_matrix,classification_report\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zXwDQbTz09uf"
   },
   "source": [
    "## Importando os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72,
     "resources": {
      "http://localhost:8080/nbextensions/google.colab/files.js": {
       "data": "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",
       "headers": [
        [
         "content-type",
         "application/javascript"
        ]
       ],
       "ok": true,
       "status": 200,
       "status_text": ""
      }
     }
    },
    "id": "muVAtL0MO66l",
    "outputId": "bdcc50b5-ce6c-4043-b857-503982ace81c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-0cc7ded5-0632-4e36-971d-615e2b5ba942\" name=\"files[]\" multiple disabled\n",
       "        style=\"border:none\" />\n",
       "     <output id=\"result-0cc7ded5-0632-4e36-971d-615e2b5ba942\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Bank_modelling_marketing.xlsx to Bank_modelling_marketing.xlsx\n"
     ]
    }
   ],
   "source": [
    "from google.colab import files\n",
    "uploaded = files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nZv7lPDHO61z"
   },
   "outputs": [],
   "source": [
    "bank=pd.read_excel('Bank_modelling_marketing.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6LOXwGXN2D4b"
   },
   "source": [
    "## Análise dos dados\n",
    "\n",
    "Visualizando as 10 primeiras linhas da base de dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 356
    },
    "id": "7TwsPdh5O687",
    "outputId": "64988ecc-072a-49f9-976a-88f0efb37e9c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Experience</th>\n",
       "      <th>Income</th>\n",
       "      <th>ZIP Code</th>\n",
       "      <th>Family</th>\n",
       "      <th>CCAvg</th>\n",
       "      <th>Education</th>\n",
       "      <th>Mortgage</th>\n",
       "      <th>Personal Loan</th>\n",
       "      <th>Securities Account</th>\n",
       "      <th>CD Account</th>\n",
       "      <th>Online</th>\n",
       "      <th>CreditCard</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>49</td>\n",
       "      <td>91107</td>\n",
       "      <td>4</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>45</td>\n",
       "      <td>19</td>\n",
       "      <td>34</td>\n",
       "      <td>90089</td>\n",
       "      <td>3</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>39</td>\n",
       "      <td>15</td>\n",
       "      <td>11</td>\n",
       "      <td>94720</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>35</td>\n",
       "      <td>9</td>\n",
       "      <td>100</td>\n",
       "      <td>94112</td>\n",
       "      <td>1</td>\n",
       "      <td>2.7</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>35</td>\n",
       "      <td>8</td>\n",
       "      <td>45</td>\n",
       "      <td>91330</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>37</td>\n",
       "      <td>13</td>\n",
       "      <td>29</td>\n",
       "      <td>92121</td>\n",
       "      <td>4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>2</td>\n",
       "      <td>155</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>53</td>\n",
       "      <td>27</td>\n",
       "      <td>72</td>\n",
       "      <td>91711</td>\n",
       "      <td>2</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>50</td>\n",
       "      <td>24</td>\n",
       "      <td>22</td>\n",
       "      <td>93943</td>\n",
       "      <td>1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>35</td>\n",
       "      <td>10</td>\n",
       "      <td>81</td>\n",
       "      <td>90089</td>\n",
       "      <td>3</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>104</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>34</td>\n",
       "      <td>9</td>\n",
       "      <td>180</td>\n",
       "      <td>93023</td>\n",
       "      <td>1</td>\n",
       "      <td>8.9</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  Age  Experience  ...  CD Account  Online  CreditCard\n",
       "0   1   25           1  ...           0       0           0\n",
       "1   2   45          19  ...           0       0           0\n",
       "2   3   39          15  ...           0       0           0\n",
       "3   4   35           9  ...           0       0           0\n",
       "4   5   35           8  ...           0       0           1\n",
       "5   6   37          13  ...           0       1           0\n",
       "6   7   53          27  ...           0       1           0\n",
       "7   8   50          24  ...           0       0           1\n",
       "8   9   35          10  ...           0       1           0\n",
       "9  10   34           9  ...           0       0           0\n",
       "\n",
       "[10 rows x 14 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bank.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ku7fJX527soG"
   },
   "source": [
    "Visualizando as 10 últimas linhas da base de dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 356
    },
    "id": "M4px4n0XO6-5",
    "outputId": "d8ba7f40-7ae2-4298-eac8-fe0e27335a37"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Experience</th>\n",
       "      <th>Income</th>\n",
       "      <th>ZIP Code</th>\n",
       "      <th>Family</th>\n",
       "      <th>CCAvg</th>\n",
       "      <th>Education</th>\n",
       "      <th>Mortgage</th>\n",
       "      <th>Personal Loan</th>\n",
       "      <th>Securities Account</th>\n",
       "      <th>CD Account</th>\n",
       "      <th>Online</th>\n",
       "      <th>CreditCard</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4990</th>\n",
       "      <td>4991</td>\n",
       "      <td>55</td>\n",
       "      <td>25</td>\n",
       "      <td>58</td>\n",
       "      <td>95023</td>\n",
       "      <td>4</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>219</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4991</th>\n",
       "      <td>4992</td>\n",
       "      <td>51</td>\n",
       "      <td>25</td>\n",
       "      <td>92</td>\n",
       "      <td>91330</td>\n",
       "      <td>1</td>\n",
       "      <td>1.900000</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4992</th>\n",
       "      <td>4993</td>\n",
       "      <td>30</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>90037</td>\n",
       "      <td>4</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4993</th>\n",
       "      <td>4994</td>\n",
       "      <td>45</td>\n",
       "      <td>21</td>\n",
       "      <td>218</td>\n",
       "      <td>91801</td>\n",
       "      <td>2</td>\n",
       "      <td>6.666667</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4994</th>\n",
       "      <td>4995</td>\n",
       "      <td>64</td>\n",
       "      <td>40</td>\n",
       "      <td>75</td>\n",
       "      <td>94588</td>\n",
       "      <td>3</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>4996</td>\n",
       "      <td>29</td>\n",
       "      <td>3</td>\n",
       "      <td>40</td>\n",
       "      <td>92697</td>\n",
       "      <td>1</td>\n",
       "      <td>1.900000</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>4997</td>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>92037</td>\n",
       "      <td>4</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>4998</td>\n",
       "      <td>63</td>\n",
       "      <td>39</td>\n",
       "      <td>24</td>\n",
       "      <td>93023</td>\n",
       "      <td>2</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>4999</td>\n",
       "      <td>65</td>\n",
       "      <td>40</td>\n",
       "      <td>49</td>\n",
       "      <td>90034</td>\n",
       "      <td>3</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>5000</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>83</td>\n",
       "      <td>92612</td>\n",
       "      <td>3</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID  Age  Experience  ...  CD Account  Online  CreditCard\n",
       "4990  4991   55          25  ...           0       0           1\n",
       "4991  4992   51          25  ...           0       0           1\n",
       "4992  4993   30           5  ...           0       0           0\n",
       "4993  4994   45          21  ...           0       1           0\n",
       "4994  4995   64          40  ...           0       1           0\n",
       "4995  4996   29           3  ...           0       1           0\n",
       "4996  4997   30           4  ...           0       1           0\n",
       "4997  4998   63          39  ...           0       0           0\n",
       "4998  4999   65          40  ...           0       1           0\n",
       "4999  5000   28           4  ...           0       1           1\n",
       "\n",
       "[10 rows x 14 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bank.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L7PKLrBM__nC"
   },
   "source": [
    "Informações sobre a base de dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 381
    },
    "id": "4dBBVkzYO7BR",
    "outputId": "8e3c17a8-1876-43fa-dd0d-7b8208387054"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5000 entries, 0 to 4999\n",
      "Data columns (total 14 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   ID                  5000 non-null   int64  \n",
      " 1   Age                 5000 non-null   int64  \n",
      " 2   Experience          5000 non-null   int64  \n",
      " 3   Income              5000 non-null   int64  \n",
      " 4   ZIP Code            5000 non-null   int64  \n",
      " 5   Family              5000 non-null   int64  \n",
      " 6   CCAvg               5000 non-null   float64\n",
      " 7   Education           5000 non-null   int64  \n",
      " 8   Mortgage            5000 non-null   int64  \n",
      " 9   Personal Loan       5000 non-null   int64  \n",
      " 10  Securities Account  5000 non-null   int64  \n",
      " 11  CD Account          5000 non-null   int64  \n",
      " 12  Online              5000 non-null   int64  \n",
      " 13  CreditCard          5000 non-null   int64  \n",
      "dtypes: float64(1), int64(13)\n",
      "memory usage: 547.0 KB\n"
     ]
    }
   ],
   "source": [
    "bank.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D8LKuqdoAbsQ"
   },
   "source": [
    "Não temos valores faltantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 277
    },
    "id": "8lCPN82JO7Ew",
    "outputId": "0a5bd33e-a3aa-4661-90d3-7787f04a40da"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID                    0\n",
       "Age                   0\n",
       "Experience            0\n",
       "Income                0\n",
       "ZIP Code              0\n",
       "Family                0\n",
       "CCAvg                 0\n",
       "Education             0\n",
       "Mortgage              0\n",
       "Personal Loan         0\n",
       "Securities Account    0\n",
       "CD Account            0\n",
       "Online                0\n",
       "CreditCard            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bank.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-tqw_XcOAoKa"
   },
   "source": [
    "Nossa base de dados possui 5000 linhas e 14 colunas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "ctq73F62O7T1",
    "outputId": "61ab9876-55c4-4fe8-890f-b312f64e44a6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 14)"
      ]
     },
     "execution_count": 121,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bank.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ub88wQgZVigg"
   },
   "source": [
    "Tabela estatística da base de dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 294
    },
    "id": "igU2QMdtViur",
    "outputId": "4c5a02db-c30a-436b-9675-0f806de868be"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Experience</th>\n",
       "      <th>Income</th>\n",
       "      <th>ZIP Code</th>\n",
       "      <th>Family</th>\n",
       "      <th>CCAvg</th>\n",
       "      <th>Education</th>\n",
       "      <th>Mortgage</th>\n",
       "      <th>Personal Loan</th>\n",
       "      <th>Securities Account</th>\n",
       "      <th>CD Account</th>\n",
       "      <th>Online</th>\n",
       "      <th>CreditCard</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.00000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2500.500000</td>\n",
       "      <td>45.338400</td>\n",
       "      <td>20.104600</td>\n",
       "      <td>73.774200</td>\n",
       "      <td>93152.503000</td>\n",
       "      <td>2.396400</td>\n",
       "      <td>1.937913</td>\n",
       "      <td>1.881000</td>\n",
       "      <td>56.498800</td>\n",
       "      <td>0.096000</td>\n",
       "      <td>0.104400</td>\n",
       "      <td>0.06040</td>\n",
       "      <td>0.596800</td>\n",
       "      <td>0.294000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1443.520003</td>\n",
       "      <td>11.463166</td>\n",
       "      <td>11.467954</td>\n",
       "      <td>46.033729</td>\n",
       "      <td>2121.852197</td>\n",
       "      <td>1.147663</td>\n",
       "      <td>1.747666</td>\n",
       "      <td>0.839869</td>\n",
       "      <td>101.713802</td>\n",
       "      <td>0.294621</td>\n",
       "      <td>0.305809</td>\n",
       "      <td>0.23825</td>\n",
       "      <td>0.490589</td>\n",
       "      <td>0.455637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>-3.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>9307.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1250.750000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>91911.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2500.500000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>93437.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3750.250000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>98.000000</td>\n",
       "      <td>94608.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>101.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5000.000000</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>224.000000</td>\n",
       "      <td>96651.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>635.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                ID          Age  ...       Online   CreditCard\n",
       "count  5000.000000  5000.000000  ...  5000.000000  5000.000000\n",
       "mean   2500.500000    45.338400  ...     0.596800     0.294000\n",
       "std    1443.520003    11.463166  ...     0.490589     0.455637\n",
       "min       1.000000    23.000000  ...     0.000000     0.000000\n",
       "25%    1250.750000    35.000000  ...     0.000000     0.000000\n",
       "50%    2500.500000    45.000000  ...     1.000000     0.000000\n",
       "75%    3750.250000    55.000000  ...     1.000000     1.000000\n",
       "max    5000.000000    67.000000  ...     1.000000     1.000000\n",
       "\n",
       "[8 rows x 14 columns]"
      ]
     },
     "execution_count": 122,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bank.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sPnPU9g9Mjrt"
   },
   "source": [
    "## Análise exploratória dos dados\n",
    "\n",
    "Na *feature Age*, podemos ver abaixo a distribuição das idades e ver, também, que a idade média de quem aceitou o empréstimo pessoal e quem não aceitou não tem muita diferença."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 329
    },
    "id": "0x1NC03RO7Yf",
    "outputId": "61bb1e96-6535-44e2-e110-33fda8e2bd44"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2160x360 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1,3,figsize=(30,5))\n",
    "bank['Age'].value_counts().plot.bar(ax=ax[2])\n",
    "sns.histplot(bank['Age'],bins=40,ax=ax[0])\n",
    "sns.barplot(x='Personal Loan',y='Age',data=bank,ax=ax[1]);\n",
    "#sns.countplot(x='Age',data=bank, ax=ax[2]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A2x0PnZYR8a7"
   },
   "source": [
    "Podemos ver os valores médios das idades de quem aceitou ou não o empréstimo pessoal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "id": "zutrpPWWR8pP",
    "outputId": "c856b4fb-8ee2-43de-b17c-ca76ff01ea9a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Idade média de quem aceitou o empréstimo pessoal : 45.067\n",
      "\n",
      "Idade média de quem não aceitou o empréstimo pessoal : 45.367\n"
     ]
    }
   ],
   "source": [
    "print('Idade média de quem aceitou o empréstimo pessoal :',round(bank[bank['Personal Loan']==1]['Age'].mean(),3))\n",
    "print('')\n",
    "print('Idade média de quem não aceitou o empréstimo pessoal :',round(bank[bank['Personal Loan']==0]['Age'].mean(),3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9tGXUStVSmPI"
   },
   "source": [
    "Bem semelhante o comportamento da Experiência profissional em anos, mas com aqueles que aceitaram o empréstimo tem anos de experiência um pouco maior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 332
    },
    "id": "gjuMI-ZhO7aA",
    "outputId": "3fb71a57-5f61-4abe-fb7c-27c796b48819"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2160x360 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1,3,figsize=(30,5))\n",
    "bank['Experience'].value_counts().plot.bar(ax=ax[0],color='red')\n",
    "sns.histplot(bank['Experience'],bins=40,ax=ax[1])\n",
    "sns.barplot(x='Personal Loan',y='Experience',data=bank,ax=ax[2]);\n",
    "#sns.countplot(x='Age',data=bank, ax=ax[2]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TmOUcMpWUV0h"
   },
   "source": [
    "Aqui vemos que os clientes que aceitou o empréstimo tem um tempo menor de experiência."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "id": "dqtdkDD3O649",
    "outputId": "8b7fd224-3934-4cc3-c929-fcb35ce23d72"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiência média de quem aceitou o empréstimo pessoal : 19.844\n",
      "\n",
      "Experiência média de quem não aceitou o empréstimo pessoal : 20.132\n"
     ]
    }
   ],
   "source": [
    "print('Experiência média de quem aceitou o empréstimo pessoal :',\n",
    "      round(bank[bank['Personal Loan']==1]['Experience'].mean(),3))\n",
    "print('')\n",
    "print('Experiência média de quem não aceitou o empréstimo pessoal :',\n",
    "      round(bank[bank['Personal Loan']==0]['Experience'].mean(),3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rlJaGEzMYurm"
   },
   "source": [
    "Para a coluna de renda vemos que os dados estão mais distribuídos para valores abaixo de 100. A média da renda de quem contratou o empréstimo é maior do que quem não contratou."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 336
    },
    "id": "mpI-Gz7FO7dX",
    "outputId": "a850a168-74c9-4bd9-a0a1-d02ec4823758"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1,2,figsize=(20,5))\n",
    "sns.histplot(bank['Income'],bins=40,ax=ax[0])\n",
    "sns.barplot(x='Personal Loan',y='Income',data=bank,ax=ax[1]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PK6pmNnEbUEt"
   },
   "source": [
    "Em *Family* a maioria dos clientes são solteiros, pois só há 1 integrante na família."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104
    },
    "id": "DJocM6GeO6zb",
    "outputId": "2e0d0218-6734-4126-b8a7-e18b7bae8acf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    1472\n",
       "2    1296\n",
       "4    1222\n",
       "3    1010\n",
       "Name: Family, dtype: int64"
      ]
     },
     "execution_count": 128,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bank['Family'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JPMeo-mhlOxe"
   },
   "source": [
    "Vamos ver o número de contratantes de empréstimos por tamanho da família graficamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 358
    },
    "id": "NI_EKAbo7Nrn",
    "outputId": "3b81ae66-a019-4af8-92c3-51749c9620e4"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(20,5))\n",
    "sns.countplot(x='Family',hue='Personal Loan', data=bank)\n",
    "plt.title('Família por contratante de empréstimo',size=15)\n",
    "plt.xlabel('Tamanho da Família',size=15);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0U-NuCryT7-8"
   },
   "source": [
    "A famílias com 3 e 4 integrantes foram os que mais contraram o empréstimo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104
    },
    "id": "M0CGc08KT8OH",
    "outputId": "7688b4b1-306c-446e-8960-0b066c55d46f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4    134\n",
       "3    133\n",
       "1    107\n",
       "2    106\n",
       "Name: Family, dtype: int64"
      ]
     },
     "execution_count": 130,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bank[bank['Personal Loan']==1]['Family'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SonWbFNYlNdh"
   },
   "source": [
    "Olhando o gasto médio de cartão de crédito mensal, observa-se que aqueles que contratam o empréstimo possuem uma média de gastos bem maior. A distribuição dos gastos, em sua maioria, se concentram abaixo de $ 2000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 334
    },
    "id": "cW5LvrxP7NxX",
    "outputId": "33e403ac-abb9-49ee-f41b-93bfed273ba8"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1,2,figsize=(20,5))\n",
    "sns.histplot(bank['CCAvg'],bins=40,ax=ax[0])\n",
    "sns.barplot(x='Personal Loan',y='CCAvg',data=bank,ax=ax[1]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YYsoZDm-2UIt"
   },
   "source": [
    "Quem contrata empréstimos tem mais que o dobro do gasto de quem não contrata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "id": "RzztkkxO7N27",
    "outputId": "d01d3d47-d4b3-4637-be5d-d913d7641394"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gasto médio de quem aceitou o empréstimo pessoal : 3.905\n",
      "\n",
      "Gasto médio de quem não aceitou o empréstimo pessoal : 1.729\n"
     ]
    }
   ],
   "source": [
    "print('Gasto médio de quem aceitou o empréstimo pessoal :',round(bank[bank['Personal Loan']==1]['CCAvg'].mean(),3))\n",
    "print('')\n",
    "print('Gasto médio de quem não aceitou o empréstimo pessoal :',round(bank[bank['Personal Loan']==0]['CCAvg'].mean(),3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YW9Lrwug27-8"
   },
   "source": [
    "A maioria dos clientes não possuem graduação e que os clientes com algum tipo de educação que é mais avançada são os que mais contratam o empréstimo pessoal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 334
    },
    "id": "PxVhPXbZ7NzZ",
    "outputId": "81e45cfd-864a-4135-9309-28bf0801b61f"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1,2,figsize=(20,5))\n",
    "sns.countplot(x='Education',data=bank,ax=ax[0])\n",
    "sns.countplot(x='Education',data=bank,ax=ax[1],hue='Personal Loan');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rzd_zMiUWq0f"
   },
   "source": [
    "Os valores das hipotecas das casas dos clientes estão mais distribuídos em valores menores que $ 100.000 (podemos conferir isso observando a média da coluna na tabela estatística gerada anteriormente).\n",
    "\n",
    "Aqueles clientes que mais solicitaram o empréstimo possuem um valor de hipoteca bem maior do que os demais."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 334
    },
    "id": "6uMauabK7N_z",
    "outputId": "f782628f-4601-4dac-8c50-3f6fbb2faf6a"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1,2,figsize=(20,5))\n",
    "sns.histplot(bank['Mortgage'],bins=40,ax=ax[0])\n",
    "sns.barplot(x='Personal Loan',y='Mortgage',data=bank,ax=ax[1]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bz-foP4oYC20"
   },
   "source": [
    "Há mais clientes que não possuem conta de valores mobiliários, porém são que mais contram o empréstimo pessoal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 334
    },
    "id": "Sjn0Ug8y7OHW",
    "outputId": "6c3db390-f3ed-49b5-e432-c9f2794e901a"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1,2,figsize=(20,5))\n",
    "sns.countplot(x='Securities Account',data=bank,ax=ax[0])\n",
    "sns.countplot(x='Securities Account',data=bank,ax=ax[1],hue='Personal Loan');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cJIL0DJKB2Bq"
   },
   "source": [
    "A mesma coisa se observa com clientes que possuem ou não conta com certificado: A maioria não possui esse tipo de conta, mas são justamente esses que mais contratam empréstimos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 334
    },
    "id": "s9O3uI8c7N8C",
    "outputId": "5336c0e4-f96f-46ab-ff3e-e4ef6f24cec5"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1,2,figsize=(20,5))\n",
    "sns.countplot(x='CD Account',data=bank,ax=ax[0])\n",
    "sns.countplot(x='CD Account',data=bank,ax=ax[1],hue='Personal Loan');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VE6Sr9iSDDhy"
   },
   "source": [
    "A maioria dos clientes usam *internet banking* e são esse grupo que mais contratam empréstimos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 334
    },
    "id": "DqfoJVb4DD7B",
    "outputId": "f0933633-9390-434c-d772-962afe48d217"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1,2,figsize=(20,5))\n",
    "sns.countplot(x='Online',data=bank,ax=ax[0])\n",
    "sns.countplot(x='Online',data=bank,ax=ax[1],hue='Personal Loan');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LPRokM94E_VL"
   },
   "source": [
    "A maioria dos clientes não utiliza cartão de crédito, mas é esse grupo que contrata o empréstimo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 334
    },
    "id": "5krdpunI7OOl",
    "outputId": "0f7b98b4-af3c-4e2f-d822-830f89f7f9e5"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1,2,figsize=(20,5))\n",
    "sns.countplot(x='CreditCard',data=bank,ax=ax[0])\n",
    "sns.countplot(x='CreditCard',data=bank,ax=ax[1],hue='Personal Loan');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VMLiVmDyFsPT"
   },
   "source": [
    "Por fim nossa variável alvo *Personal Loan*.\n",
    "\n",
    "A maioria dos clientes não contrata o empréstimo pessoal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 358
    },
    "id": "XfkZ80gu7OTA",
    "outputId": "6b852795-5ab6-410e-ad5d-7b80cf16676b"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(20,5))\n",
    "sns.countplot(x='Personal Loan', data=bank)\n",
    "plt.xlabel('Contratação de empréstimo',size=15)\n",
    "plt.ylabel('')\n",
    "plt.title('Clientes que contrataram ou não o empréstimo pessoal',size=15);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3gfFtfecH8uT"
   },
   "source": [
    "## Separando dados de treino e teste\n",
    "\n",
    "Agora iremos separa uma parte dos dados para treinar a Rede Neural e depois iremos usar uma outra parte para avaliar o modelo com as métricas de avaliação pertinentes. Aqui eu irei excluir a coluna *ID* e *ZIP Code*, pois são colunas que ao meu ver não trazem informações relevantes para o treinamento do modelo.\n",
    "\n",
    "Definindo as colunas com as *features* e a coluna alvo ou *target*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U559vhddNFPq"
   },
   "outputs": [],
   "source": [
    "X=bank[['Age', 'Experience', 'Income', 'Family', 'CCAvg','Education', 'Mortgage','Securities Account','CD Account', 'Online',\n",
    "        'CreditCard']]\n",
    "\n",
    "y=bank['Personal Loan']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kTsXIi5ZNsxk"
   },
   "source": [
    "Dimensão dessas bases de dados: temos a base com as *features* com 11 colunas e a base com a variável *target*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "P3MpJ29uNr1a",
    "outputId": "0a3759cb-844b-433b-9d48-89d17c236ab8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 11) (5000,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape,y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JXvr78dFN1DO"
   },
   "source": [
    "Agora vamos dividir os dados em treino e de teste. Aplicarei uma parte da base com as *features* e uma parte da base com a variável *target* para treinar o modelo; já a outra parte será para avaliar o desempenho do modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "awpyV_1QO7WJ"
   },
   "outputs": [],
   "source": [
    "X_treino, X_teste, y_treino, y_teste = train_test_split(X,y,random_state=42,test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IxYQBjKbOBYa"
   },
   "source": [
    "Dimensões das bases de treino e teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "iquTKp187OZN",
    "outputId": "25962f02-29c5-4475-bcab-a487a377f31f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4000, 11) (1000, 11) (4000,) (1000,)\n"
     ]
    }
   ],
   "source": [
    "print(X_treino.shape, X_teste.shape, y_treino.shape, y_teste.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "15FeKZJN8jFK"
   },
   "source": [
    "Podemos ver, graficamente, que para ambos os *dataset* (treino e teste) as classes se mantém desbalanceadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "AJPGMhYg8jWe",
    "outputId": "21967540-adce-433d-991b-a2e7a1958156"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  FutureWarning\n",
      "/usr/local/lib/python3.6/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABJgAAAE9CAYAAABHvdhKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dfZBmZ1kn4N9NQkDRJQnpzYaZYFIyKxXdJcExxEVdJAoJfkx0kQq7yoApR6uCwuIqwa1aEDdVUipR/KAqmkBiscSISGbdrNkYQKTWhEwkhnxIMcuHmalARhIiHwom3vtHPwOdZD56cubtt3v6uqre6nPu85zz3v3HTD3163POU90dAAAAAHisHjfvBgAAAABY2wRMAAAAAEwiYAIAAABgEgETAAAAAJMImAAAAACYRMAEAAAAwCRHz7uBWTjhhBP6lFNOmXcbAMAM3XLLLX/X3Qvz7oOvMgcDgCPbgeZfR2TAdMopp2THjh3zbgMAmKGq+uS8e+DhzMEA4Mh2oPmXR+QAAAAAmETABAAAAMAkAiYAAAAAJhEwAQAAADCJgAkAAACASQRMAAAAAEwiYAIAAABgEgETAAAAAJMImAAAAACYRMAEAAAAwCQCJgAAAAAmOXreDaxl3/pzV867BVgTbvmVl867BQCOIOZgcHDmX8BKcwcTAAAAAJMImAAAAACYRMAEAAAAwCQCJgAAAAAmmVnAVFVPrKoPVtVfV9UdVfWLo/62qvp4Vd06PqePelXVm6tqZ1XdVlXPWnKtrVX10fHZOqueAQAAADh0s1xF7ktJntfdn6+qxyf5QFX973Hs57r7nY8Yf26STePz7CRvSfLsqjo+yeuSbE7SSW6pqu3dff8MewcAAABgmWZ2B1Mv+vzYffz49AFO2ZLkynHejUmOraqTkrwgyfXdfd8Ila5Pcs6s+gYAAADg0Mz0HUxVdVRV3Zrk3iyGRDeNQxePx+AuqaonjNqGJHcvOX3XqO2vDgAAAMAqMNOAqbsf6u7Tk2xMcmZVfUuS1yZ5RpJvS3J8ktccju+qqm1VtaOqduzZs+dwXBIAAACAZViRVeS6+7NJ3pvknO6+ZzwG96Ukb01y5hi2O8nJS07bOGr7qz/yOy7t7s3dvXlhYWEWvwYAAAAA+zDLVeQWqurYsf01Sb43yd+M9yqlqirJeUluH6dsT/LSsZrcWUke6O57klyX5PlVdVxVHZfk+aMGAAAAwCowy1XkTkpyRVUdlcUg6+ru/pOqek9VLSSpJLcm+akx/tokL0yyM8kXk7w8Sbr7vqr6pSQ3j3Fv6O77Ztg3AAAAAIdgZgFTd9+W5Ix91J+3n/Gd5ML9HLs8yeWHtUEAAAAADosVeQcTAAAAAEcuARMAAAAAkwiYAAAAAJhEwAQAAADAJAImAAAAACYRMAEAAAAwiYAJAAAAgEkETAAAAABMImACAAAAYBIBEwAAAACTCJgAANaJqvrPVXVHVd1eVe+oqidW1alVdVNV7ayqP6iqY8bYJ4z9neP4KfPtHgBYzQRMAADrQFVtSPIzSTZ397ckOSrJ+UnemOSS7n56kvuTXDBOuSDJ/aN+yRgHALBPAiYAgPXj6CRfU1VHJ/naJPckeV6Sd47jVyQ5b2xvGfsZx8+uqlrBXgGANUTABACwDnT37iS/muRvsxgsPZDkliSf7e4Hx7BdSTaM7Q1J7h7nPjjGP+WR162qbVW1o6p27NmzZ7a/BACwagmYAADWgao6Lot3JZ2a5KlJnpTknKnX7e5Lu3tzd29eWFiYejkAYI0SMAEArA/fk+Tj3b2nu/8pybuSPCfJseORuSTZmGT32N6d5OQkGcefnOQzK9syALBWCJgAANaHv01yVlV97XiX0tlJ7kzy3iQvGmO2JrlmbG8f+xnH39PdvYL9AgBriIAJAGAd6O6bsviy7r9K8uEszgMvTfKaJK+uqp1ZfMfSZeOUy5I8ZdRfneSiFW8aAFgzjj74EAAAjgTd/bokr3tE+WNJztzH2H9M8iMr0RcAsPa5gwkAAACASQRMAAAAAEwiYAIAAABgEgETAAAAAJMImAAAAACYRMAEAAAAwCQCJgAAAAAmETABAAAAMMnMAqaqemJVfbCq/rqq7qiqXxz1U6vqpqraWVV/UFXHjPoTxv7OcfyUJdd67ah/pKpeMKueAQAAADh0s7yD6UtJntfdz0xyepJzquqsJG9Mckl3Pz3J/UkuGOMvSHL/qF8yxqWqTktyfpJvTnJOkt+pqqNm2DcAAAAAh2BmAVMv+vzYffz4dJLnJXnnqF+R5LyxvWXsZxw/u6pq1K/q7i9198eT7Exy5qz6BgAAAODQzPQdTFV1VFXdmuTeJNcn+X9JPtvdD44hu5JsGNsbktydJOP4A0mesrS+j3MAAAAAmLOZBkzd/VB3n55kYxbvOnrGrL6rqrZV1Y6q2rFnz55ZfQ0AAAAAj7Aiq8h192eTvDfJtyc5tqqOHoc2Jtk9tncnOTlJxvEnJ/nM0vo+zln6HZd29+bu3rywsDCT3wMAAACAR5vlKnILVXXs2P6aJN+b5K4sBk0vGsO2JrlmbG8f+xnH39PdPernj1XmTk2yKckHZ9U3AAAAAIfm6IMPecxOSnLFWPHtcUmu7u4/qao7k1xVVf89yYeSXDbGX5bk96tqZ5L7srhyXLr7jqq6OsmdSR5McmF3PzTDvgEAAAA4BDMLmLr7tiRn7KP+sexjFbju/sckP7Kfa12c5OLD3SMAAAAA063IO5gAAAAAOHIJmAAAAACYRMAEAAAAwCQCJgAAAAAmETABAAAAMImACQAAAIBJBEwAAAAATCJgAgAAAGASARMAAAAAkwiYAAAAAJhEwAQAAADAJAImAAAAACYRMAEAAAAwiYAJAAAAgEkETAAAAABMImACAAAAYBIBEwAAAACTCJgAAAAAmETABAAAAMAkAiYAAAAAJhEwAQAAADCJgAkAAACASQRMAAAAAEwiYAIAAABgEgETAAAAAJMImAAAAACYZGYBU1WdXFXvrao7q+qOqnrlqL++qnZX1a3j88Il57y2qnZW1Ueq6gVL6ueM2s6qumhWPQMAAABw6I6e4bUfTPKz3f1XVfX1SW6pquvHsUu6+1eXDq6q05Kcn+Sbkzw1yZ9V1b8eh387yfcm2ZXk5qra3t13zrB3AAAAAJZpZgFTd9+T5J6x/bmquivJhgOcsiXJVd39pSQfr6qdSc4cx3Z298eSpKquGmMFTAAAAACrwIq8g6mqTklyRpKbRukVVXVbVV1eVceN2oYkdy85bdeo7a8OAAAAwCow84Cpqr4uyR8leVV3/32StyT5xiSnZ/EOp187TN+zrap2VNWOPXv2HI5LAgAAALAMMw2YqurxWQyX3t7d70qS7v50dz/U3f+c5Hfz1cfgdic5ecnpG0dtf/WH6e5Lu3tzd29eWFg4/L8MAMAaV1XHVtU7q+pvququqvr2qjq+qq6vqo+On8eNsVVVbx6LrNxWVc+ad/8AwOo1y1XkKsllSe7q7jctqZ+0ZNgPJbl9bG9Pcn5VPaGqTk2yKckHk9ycZFNVnVpVx2TxReDbZ9U3AMAR7DeS/Gl3PyPJM5PcleSiJDd096YkN4z9JDk3i/OxTUm2ZfEudACAfZrlKnLPSfJjST5cVbeO2i8keUlVnZ6kk3wiyU8mSXffUVVXZ/Hl3Q8mubC7H0qSqnpFkuuSHJXk8u6+Y4Z9AwAccarqyUm+K8nLkqS7v5zky1W1Jclzx7ArkrwvyWuyuKjKld3dSW4cdz+dNBZyAQB4mFmuIveBJLWPQ9ce4JyLk1y8j/q1BzoPAICDOjXJniRvrapnJrklySuTnLgkNPpUkhPH9v4WWhEwAQCPsiKryAEAMHdHJ3lWkrd09xlJvpCvPg6XJBl3K/WhXNRCKwBAImACAFgvdiXZ1d03jf13ZjFw+vTed2SOn/eO4xZaAQCWTcAEALAOdPenktxdVd80Smdn8d2X25NsHbWtSa4Z29uTvHSsJndWkge8fwkA2J9ZvuQbAIDV5aeTvH2szPuxJC/P4h8cr66qC5J8MsmLx9hrk7wwyc4kXxxjAQD2ScAEALBOdPetSTbv49DZ+xjbSS6ceVMAwBHBI3IAAAAATCJgAgAAAGASARMAAAAAkwiYAAAAAJhEwAQAAADAJAImAAAAACYRMAEAAAAwiYAJAAAAgEkETAAAAABMImACAAAAYBIBEwAAAACTCJgAAAAAmETABAAAAMAkAiYAAAAAJhEwAQAAADCJgAkAAACASQRMAAAAAEwiYAIAAABgEgETAAAAAJMImAAAAACYRMAEAAAAwCTLCpiq6obl1AAAmD1zMwBgtTlgwFRVT6yq45OcUFXHVdXx43NKkg0HOffkqnpvVd1ZVXdU1StH/fiqur6qPjp+HjfqVVVvrqqdVXVbVT1rybW2jvEfraqtU39pAIC1aMrcDABglo4+yPGfTPKqJE9NckuSGvW/T/JbBzn3wSQ/291/VVVfn+SWqro+ycuS3NDdv1xVFyW5KMlrkpybZNP4PDvJW5I8e0yiXpdkc5Ie19ne3fcf0m8KALD2TZmbAQDMzAEDpu7+jSS/UVU/3d2/eSgX7u57ktwztj9XVXdl8S9rW5I8dwy7Isn7shgwbUlyZXd3khur6tiqOmmMvb6770uSEVKdk+Qdh9IPAMBaN2VuBgAwSwe7gylJ0t2/WVX/LskpS8/p7iuXc/64bfuMJDclOXGET0nyqSQnju0NSe5ectquUdtfHQBgXZo6NwMAONyWFTBV1e8n+cYktyZ5aJQ7yUEnMVX1dUn+KMmruvvvq+orx7q7q6oPten9fM+2JNuS5GlPe9rhuCQAwKo0ZW4GADALywqYsvj+o9PG42vLVlWPz2K49Pbuftcof7qqTurue8YjcPeO+u4kJy85feOo7c5XH6nbW3/fI7+ruy9NcmmSbN68+bCEVgAAq9RjmpsBAMzKAVeRW+L2JP/qUC5ci7cqXZbkru5+05JD25PsXQlua5JrltRfOlaTOyvJA+NRuuuSPH+slHJckuePGgDAenXIczMAgFla7h1MJyS5s6o+mORLe4vd/YMHOOc5SX4syYer6tZR+4Ukv5zk6qq6IMknk7x4HLs2yQuT7EzyxSQvH99xX1X9UpKbx7g37H3hNwDAOvVY5mYAADOz3IDp9Yd64e7+QL66dO4jnb2P8Z3kwv1c6/Iklx9qDwAAR6jXz7sBAICllruK3J/PuhEAAJbH3AwAWG2Wu4rc57K4MkmSHJPk8Um+0N3/YlaNAQCwb+ZmAMBqs9w7mL5+7/Z4efeWJGfNqikAAPbP3AwAWG2Wu4rcV/Sidyd5wQz6AQDgEJibAQCrwXIfkfvhJbuPS7I5yT/OpCMAAA7I3AwAWG2Wu4rcDyzZfjDJJ7J4KzYAACvP3AwAWFWW+w6ml8+6EQAAlsfcDABYbZb1Dqaq2lhVf1xV947PH1XVxlk3BwDAo5mbAQCrzXJf8v3WJNuTPHV8/ueoAQCw8szNAIBVZbkB00J3v7W7HxyftyVZmGFfAADsn7kZALCqLDdg+kxV/WhVHTU+P5rkM7NsDACA/TI3AwBWleUGTD+e5MVJPpXkniQvSvKyGfUEAMCBmZsBAKvKslaRS/KGJFu7+/4kqarjk/xqFic3AACsLHMzAGBVWe4dTP927wQmSbr7viRnzKYlAAAOwtwMAFhVlhswPa6qjtu7M/5Ktty7nwAAOLzMzQCAVWW5E5FfS/KXVfWHY/9Hklw8m5YAADgIczMAYFVZVsDU3VdW1Y4kzxulH+7uO2fXFgAA+2NuBgCsNsu+lXpMWkxcAABWAXMzAGA1We47mAAAOAJU1VFV9aGq+pOxf2pV3VRVO6vqD6rqmFF/wtjfOY6fMs++AYDVTcAEALC+vDLJXUv235jkku5+epL7k1ww6hckuX/ULxnjAAD2ScAEALBOVNXGJN+X5PfGfmXxPU7vHEOuSHLe2N4y9jOOnz3GAwA8ioAJAGD9+PUkP5/kn8f+U5J8trsfHPu7kmwY2xuS3J0k4/gDYzwAwKMImAAA1oGq+v4k93b3LYf5utuqakdV7dizZ8/hvDQAsIYImAAA1ofnJPnBqvpEkquy+GjcbyQ5tqr2riy8Mcnusb07yclJMo4/OclnHnnR7r60uzd39+aFhYXZ/gYAwKolYAIAWAe6+7XdvbG7T0lyfpL3dPd/SvLeJC8aw7YmuWZsbx/7Gcff0929gi0DAGuIgAkAYH17TZJXV9XOLL5j6bJRvyzJU0b91UkumlN/AMAacPTBhwAAcCTp7vcled/Y/liSM/cx5h+T/MiKNgYArFkzu4Opqi6vqnur6vYltddX1e6qunV8Xrjk2GuramdVfaSqXrCkfs6o7awqfzkDAAAAWGVm+Yjc25Kcs4/6Jd19+vhcmyRVdVoW3wXwzeOc36mqo6rqqCS/neTcJKcleckYCwAAAMAqMbNH5Lr7/VV1yjKHb0lyVXd/KcnHx7P+e2/V3jlu3U5VXTXG3nmY2wUAAADgMZrHS75fUVW3jUfojhu1DUnuXjJm16jtrw4AAADAKrHSAdNbknxjktOT3JPk1w7XhatqW1XtqKode/bsOVyXBQAAAOAgVjRg6u5Pd/dD3f3PSX43X30MbneSk5cM3Thq+6vv69qXdvfm7t68sLBw+JsHAAAAYJ9WNGCqqpOW7P5Qkr0rzG1Pcn5VPaGqTk2yKckHk9ycZFNVnVpVx2TxReDbV7JnAAAAAA5sZi/5rqp3JHlukhOqaleS1yV5blWdnqSTfCLJTyZJd99RVVdn8eXdDya5sLsfGtd5RZLrkhyV5PLuvmNWPQMAAABw6Ga5itxL9lG+7ADjL05y8T7q1ya59jC2BgAAAMBhNI9V5AAAAAA4ggiYAAAAAJhEwAQAAADAJAImAAAAACYRMAEAAAAwiYAJAAAAgEkETAAAAABMImACAAAAYBIBEwAAAACTCJgAAAAAmETABAAAAMAkAiYAAAAAJhEwAQAAADCJgAkAAACASQRMAAAAAEwiYAIAAABgEgETAAAAAJMImAAAAACYRMAEAAAAwCQCJgAAAAAmETABAAAAMImACQAAAIBJBEwAAAAATCJgAgAAAGASARMAAAAAkwiYAAAAAJhEwAQAAADAJDMLmKrq8qq6t6puX1I7vqqur6qPjp/HjXpV1ZuramdV3VZVz1pyztYx/qNVtXVW/QIAAADw2MzyDqa3JTnnEbWLktzQ3ZuS3DD2k+TcJJvGZ1uStySLgVSS1yV5dpIzk7xubygFAAAAwOows4Cpu9+f5L5HlLckuWJsX5HkvCX1K3vRjUmOraqTkrwgyfXdfV9335/k+jw6tAIAAABgjlb6HUwndvc9Y/tTSU4c2xuS3L1k3K5R21/9UapqW1XtqKode/bsObxdAwAAALBfc3vJd3d3kj6M17u0uzd39+aFhYXDdVkAAAAADmKlA6ZPj0ffMn7eO+q7k5y8ZNzGUdtfHQAAAIBVYqUDpu1J9q4EtzXJNUvqLx2ryZ2V5IHxKN11SZ5fVceNl3s/f9QAAAAAWCWOntWFq+odSZ6b5ISq2pXF1eB+OcnVVXVBkk8mefEYfm2SFybZmeSLSV6eJN19X1X9UpKbx7g3dPcjXxwOAAAAwBzNLGDq7pfs59DZ+xjbSS7cz3UuT3L5YWwNAAAAgMNobi/5BgAAAODIIGACAAAAYBIBEwAAAACTCJgAAAAAmETABACwDlTVyVX13qq6s6ruqKpXjvrxVXV9VX10/Dxu1Kuq3lxVO6vqtqp61nx/AwBgNRMwAQCsDw8m+dnuPi3JWUkurKrTklyU5Ibu3pTkhrGfJOcm2TQ+25K8ZeVbBgDWCgETAMA60N33dPdfje3PJbkryYYkW5JcMYZdkeS8sb0lyZW96MYkx1bVSSvcNgCwRgiYAADWmao6JckZSW5KcmJ33zMOfSrJiWN7Q5K7l5y2a9QAAB5FwAQAsI5U1dcl+aMkr+ruv196rLs7SR/i9bZV1Y6q2rFnz57D2CkAsJYImAAA1omqenwWw6W3d/e7RvnTex99Gz/vHfXdSU5ecvrGUXuY7r60uzd39+aFhYXZNQ8ArGoCJgCAdaCqKsllSe7q7jctObQ9ydaxvTXJNUvqLx2ryZ2V5IElj9IBADzM0fNuAACAFfGcJD+W5MNVdeuo/UKSX05ydVVdkOSTSV48jl2b5IVJdib5YpKXr2y7AMBaImACAFgHuvsDSWo/h8/ex/hOcuFMmwIAjhgekQMAAABgEgETAAAAAJMImAAAAACYRMAEAAAAwCQCJgAAAAAmETABAAAAMImACQAAAIBJBEwAAAAATCJgAgAAAGASARMAAAAAkwiYAAAAAJhEwAQAAADAJAImAAAAACaZS8BUVZ+oqg9X1a1VtWPUjq+q66vqo+PncaNeVfXmqtpZVbdV1bPm0TMAAAAA+zbPO5i+u7tP7+7NY/+iJDd096YkN4z9JDk3yabx2ZbkLSveKQAAAAD7tZoekduS5IqxfUWS85bUr+xFNyY5tqpOmkeDAAAAADzavAKmTvJ/quqWqto2aid29z1j+1NJThzbG5LcveTcXaMGAAAAwCpw9Jy+9zu6e3dV/csk11fV3yw92N1dVX0oFxxB1bYkedrTnnb4OgUAAADggOZyB1N37x4/703yx0nOTPLpvY++jZ/3juG7k5y85PSNo/bIa17a3Zu7e/PCwsIs2wcAAABgiRUPmKrqSVX19Xu3kzw/ye1JtifZOoZtTXLN2N6e5KVjNbmzkjyw5FE6AAAAAOZsHo/InZjkj6tq7/f/j+7+06q6OcnVVXVBkk8mefEYf22SFybZmeSLSV6+8i0DAAAAsD8rHjB198eSPHMf9c8kOXsf9U5y4Qq0BgAAAMBjMK+XfAMAAMBB/e0b/s28W4A14Wn/7cNz/f65vOQbAAAAgCOHgAkAAACASQRMAAAAAEziHUwAy+T5f1ieeT//DwDAynMHEwAAAACTCJgAAAAAmETABAAAAMAkAiYAAAAAJhEwAQAAADCJgAkAAACASQRMAAAAAEwiYAIAAABgEgETAAAAAJMImAAAAACYRMAEAAAAwCQCJgAAAAAmETABAAAAMImACQAAAIBJBEwAAAAATCJgAgAAAGASARMAAAAAkwiYAAAAAJhEwAQAAADAJAImAAAAACYRMAEAAAAwiYAJAAAAgEnWTMBUVedU1UeqamdVXTTvfgAA1gNzMABgOdZEwFRVRyX57STnJjktyUuq6rT5dgUAcGQzBwMAlmtNBExJzkyys7s/1t1fTnJVki1z7gkA4EhnDgYALMtaCZg2JLl7yf6uUQMAYHbMwQCAZTl63g0cLlW1Lcm2sfv5qvrIPPthbk5I8nfzboKHq1/dOu8WOLL5d7/avK5W6pu+YaW+iP0zB2Pwf/EqY/7FCvDvfrVZmTnYfudfayVg2p3k5CX7G0ftK7r70iSXrmRTrD5VtaO7N8+7D2Dl+HcPM2UOxrL4vxjWH//ueaS18ojczUk2VdWpVXVMkvOTbJ9zTwAARzpzMABgWdbEHUzd/WBVvSLJdUmOSnJ5d98x57YAAI5o5mAAwHKtiYApSbr72iTXzrsPVj236MP64989zJA5GMvk/2JYf/y752Gqu+fdAwAAAABr2Fp5BxMAAAAAq5SAiSNGVZ1TVR+pqp1VddG8+wFmq6our6p7q+r2efcCsF6Zf8H6Yw7G/giYOCJU1VFJfjvJuUlOS/KSqjptvl0BM/a2JOfMuwmA9cr8C9att8UcjH0QMHGkODPJzu7+WHd/OclVSbbMuSdghrr7/Unum3cfAOuY+ResQ+Zg7I+AiSPFhiR3L9nfNWoAAMyG+RcAXyFgAgAAAGASARNHit1JTl6yv3HUAACYDfMvAL5CwMSR4uYkm6rq1Ko6Jsn5SbbPuScAgCOZ+RcAXyFg4ojQ3Q8meUWS65LcleTq7r5jvl0Bs1RV70jyl0m+qap2VdUF8+4JYD0x/4L1yRyM/anunncPAAAAAKxh7mACAAAAYBIBEwAAAACTCJgAAAAAmETABAAAAMAkAiYAAAAAJhEwAZNU1UNVdWtV3V5Vf1hVXzvvnvaqqpdV1W8ttw4AsFaYgwGrjYAJmOofuvv07v6WJF9O8lPLOamqjp5tWwAARzRzMGBVETABh9NfJHl6VT2pqi6vqg9W1Yeqakvylb9aba+q9yS5oapOqqr3L/nr23eOcS+pqg+P2hv3XryqPl9VF1fVX1fVjVV14qj/QFXdNL7rz/bWD1VVvXp85+1V9aol9XdX1S1VdUdVbTtYPwAAK8wcDJg7ARNwWIy/hp2b5MNJ/muS93T3mUm+O8mvVNWTxtBnJXlRd//7JP8xyXXdfXqSZya5taqemuSNSZ6X5PQk31ZV541zn5Tkxu5+ZpL3J/mJUf9AkrO6+4wkVyX5+cfQ/7cmeXmSZyc5K8lPVNUZ4/CPd/e3Jtmc5Geq6ikH6QcAYEWYg5mDwWrh9khgqq+pqlvH9l8kuSzJ/03yg1X1X0b9iUmeNrav7+77xvbNSS6vqscneXd331pVz0vyvu7ekyRV9fYk35Xk3Vm8/ftPxrm3JPnesb0xyR9U1UlJjkny8cfwe3xHkj/u7i+M731Xku9M8qEsTmh+aIw7OcmmJJ85QD8AALNmDvbofoA5EjABU/3D+OvXV1RVJfkP3f2RR9SfneQLe/e7+/1V9V1Jvi/J26rqTUkeOMB3/VN399h+KF/9P+w3k7ypu7dX1XOTvH7C7/Mw43rfk+Tbu/uLVfW+LE7WDtQPAMCsmYM9uh9gjjwiB8zCdUl+ekxysuQ254epqm9I8unu/t0kv5fFW7c/mOTfV9UJVXVUkpck+fODfN+Tk+we21sfY89/keS8qvracSv5D43ak5PcPyY2z8jirdsAAKuRORgwN5JeYBZ+KcmvJ7mtqh6Xxdulv38f456b5Oeq6p+SfD7JS7v7nqq6KMl7k1SS/9Xd1xzk+16f5A+r6v4k70ly6jJ6fNmS9woki5OWt2VxcpUkv9fdH6qqO5P8VFXdleQjSW5cxrUBAObBHAyYm/rqnYUAAAAAcOg8IgcAAM1drlQAAAA9SURBVADAJAImAAAAACYRMAEAAAAwiYAJAAAAgEkETAAAAABMImACAAAAYBIBEwAAAACTCJgAAAAAmOT/A5oS/IerG8axAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 1440x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1,2,figsize=(20,5))\n",
    "sns.countplot(y_treino,ax=ax[0])\n",
    "sns.countplot(y_teste,ax=ax[1]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-kKP9tG89iVt"
   },
   "source": [
    "Antes iremos fazer uma padronização em algumas colunas da nossas bases de treino e de teste. Iremos padronizar as colunas *Age, Experience, Income, CCAvg* e *Mortgage* que tratam, respectivamente, de idade, anos de experiência, renda, gasto mensal do cartão de crédito e o valor da hipoteca da casa dos clientes que a possuem, pois seus valores são contínuos e não são adequados para modelos de classificação, tanto de *machine learning* como de *deep learning*, que é o nosso caso.\n",
    "\n",
    "Para isso faremos um *for loop* subtraindo o valor da média de cada observação de cada coluna e dividindo pelo desvio padrão da mesma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 225
    },
    "id": "TzN3mDvi9irW",
    "outputId": "24f07741-5e4c-40df-d3b9-2cf88bb9db05"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "lista=['Age','Experience','Income','CCAvg','Mortgage']\n",
    "\n",
    "for i in lista:\n",
    "  X_treino[i] = (X_treino[i] - X_treino[i].mean())/(X_treino[i].std())\n",
    "  X_teste[i] = (X_teste[i] - X_teste[i].mean())/(X_teste[i].std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zkGlwJn_URXH"
   },
   "source": [
    "Abaixo podemos ver a base de treino novamente, mas com os valores das colunas, que citamos anteriormente, padronizadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 416
    },
    "id": "Qr8f0gsY_b4y",
    "outputId": "783a7b1f-0135-4f7f-86a1-bbe303fe1a79"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Experience</th>\n",
       "      <th>Income</th>\n",
       "      <th>Family</th>\n",
       "      <th>CCAvg</th>\n",
       "      <th>Education</th>\n",
       "      <th>Mortgage</th>\n",
       "      <th>Securities Account</th>\n",
       "      <th>CD Account</th>\n",
       "      <th>Online</th>\n",
       "      <th>CreditCard</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4227</th>\n",
       "      <td>-1.157922</td>\n",
       "      <td>-1.136246</td>\n",
       "      <td>0.805772</td>\n",
       "      <td>1</td>\n",
       "      <td>1.068210</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.552282</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4676</th>\n",
       "      <td>-0.546605</td>\n",
       "      <td>-0.612620</td>\n",
       "      <td>-0.128425</td>\n",
       "      <td>3</td>\n",
       "      <td>0.096521</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.552282</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800</th>\n",
       "      <td>-1.245253</td>\n",
       "      <td>-1.136246</td>\n",
       "      <td>2.152753</td>\n",
       "      <td>1</td>\n",
       "      <td>2.325690</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.552282</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3671</th>\n",
       "      <td>0.414036</td>\n",
       "      <td>0.434631</td>\n",
       "      <td>-1.214700</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.875168</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.552282</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4193</th>\n",
       "      <td>1.462009</td>\n",
       "      <td>1.481883</td>\n",
       "      <td>-0.932268</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.989484</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.552282</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4426</th>\n",
       "      <td>-1.070591</td>\n",
       "      <td>-1.048975</td>\n",
       "      <td>1.435811</td>\n",
       "      <td>1</td>\n",
       "      <td>1.525476</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.552282</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>-1.769239</td>\n",
       "      <td>-1.747143</td>\n",
       "      <td>-1.323327</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.589377</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.552282</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3092</th>\n",
       "      <td>-0.197281</td>\n",
       "      <td>-0.176266</td>\n",
       "      <td>0.849223</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.875168</td>\n",
       "      <td>1</td>\n",
       "      <td>2.586437</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3772</th>\n",
       "      <td>-0.895929</td>\n",
       "      <td>-0.874433</td>\n",
       "      <td>1.696517</td>\n",
       "      <td>2</td>\n",
       "      <td>0.610945</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.552282</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>1.025353</td>\n",
       "      <td>0.958257</td>\n",
       "      <td>-0.953994</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.703693</td>\n",
       "      <td>2</td>\n",
       "      <td>0.848070</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4000 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Age  Experience    Income  ...  CD Account  Online  CreditCard\n",
       "4227 -1.157922   -1.136246  0.805772  ...           0       0           0\n",
       "4676 -0.546605   -0.612620 -0.128425  ...           0       1           0\n",
       "800  -1.245253   -1.136246  2.152753  ...           0       1           0\n",
       "3671  0.414036    0.434631 -1.214700  ...           0       1           0\n",
       "4193  1.462009    1.481883 -0.932268  ...           0       1           0\n",
       "...        ...         ...       ...  ...         ...     ...         ...\n",
       "4426 -1.070591   -1.048975  1.435811  ...           0       1           0\n",
       "466  -1.769239   -1.747143 -1.323327  ...           0       1           0\n",
       "3092 -0.197281   -0.176266  0.849223  ...           0       0           0\n",
       "3772 -0.895929   -0.874433  1.696517  ...           0       1           0\n",
       "860   1.025353    0.958257 -0.953994  ...           0       0           0\n",
       "\n",
       "[4000 rows x 11 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_treino"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p1qhwoUDUd_u"
   },
   "source": [
    "A mesma coisa para a nossa base de teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 416
    },
    "id": "ozHWgL1m_euP",
    "outputId": "ca38de6f-84a6-44f9-e0db-e6c07bdea28d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Experience</th>\n",
       "      <th>Income</th>\n",
       "      <th>Family</th>\n",
       "      <th>CCAvg</th>\n",
       "      <th>Education</th>\n",
       "      <th>Mortgage</th>\n",
       "      <th>Securities Account</th>\n",
       "      <th>CD Account</th>\n",
       "      <th>Online</th>\n",
       "      <th>CreditCard</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1501</th>\n",
       "      <td>-1.359828</td>\n",
       "      <td>-1.429301</td>\n",
       "      <td>-0.829699</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.956479</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.571616</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2586</th>\n",
       "      <td>0.116735</td>\n",
       "      <td>0.222166</td>\n",
       "      <td>1.644681</td>\n",
       "      <td>4</td>\n",
       "      <td>2.375332</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.571616</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2653</th>\n",
       "      <td>-1.359828</td>\n",
       "      <td>-1.342382</td>\n",
       "      <td>1.036939</td>\n",
       "      <td>2</td>\n",
       "      <td>0.651982</td>\n",
       "      <td>1</td>\n",
       "      <td>3.767427</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1055</th>\n",
       "      <td>-1.272971</td>\n",
       "      <td>-1.255463</td>\n",
       "      <td>-0.243661</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.554363</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.571616</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>705</th>\n",
       "      <td>1.419586</td>\n",
       "      <td>1.352117</td>\n",
       "      <td>-0.938224</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.726699</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.571616</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4711</th>\n",
       "      <td>1.680156</td>\n",
       "      <td>1.699794</td>\n",
       "      <td>-0.308777</td>\n",
       "      <td>3</td>\n",
       "      <td>0.249867</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.571616</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2313</th>\n",
       "      <td>1.072159</td>\n",
       "      <td>1.004440</td>\n",
       "      <td>-0.417302</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.956479</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.571616</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3214</th>\n",
       "      <td>1.332729</td>\n",
       "      <td>1.439036</td>\n",
       "      <td>-0.873109</td>\n",
       "      <td>3</td>\n",
       "      <td>-1.071369</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.571616</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2732</th>\n",
       "      <td>-1.099258</td>\n",
       "      <td>-0.994705</td>\n",
       "      <td>-0.764583</td>\n",
       "      <td>1</td>\n",
       "      <td>0.077532</td>\n",
       "      <td>3</td>\n",
       "      <td>0.842827</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1926</th>\n",
       "      <td>-1.359828</td>\n",
       "      <td>-1.255463</td>\n",
       "      <td>-0.699468</td>\n",
       "      <td>1</td>\n",
       "      <td>0.249867</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.571616</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Age  Experience    Income  ...  CD Account  Online  CreditCard\n",
       "1501 -1.359828   -1.429301 -0.829699  ...           0       0           1\n",
       "2586  0.116735    0.222166  1.644681  ...           0       0           1\n",
       "2653 -1.359828   -1.342382  1.036939  ...           0       1           0\n",
       "1055 -1.272971   -1.255463 -0.243661  ...           0       1           0\n",
       "705   1.419586    1.352117 -0.938224  ...           0       1           0\n",
       "...        ...         ...       ...  ...         ...     ...         ...\n",
       "4711  1.680156    1.699794 -0.308777  ...           0       0           0\n",
       "2313  1.072159    1.004440 -0.417302  ...           0       1           1\n",
       "3214  1.332729    1.439036 -0.873109  ...           0       1           0\n",
       "2732 -1.099258   -0.994705 -0.764583  ...           0       0           0\n",
       "1926 -1.359828   -1.255463 -0.699468  ...           0       1           0\n",
       "\n",
       "[1000 rows x 11 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_teste"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T1ygvB1DOQOp"
   },
   "source": [
    "## Criando o modelo de Rede Neural\n",
    "\n",
    "Para o nosso modelo, vamos criar uma camada de entrada, uma camada oculta e uma camada de saída, logo é um modelo bem simples.\n",
    "\n",
    "Na camada de entrada, vamos inserir o número de neurônios que definirei como 6, pois será o número de *features* somado mais um e em seguida dividido por 2 ou $\\frac{\\text{# features} + 1}{2}$. Como temos 11 *features*, então $\\frac{11 + 1}{2} = \\frac{12}{2} = 6$.\n",
    "\n",
    "Como função de ativação usarei a *ReLU* que é uma função que retorna valores da seguinte forma $\\text{ReLU(x)} = \\text{max(0,x)}$ e a derivada da função *ReLU* retorna valores 1 (se $x$ for maior igual a 0) ou 0, caso contrário.\n",
    "\n",
    "Como incializadores de pesos da camada de entrada usarei o *random uniform* e em *input_dim* irei inserir o número de *features* da base de dados.\n",
    "\n",
    "Na camada de saída colocarei apenas um neurônio e a função de ativação será a *Sigmóide*, pois ela retornará valores entre 1 e 0. A função *Sigmóide* é dada por $y = \\frac{1}{1+\\epsilon^{-x}}$.\n",
    "\n",
    "Então vamos criar a rede neural e treiná-la."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "4mQQfCR77OfW",
    "outputId": "d9eab9c2-3c25-4828-bed6-fa965db7b29d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "364/364 [==============================] - 0s 954us/step - loss: 0.4071 - binary_accuracy: 0.8723\n",
      "Epoch 2/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.2424 - binary_accuracy: 0.9150\n",
      "Epoch 3/100\n",
      "364/364 [==============================] - 0s 959us/step - loss: 0.2038 - binary_accuracy: 0.9287\n",
      "Epoch 4/100\n",
      "364/364 [==============================] - 0s 958us/step - loss: 0.1796 - binary_accuracy: 0.9408\n",
      "Epoch 5/100\n",
      "364/364 [==============================] - 0s 964us/step - loss: 0.1626 - binary_accuracy: 0.9480\n",
      "Epoch 6/100\n",
      "364/364 [==============================] - 0s 949us/step - loss: 0.1499 - binary_accuracy: 0.9540\n",
      "Epoch 7/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.1399 - binary_accuracy: 0.9578\n",
      "Epoch 8/100\n",
      "364/364 [==============================] - 0s 954us/step - loss: 0.1324 - binary_accuracy: 0.9610\n",
      "Epoch 9/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.1262 - binary_accuracy: 0.9632\n",
      "Epoch 10/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.1208 - binary_accuracy: 0.9640\n",
      "Epoch 11/100\n",
      "364/364 [==============================] - 0s 955us/step - loss: 0.1163 - binary_accuracy: 0.9668\n",
      "Epoch 12/100\n",
      "364/364 [==============================] - 0s 960us/step - loss: 0.1124 - binary_accuracy: 0.9668\n",
      "Epoch 13/100\n",
      "364/364 [==============================] - 0s 963us/step - loss: 0.1093 - binary_accuracy: 0.9685\n",
      "Epoch 14/100\n",
      "364/364 [==============================] - 0s 907us/step - loss: 0.1058 - binary_accuracy: 0.9680\n",
      "Epoch 15/100\n",
      "364/364 [==============================] - 0s 962us/step - loss: 0.1033 - binary_accuracy: 0.9690\n",
      "Epoch 16/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.1007 - binary_accuracy: 0.9693\n",
      "Epoch 17/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.0987 - binary_accuracy: 0.9697\n",
      "Epoch 18/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.0965 - binary_accuracy: 0.9695\n",
      "Epoch 19/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.0952 - binary_accuracy: 0.9693\n",
      "Epoch 20/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.0941 - binary_accuracy: 0.9707\n",
      "Epoch 21/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.0930 - binary_accuracy: 0.9697\n",
      "Epoch 22/100\n",
      "364/364 [==============================] - 0s 945us/step - loss: 0.0916 - binary_accuracy: 0.9703\n",
      "Epoch 23/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.0902 - binary_accuracy: 0.9700\n",
      "Epoch 24/100\n",
      "364/364 [==============================] - 0s 998us/step - loss: 0.0888 - binary_accuracy: 0.9725\n",
      "Epoch 25/100\n",
      "364/364 [==============================] - 0s 935us/step - loss: 0.0884 - binary_accuracy: 0.9697\n",
      "Epoch 26/100\n",
      "364/364 [==============================] - 0s 957us/step - loss: 0.0868 - binary_accuracy: 0.9710\n",
      "Epoch 27/100\n",
      "364/364 [==============================] - 0s 926us/step - loss: 0.0867 - binary_accuracy: 0.9718\n",
      "Epoch 28/100\n",
      "364/364 [==============================] - 0s 984us/step - loss: 0.0861 - binary_accuracy: 0.9710\n",
      "Epoch 29/100\n",
      "364/364 [==============================] - 0s 990us/step - loss: 0.0856 - binary_accuracy: 0.9720\n",
      "Epoch 30/100\n",
      "364/364 [==============================] - 0s 939us/step - loss: 0.0838 - binary_accuracy: 0.9725\n",
      "Epoch 31/100\n",
      "364/364 [==============================] - 0s 1000us/step - loss: 0.0841 - binary_accuracy: 0.9700\n",
      "Epoch 32/100\n",
      "364/364 [==============================] - 0s 950us/step - loss: 0.0834 - binary_accuracy: 0.9725\n",
      "Epoch 33/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.0826 - binary_accuracy: 0.9725\n",
      "Epoch 34/100\n",
      "364/364 [==============================] - 0s 954us/step - loss: 0.0818 - binary_accuracy: 0.9720\n",
      "Epoch 35/100\n",
      "364/364 [==============================] - 0s 956us/step - loss: 0.0820 - binary_accuracy: 0.9725\n",
      "Epoch 36/100\n",
      "364/364 [==============================] - 0s 951us/step - loss: 0.0812 - binary_accuracy: 0.9722\n",
      "Epoch 37/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.0816 - binary_accuracy: 0.9722\n",
      "Epoch 38/100\n",
      "364/364 [==============================] - 0s 957us/step - loss: 0.0809 - binary_accuracy: 0.9735\n",
      "Epoch 39/100\n",
      "364/364 [==============================] - 0s 927us/step - loss: 0.0803 - binary_accuracy: 0.9737\n",
      "Epoch 40/100\n",
      "364/364 [==============================] - 0s 965us/step - loss: 0.0798 - binary_accuracy: 0.9728\n",
      "Epoch 41/100\n",
      "364/364 [==============================] - 0s 950us/step - loss: 0.0795 - binary_accuracy: 0.9730\n",
      "Epoch 42/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.0791 - binary_accuracy: 0.9745\n",
      "Epoch 43/100\n",
      "364/364 [==============================] - 0s 972us/step - loss: 0.0790 - binary_accuracy: 0.9732\n",
      "Epoch 44/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.0792 - binary_accuracy: 0.9730\n",
      "Epoch 45/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.0787 - binary_accuracy: 0.9722\n",
      "Epoch 46/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.0778 - binary_accuracy: 0.9740\n",
      "Epoch 47/100\n",
      "364/364 [==============================] - 0s 942us/step - loss: 0.0782 - binary_accuracy: 0.9722\n",
      "Epoch 48/100\n",
      "364/364 [==============================] - 0s 976us/step - loss: 0.0783 - binary_accuracy: 0.9732\n",
      "Epoch 49/100\n",
      "364/364 [==============================] - 0s 935us/step - loss: 0.0782 - binary_accuracy: 0.9728\n",
      "Epoch 50/100\n",
      "364/364 [==============================] - 0s 950us/step - loss: 0.0780 - binary_accuracy: 0.9745\n",
      "Epoch 51/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.0774 - binary_accuracy: 0.9740\n",
      "Epoch 52/100\n",
      "364/364 [==============================] - 0s 953us/step - loss: 0.0767 - binary_accuracy: 0.9735\n",
      "Epoch 53/100\n",
      "364/364 [==============================] - 0s 935us/step - loss: 0.0771 - binary_accuracy: 0.9740\n",
      "Epoch 54/100\n",
      "364/364 [==============================] - 0s 963us/step - loss: 0.0767 - binary_accuracy: 0.9737\n",
      "Epoch 55/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.0763 - binary_accuracy: 0.9743\n",
      "Epoch 56/100\n",
      "364/364 [==============================] - 0s 991us/step - loss: 0.0763 - binary_accuracy: 0.9740\n",
      "Epoch 57/100\n",
      "364/364 [==============================] - 0s 947us/step - loss: 0.0766 - binary_accuracy: 0.9740\n",
      "Epoch 58/100\n",
      "364/364 [==============================] - 0s 955us/step - loss: 0.0761 - binary_accuracy: 0.9747\n",
      "Epoch 59/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.0757 - binary_accuracy: 0.9745\n",
      "Epoch 60/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.0754 - binary_accuracy: 0.9750\n",
      "Epoch 61/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.0757 - binary_accuracy: 0.9755\n",
      "Epoch 62/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.0754 - binary_accuracy: 0.9750\n",
      "Epoch 63/100\n",
      "364/364 [==============================] - 0s 961us/step - loss: 0.0752 - binary_accuracy: 0.9755\n",
      "Epoch 64/100\n",
      "364/364 [==============================] - 0s 962us/step - loss: 0.0747 - binary_accuracy: 0.9758\n",
      "Epoch 65/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.0754 - binary_accuracy: 0.9750\n",
      "Epoch 66/100\n",
      "364/364 [==============================] - 0s 945us/step - loss: 0.0744 - binary_accuracy: 0.9747\n",
      "Epoch 67/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.0739 - binary_accuracy: 0.9760\n",
      "Epoch 68/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.0742 - binary_accuracy: 0.9750\n",
      "Epoch 69/100\n",
      "364/364 [==============================] - 0s 998us/step - loss: 0.0749 - binary_accuracy: 0.9762\n",
      "Epoch 70/100\n",
      "364/364 [==============================] - 0s 991us/step - loss: 0.0746 - binary_accuracy: 0.9755\n",
      "Epoch 71/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.0742 - binary_accuracy: 0.9755\n",
      "Epoch 72/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.0739 - binary_accuracy: 0.9750\n",
      "Epoch 73/100\n",
      "364/364 [==============================] - 0s 1000us/step - loss: 0.0735 - binary_accuracy: 0.9765\n",
      "Epoch 74/100\n",
      "364/364 [==============================] - 0s 997us/step - loss: 0.0735 - binary_accuracy: 0.9730\n",
      "Epoch 75/100\n",
      "364/364 [==============================] - 0s 983us/step - loss: 0.0743 - binary_accuracy: 0.9745\n",
      "Epoch 76/100\n",
      "364/364 [==============================] - 0s 993us/step - loss: 0.0741 - binary_accuracy: 0.9758\n",
      "Epoch 77/100\n",
      "364/364 [==============================] - 0s 911us/step - loss: 0.0739 - binary_accuracy: 0.9747\n",
      "Epoch 78/100\n",
      "364/364 [==============================] - 0s 988us/step - loss: 0.0729 - binary_accuracy: 0.9775\n",
      "Epoch 79/100\n",
      "364/364 [==============================] - 0s 971us/step - loss: 0.0731 - binary_accuracy: 0.9760\n",
      "Epoch 80/100\n",
      "364/364 [==============================] - 0s 991us/step - loss: 0.0728 - binary_accuracy: 0.9758\n",
      "Epoch 81/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.0730 - binary_accuracy: 0.9770\n",
      "Epoch 82/100\n",
      "364/364 [==============================] - 0s 931us/step - loss: 0.0726 - binary_accuracy: 0.9755\n",
      "Epoch 83/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.0727 - binary_accuracy: 0.9765\n",
      "Epoch 84/100\n",
      "364/364 [==============================] - 0s 993us/step - loss: 0.0728 - binary_accuracy: 0.9758\n",
      "Epoch 85/100\n",
      "364/364 [==============================] - 0s 994us/step - loss: 0.0727 - binary_accuracy: 0.9743\n",
      "Epoch 86/100\n",
      "364/364 [==============================] - 0s 947us/step - loss: 0.0718 - binary_accuracy: 0.9770\n",
      "Epoch 87/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.0727 - binary_accuracy: 0.9758\n",
      "Epoch 88/100\n",
      "364/364 [==============================] - 0s 962us/step - loss: 0.0722 - binary_accuracy: 0.9762\n",
      "Epoch 89/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.0720 - binary_accuracy: 0.9755\n",
      "Epoch 90/100\n",
      "364/364 [==============================] - 0s 934us/step - loss: 0.0716 - binary_accuracy: 0.9758\n",
      "Epoch 91/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.0722 - binary_accuracy: 0.9760\n",
      "Epoch 92/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.0720 - binary_accuracy: 0.9758\n",
      "Epoch 93/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.0724 - binary_accuracy: 0.9755\n",
      "Epoch 94/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.0719 - binary_accuracy: 0.9765\n",
      "Epoch 95/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.0713 - binary_accuracy: 0.9780\n",
      "Epoch 96/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.0710 - binary_accuracy: 0.9750\n",
      "Epoch 97/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.0708 - binary_accuracy: 0.9772\n",
      "Epoch 98/100\n",
      "364/364 [==============================] - 0s 996us/step - loss: 0.0712 - binary_accuracy: 0.9765\n",
      "Epoch 99/100\n",
      "364/364 [==============================] - 0s 980us/step - loss: 0.0708 - binary_accuracy: 0.9783\n",
      "Epoch 100/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.0709 - binary_accuracy: 0.9762\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f0c75b315c0>"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Construção da rede neural\n",
    "modelo=Sequential()\n",
    "#camada oculta\n",
    "modelo.add(Dense(units=6, activation='relu', kernel_initializer='random_uniform', input_dim=11))\n",
    "#camada de saída\n",
    "modelo.add(Dense(units=1,activation='sigmoid'))\n",
    "modelo.compile(optimizer='adam',loss='binary_crossentropy', metrics=['binary_accuracy'])\n",
    "\n",
    "#treinando a rede neural\n",
    "modelo.fit(X_treino,y_treino, batch_size=11, epochs = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gerando as previsões com a rede neural."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "swScsiYN7Oix"
   },
   "outputs": [],
   "source": [
    "previsoes=modelo.predict(X_teste)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ed3ZfvkRF1K3"
   },
   "source": [
    "Vamos agora substituir os valores para que sejam apenas 0 ou 1. Para valores que ficarem acima de 0.5 (probabilidade de 50), os valores serão substituídos por 1, se ficarem abaixo desse valor serão substituídos por 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xGyonFAB7Ork"
   },
   "outputs": [],
   "source": [
    "lista=[]\n",
    "for i in previsoes:\n",
    "  if i > 0.5:\n",
    "    i=1\n",
    "  else:\n",
    "    i=0\n",
    "  lista.append(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qS7ClRRoF3c8"
   },
   "source": [
    "Vamos transformar a base *y_teste* em um *dataframe* e vamos inserir junto dele uma outra coluna que serão nossas previsões."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UWXWc2sr7OuT"
   },
   "outputs": [],
   "source": [
    "y_teste2=y_teste\n",
    "y_teste2=pd.DataFrame(y_teste2)\n",
    "y_teste2['prev']=pd.DataFrame(lista, index=y_teste2.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lsZffeaRTIso"
   },
   "source": [
    "Novo *dataset*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 416
    },
    "id": "Z9BiXcRm7O04",
    "outputId": "2ab97678-15ad-4cec-a662-21deb43e0d50"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Personal Loan</th>\n",
       "      <th>prev</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1501</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2586</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2653</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1055</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>705</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4711</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2313</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3214</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2732</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1926</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Personal Loan  prev\n",
       "1501              0     0\n",
       "2586              1     1\n",
       "2653              0     0\n",
       "1055              0     0\n",
       "705               0     0\n",
       "...             ...   ...\n",
       "4711              0     0\n",
       "2313              0     0\n",
       "3214              0     0\n",
       "2732              0     0\n",
       "1926              0     0\n",
       "\n",
       "[1000 rows x 2 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_teste2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_XmYEhHpDZRb"
   },
   "source": [
    "### Avaliação da Rede Neural\n",
    "\n",
    "Para analisar o desempenho do modelo de rede Rede Neural que construímos irei utilizar algumas métricas de avaliação que serão a acurácia do modelo (ou quanto o modelo acertou nas previsões), a matriz de confusão que irá mostrar o quanto o modelo acertou por classe e as métricas de precisão, *recall* e o *f1-score*.\n",
    "\n",
    "#### Acurácia do modelo de Rede Neural\n",
    "\n",
    "Vemos que a acurácia desse modelo foi bastante elevada (quase 100%), mesmo com as classes estando desbalanceadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "OfFFdpV97O5p",
    "outputId": "1ac592cb-4eb7-4270-a740-7f9082ef2d1d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A acurácia do modelo de Rede Neural foi de 98.1 %\n"
     ]
    }
   ],
   "source": [
    "print('A acurácia do modelo de Rede Neural foi de',(accuracy_score(y_teste2['Personal Loan'],y_teste2['prev']))*100,'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AHUR1_7-IdOu"
   },
   "source": [
    "Como nós temos uma base de dados desbalanceada, pode ocorrer que o número de acertos na classe com mais observações pode influenciar no desempenho das previsões. Como abaixo, seu o modelo acertar as observações da classe 0 (não tomou empréstimo pessoal) e não acertar nenhuma da classe 1 (tomo empréstimo pessoal), a acurácia do modelo será de 89.5%, que é um desempenho bastante elevado por parte do modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "NkTS-ne3IkYU",
    "outputId": "58cc2ead-b892-4917-b50d-6adb3108ace0"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Personal Loan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>375</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Personal Loan\n",
       "0           3625\n",
       "1            375"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Personal Loan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Personal Loan\n",
       "0            895\n",
       "1            105"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(pd.DataFrame(y_treino.value_counts()))\n",
    "display(pd.DataFrame(y_teste2['Personal Loan'].value_counts()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3qm49-QMDYjt"
   },
   "source": [
    "#### Matriz de confusão\n",
    "\n",
    "Uma das formas de analisarmos o desempenho para cada classe é analisar a matriz de confusão. Na diagonal principal da matriz podemos observar os resultados: para a classe 0 o modelo acertou 889 de 895 e errou 6, já para a classe 1 a rede neural acertou 94 de 105 e errou 11."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "id": "bHI8x_LJ7PDA",
    "outputId": "6ff22ab6-b94a-4faf-e403-2042a81e6d4a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[891   4]\n",
      " [ 15  90]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_teste2['Personal Loan'],y_teste2['prev']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ocKSrCh6KE5u"
   },
   "source": [
    "#### Métricas de avaliação\n",
    "\n",
    "Aqui temos 3 métricas de avaliação: a precisão, o *recall* e o *f1-score*.\n",
    "\n",
    "A precisão é o quanto o modelo acertou para uma classe em relação ao que foi predito pelo modelo. No nosso caso, para a classe 0, o modelo acertou 891 observações, mas previu que seriam 906 (891 + 15), que nos dá uma resultado de 98% de $\\frac{891}{891+15}$. Para a classe 1 esse valor foi de 96%  de $\\frac{90}{(90+4)}$.\n",
    "\n",
    "O *Recall* ou Revocação ou Sensibilidade é o quanto o modelo acertou nas previsões em relação aos valores reais. Aqui temos um resultado de 100% (um arredondamento) para a classe 0, pois o modelo acertou 891 de 895; e para a classe 1 tivemos um valor bem inferior, 86%, de 90 para 105 valores reais.\n",
    "\n",
    "O *f1-score* é a média ponderadas das duas métricas anteriores. Tivemos, para essa métricas, os resultados de 99% e 90%, para a classe 0 e classe 1, respectivamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "id": "QgV5IQDW7PGy",
    "outputId": "7514c625-3045-46c1-b07d-5e70e757c108"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99       895\n",
      "           1       0.96      0.86      0.90       105\n",
      "\n",
      "    accuracy                           0.98      1000\n",
      "   macro avg       0.97      0.93      0.95      1000\n",
      "weighted avg       0.98      0.98      0.98      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_teste2['Personal Loan'],y_teste2['prev']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CxlPj1lxVv3y"
   },
   "source": [
    "Vemos que o desempenho para a classe 1 foi bastante satisfatório, mesmo havendo uma diferença considerável entre a precisão e o *recall*.\n",
    "\n",
    "#### Pesos\n",
    "\n",
    "Vamos agora visualizar os pesos da Rede Neural.\n",
    "\n",
    "Temos 11 *features* e vemos que abaixo temos 11 conjuntos de pesos. Cada conjuntos de pesos possuem 6 valores correspondentes aos 6 neurônios que inserimos no nosso modelo na camada de entrada.\n",
    "\n",
    "Temos também outros *array* com 1 conjunto de 6 pesos, que corresponde a camada oculta que inserimos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 433
    },
    "id": "UzkLiSEP7PJv",
    "outputId": "83853e85-156e-4517-f67a-be64e60c22bc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 1.9622658e-01, -4.1741915e-02, -1.1666330e-01,  4.2183653e-02,\n",
       "          5.3961757e-03, -8.4178507e-02],\n",
       "        [-2.1885206e-01,  3.9636131e-02,  1.2540683e-01, -4.3337464e-02,\n",
       "         -8.1782631e-04,  6.4418972e-02],\n",
       "        [-2.0653951e+00,  2.3110237e-03, -2.5849927e-02, -1.0261957e-03,\n",
       "          1.2092242e-02, -6.8372175e-02],\n",
       "        [ 3.6329007e-01, -1.2331336e-02,  3.1262052e-01, -1.6063079e-02,\n",
       "         -3.2039151e-02,  3.1650135e-01],\n",
       "        [-6.2650025e-01, -9.3934865e-04, -2.4159947e-02, -1.0885049e-02,\n",
       "         -9.6449377e-03, -2.0487655e-02],\n",
       "        [ 1.0484409e+00, -8.6348811e-03,  7.8141236e-01, -1.7921945e-02,\n",
       "         -2.1281857e-02,  7.8688115e-01],\n",
       "        [ 3.4480914e-02, -9.2486746e-04,  7.4970573e-03,  1.0465845e-02,\n",
       "         -1.3575295e-02,  2.2673804e-02],\n",
       "        [ 5.0842702e-02, -2.3594785e-02, -9.6197590e-02, -2.2293752e-02,\n",
       "          3.1671323e-02, -1.0293601e-01],\n",
       "        [-1.8333679e-01,  3.9273575e-02,  5.7926983e-01, -1.2402844e-02,\n",
       "          3.5626579e-02,  5.6360346e-01],\n",
       "        [-1.4673712e-02, -4.2177856e-02, -1.5481758e-01, -3.6487013e-02,\n",
       "         -2.1998517e-02, -1.1344149e-01],\n",
       "        [ 1.6449575e-01, -2.8550152e-02, -1.6925664e-01, -8.3066970e-03,\n",
       "         -3.3018168e-02, -1.7480116e-01]], dtype=float32),\n",
       " array([-0.06120261, -0.02496617, -0.98488   , -0.02058219, -0.01510549,\n",
       "        -0.9317307 ], dtype=float32)]"
      ]
     },
     "execution_count": 21,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelo.layers[0].get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121
    },
    "id": "muOagaK_7PSH",
    "outputId": "05dac374-553e-4b6b-9700-12d325db1873"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-3.48025   ],\n",
       "        [ 0.80603623],\n",
       "        [ 2.877001  ],\n",
       "        [ 0.8159405 ],\n",
       "        [ 0.6772436 ],\n",
       "        [ 2.5881963 ]], dtype=float32), array([-3.5645201], dtype=float32)]"
      ]
     },
     "execution_count": 22,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelo.layers[1].get_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uilbsDR6lcMN"
   },
   "source": [
    "#### *Cross Validation* do modelo\n",
    "\n",
    "O *Cross Validation* é o processo de aplicar partes diferentes de treino e teste do *dataset* ao nosso modelo de Rede Neural e depois vamos encontrar a média e o desvio padrão desses resultados. A validação cruzada serve para vermos a capacidade de generalização do modelo de Rede Neural.\n",
    "\n",
    "\n",
    "Antes de aplicarmos o *cross validation* irei padronizar as colunas que tínhamos padronizado nas bases de treino e teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121
    },
    "id": "midO6rNqsKyj",
    "outputId": "da84d8ff-6639-4873-a924-057737f0cab6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "X2 = X\n",
    "lista=['Age','Experience','Income','CCAvg','Mortgage']\n",
    "\n",
    "for i in lista:\n",
    "  X2[i] = (X2[i] - X2[i].mean())/(X2[i].std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8twycEqZsLEa"
   },
   "source": [
    "\n",
    "Criarei uma função que irá gerar o modelo e em seguida aplicaremos essa função ao processo de *cross validation*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AruIMHaw7PVH"
   },
   "outputs": [],
   "source": [
    "def RedeNeural():\n",
    "  modelo=Sequential()\n",
    "  modelo.add(Dense(units=6, activation='relu', kernel_initializer='random_uniform', input_dim=11))\n",
    "  modelo.add(Dense(units=1,activation='sigmoid'))\n",
    "  modelo.compile(optimizer='adam',loss='binary_crossentropy', metrics=['binary_accuracy'])\n",
    "\n",
    "  return modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CWshIYuamNHF"
   },
   "source": [
    "Aplicando o *cross validation* vamos gerar 100 épocas (*epochs*) para cada treino, ou seja, um total de 1000 *epochs* (o que pode fazer esse processo ser demorado)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "MrqMJzBQ7PeO",
    "outputId": "2be2fdef-b64d-4317-b433-d37e957e5d34"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "450/450 [==============================] - 0s 878us/step - loss: 0.3441 - binary_accuracy: 0.9007\n",
      "Epoch 2/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.2258 - binary_accuracy: 0.9138\n",
      "Epoch 3/100\n",
      "450/450 [==============================] - 0s 957us/step - loss: 0.1922 - binary_accuracy: 0.9349\n",
      "Epoch 4/100\n",
      "450/450 [==============================] - 0s 883us/step - loss: 0.1700 - binary_accuracy: 0.9478\n",
      "Epoch 5/100\n",
      "450/450 [==============================] - 0s 921us/step - loss: 0.1533 - binary_accuracy: 0.9569\n",
      "Epoch 6/100\n",
      "450/450 [==============================] - 0s 926us/step - loss: 0.1393 - binary_accuracy: 0.9616\n",
      "Epoch 7/100\n",
      "450/450 [==============================] - 0s 889us/step - loss: 0.1281 - binary_accuracy: 0.9636\n",
      "Epoch 8/100\n",
      "450/450 [==============================] - 0s 884us/step - loss: 0.1185 - binary_accuracy: 0.9656\n",
      "Epoch 9/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1101 - binary_accuracy: 0.9671\n",
      "Epoch 10/100\n",
      "450/450 [==============================] - 0s 978us/step - loss: 0.1041 - binary_accuracy: 0.9678\n",
      "Epoch 11/100\n",
      "450/450 [==============================] - 0s 889us/step - loss: 0.0983 - binary_accuracy: 0.9691\n",
      "Epoch 12/100\n",
      "450/450 [==============================] - 0s 883us/step - loss: 0.0955 - binary_accuracy: 0.9700\n",
      "Epoch 13/100\n",
      "450/450 [==============================] - 0s 885us/step - loss: 0.0921 - binary_accuracy: 0.9698\n",
      "Epoch 14/100\n",
      "450/450 [==============================] - 0s 913us/step - loss: 0.0892 - binary_accuracy: 0.9720\n",
      "Epoch 15/100\n",
      "450/450 [==============================] - 0s 935us/step - loss: 0.0869 - binary_accuracy: 0.9716\n",
      "Epoch 16/100\n",
      "450/450 [==============================] - 0s 892us/step - loss: 0.0850 - binary_accuracy: 0.9716\n",
      "Epoch 17/100\n",
      "450/450 [==============================] - 0s 899us/step - loss: 0.0832 - binary_accuracy: 0.9724\n",
      "Epoch 18/100\n",
      "450/450 [==============================] - 0s 881us/step - loss: 0.0822 - binary_accuracy: 0.9722\n",
      "Epoch 19/100\n",
      "450/450 [==============================] - 0s 889us/step - loss: 0.0805 - binary_accuracy: 0.9736\n",
      "Epoch 20/100\n",
      "450/450 [==============================] - 0s 914us/step - loss: 0.0793 - binary_accuracy: 0.9729\n",
      "Epoch 21/100\n",
      "450/450 [==============================] - 0s 864us/step - loss: 0.0784 - binary_accuracy: 0.9738\n",
      "Epoch 22/100\n",
      "450/450 [==============================] - 0s 913us/step - loss: 0.0777 - binary_accuracy: 0.9736\n",
      "Epoch 23/100\n",
      "450/450 [==============================] - 0s 886us/step - loss: 0.0767 - binary_accuracy: 0.9764\n",
      "Epoch 24/100\n",
      "450/450 [==============================] - 0s 933us/step - loss: 0.0759 - binary_accuracy: 0.9749\n",
      "Epoch 25/100\n",
      "450/450 [==============================] - 0s 926us/step - loss: 0.0756 - binary_accuracy: 0.9751\n",
      "Epoch 26/100\n",
      "450/450 [==============================] - 0s 875us/step - loss: 0.0752 - binary_accuracy: 0.9747\n",
      "Epoch 27/100\n",
      "450/450 [==============================] - 0s 897us/step - loss: 0.0740 - binary_accuracy: 0.9742\n",
      "Epoch 28/100\n",
      "450/450 [==============================] - 0s 975us/step - loss: 0.0739 - binary_accuracy: 0.9738\n",
      "Epoch 29/100\n",
      "450/450 [==============================] - 0s 934us/step - loss: 0.0737 - binary_accuracy: 0.9758\n",
      "Epoch 30/100\n",
      "450/450 [==============================] - 0s 935us/step - loss: 0.0730 - binary_accuracy: 0.9749\n",
      "Epoch 31/100\n",
      "450/450 [==============================] - 0s 924us/step - loss: 0.0728 - binary_accuracy: 0.9736\n",
      "Epoch 32/100\n",
      "450/450 [==============================] - 0s 947us/step - loss: 0.0725 - binary_accuracy: 0.9749\n",
      "Epoch 33/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0715 - binary_accuracy: 0.9747\n",
      "Epoch 34/100\n",
      "450/450 [==============================] - 0s 934us/step - loss: 0.0708 - binary_accuracy: 0.9767\n",
      "Epoch 35/100\n",
      "450/450 [==============================] - 0s 930us/step - loss: 0.0710 - binary_accuracy: 0.9756\n",
      "Epoch 36/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0703 - binary_accuracy: 0.9767\n",
      "Epoch 37/100\n",
      "450/450 [==============================] - 0s 892us/step - loss: 0.0691 - binary_accuracy: 0.9769\n",
      "Epoch 38/100\n",
      "450/450 [==============================] - 0s 957us/step - loss: 0.0686 - binary_accuracy: 0.9773\n",
      "Epoch 39/100\n",
      "450/450 [==============================] - 0s 927us/step - loss: 0.0677 - binary_accuracy: 0.9778\n",
      "Epoch 40/100\n",
      "450/450 [==============================] - 0s 952us/step - loss: 0.0672 - binary_accuracy: 0.9780\n",
      "Epoch 41/100\n",
      "450/450 [==============================] - 0s 957us/step - loss: 0.0666 - binary_accuracy: 0.9787\n",
      "Epoch 42/100\n",
      "450/450 [==============================] - 0s 944us/step - loss: 0.0656 - binary_accuracy: 0.9782\n",
      "Epoch 43/100\n",
      "450/450 [==============================] - 0s 915us/step - loss: 0.0651 - binary_accuracy: 0.9782\n",
      "Epoch 44/100\n",
      "450/450 [==============================] - 0s 926us/step - loss: 0.0646 - binary_accuracy: 0.9791\n",
      "Epoch 45/100\n",
      "450/450 [==============================] - 0s 880us/step - loss: 0.0642 - binary_accuracy: 0.9798\n",
      "Epoch 46/100\n",
      "450/450 [==============================] - 0s 905us/step - loss: 0.0637 - binary_accuracy: 0.9796\n",
      "Epoch 47/100\n",
      "450/450 [==============================] - 0s 899us/step - loss: 0.0629 - binary_accuracy: 0.9800\n",
      "Epoch 48/100\n",
      "450/450 [==============================] - 0s 915us/step - loss: 0.0621 - binary_accuracy: 0.9796\n",
      "Epoch 49/100\n",
      "450/450 [==============================] - 0s 927us/step - loss: 0.0614 - binary_accuracy: 0.9813\n",
      "Epoch 50/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0617 - binary_accuracy: 0.9798\n",
      "Epoch 51/100\n",
      "450/450 [==============================] - 0s 944us/step - loss: 0.0614 - binary_accuracy: 0.9804\n",
      "Epoch 52/100\n",
      "450/450 [==============================] - 0s 868us/step - loss: 0.0609 - binary_accuracy: 0.9811\n",
      "Epoch 53/100\n",
      "450/450 [==============================] - 0s 941us/step - loss: 0.0604 - binary_accuracy: 0.9811\n",
      "Epoch 54/100\n",
      "450/450 [==============================] - 0s 930us/step - loss: 0.0598 - binary_accuracy: 0.9811\n",
      "Epoch 55/100\n",
      "450/450 [==============================] - 0s 990us/step - loss: 0.0598 - binary_accuracy: 0.9807\n",
      "Epoch 56/100\n",
      "450/450 [==============================] - 0s 945us/step - loss: 0.0597 - binary_accuracy: 0.9804\n",
      "Epoch 57/100\n",
      "450/450 [==============================] - 0s 868us/step - loss: 0.0595 - binary_accuracy: 0.9802\n",
      "Epoch 58/100\n",
      "450/450 [==============================] - 0s 970us/step - loss: 0.0586 - binary_accuracy: 0.9813\n",
      "Epoch 59/100\n",
      "450/450 [==============================] - 0s 983us/step - loss: 0.0587 - binary_accuracy: 0.9809\n",
      "Epoch 60/100\n",
      "450/450 [==============================] - 0s 912us/step - loss: 0.0585 - binary_accuracy: 0.9809\n",
      "Epoch 61/100\n",
      "450/450 [==============================] - 0s 941us/step - loss: 0.0586 - binary_accuracy: 0.9800\n",
      "Epoch 62/100\n",
      "450/450 [==============================] - 0s 933us/step - loss: 0.0578 - binary_accuracy: 0.9800\n",
      "Epoch 63/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0577 - binary_accuracy: 0.9816\n",
      "Epoch 64/100\n",
      "450/450 [==============================] - 0s 901us/step - loss: 0.0577 - binary_accuracy: 0.9813\n",
      "Epoch 65/100\n",
      "450/450 [==============================] - 0s 919us/step - loss: 0.0575 - binary_accuracy: 0.9811\n",
      "Epoch 66/100\n",
      "450/450 [==============================] - 0s 874us/step - loss: 0.0572 - binary_accuracy: 0.9811\n",
      "Epoch 67/100\n",
      "450/450 [==============================] - 0s 944us/step - loss: 0.0569 - binary_accuracy: 0.9800\n",
      "Epoch 68/100\n",
      "450/450 [==============================] - 0s 922us/step - loss: 0.0573 - binary_accuracy: 0.9813\n",
      "Epoch 69/100\n",
      "450/450 [==============================] - 0s 989us/step - loss: 0.0568 - binary_accuracy: 0.9813\n",
      "Epoch 70/100\n",
      "450/450 [==============================] - 0s 972us/step - loss: 0.0570 - binary_accuracy: 0.9811\n",
      "Epoch 71/100\n",
      "450/450 [==============================] - 0s 917us/step - loss: 0.0564 - binary_accuracy: 0.9811\n",
      "Epoch 72/100\n",
      "450/450 [==============================] - 0s 944us/step - loss: 0.0560 - binary_accuracy: 0.9816\n",
      "Epoch 73/100\n",
      "450/450 [==============================] - 0s 894us/step - loss: 0.0558 - binary_accuracy: 0.9807\n",
      "Epoch 74/100\n",
      "450/450 [==============================] - 0s 945us/step - loss: 0.0558 - binary_accuracy: 0.9811\n",
      "Epoch 75/100\n",
      "450/450 [==============================] - 0s 892us/step - loss: 0.0558 - binary_accuracy: 0.9811\n",
      "Epoch 76/100\n",
      "450/450 [==============================] - 0s 935us/step - loss: 0.0558 - binary_accuracy: 0.9807\n",
      "Epoch 77/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0553 - binary_accuracy: 0.9809\n",
      "Epoch 78/100\n",
      "450/450 [==============================] - 0s 998us/step - loss: 0.0554 - binary_accuracy: 0.9816\n",
      "Epoch 79/100\n",
      "450/450 [==============================] - 0s 948us/step - loss: 0.0559 - binary_accuracy: 0.9811\n",
      "Epoch 80/100\n",
      "450/450 [==============================] - 0s 928us/step - loss: 0.0554 - binary_accuracy: 0.9818\n",
      "Epoch 81/100\n",
      "450/450 [==============================] - 0s 973us/step - loss: 0.0550 - binary_accuracy: 0.9816\n",
      "Epoch 82/100\n",
      "450/450 [==============================] - 0s 904us/step - loss: 0.0539 - binary_accuracy: 0.9816\n",
      "Epoch 83/100\n",
      "450/450 [==============================] - 0s 915us/step - loss: 0.0554 - binary_accuracy: 0.9807\n",
      "Epoch 84/100\n",
      "450/450 [==============================] - 0s 932us/step - loss: 0.0545 - binary_accuracy: 0.9811\n",
      "Epoch 85/100\n",
      "450/450 [==============================] - 0s 978us/step - loss: 0.0549 - binary_accuracy: 0.9809\n",
      "Epoch 86/100\n",
      "450/450 [==============================] - 0s 980us/step - loss: 0.0550 - binary_accuracy: 0.9816\n",
      "Epoch 87/100\n",
      "450/450 [==============================] - 0s 947us/step - loss: 0.0544 - binary_accuracy: 0.9820\n",
      "Epoch 88/100\n",
      "450/450 [==============================] - 0s 884us/step - loss: 0.0549 - binary_accuracy: 0.9816\n",
      "Epoch 89/100\n",
      "450/450 [==============================] - 0s 967us/step - loss: 0.0547 - binary_accuracy: 0.9813\n",
      "Epoch 90/100\n",
      "450/450 [==============================] - 0s 954us/step - loss: 0.0543 - binary_accuracy: 0.9809\n",
      "Epoch 91/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0541 - binary_accuracy: 0.9811\n",
      "Epoch 92/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0544 - binary_accuracy: 0.9811\n",
      "Epoch 93/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0543 - binary_accuracy: 0.9816\n",
      "Epoch 94/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0541 - binary_accuracy: 0.9816\n",
      "Epoch 95/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0540 - binary_accuracy: 0.9816\n",
      "Epoch 96/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0538 - binary_accuracy: 0.9822\n",
      "Epoch 97/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0541 - binary_accuracy: 0.9809\n",
      "Epoch 98/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0540 - binary_accuracy: 0.9804\n",
      "Epoch 99/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0534 - binary_accuracy: 0.9818\n",
      "Epoch 100/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0537 - binary_accuracy: 0.9807\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/wrappers/scikit_learn.py:241: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
      "Instructions for updating:\n",
      "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "Epoch 1/100\n",
      "450/450 [==============================] - 0s 972us/step - loss: 0.3606 - binary_accuracy: 0.8987\n",
      "Epoch 2/100\n",
      "450/450 [==============================] - 0s 944us/step - loss: 0.2249 - binary_accuracy: 0.9053\n",
      "Epoch 3/100\n",
      "450/450 [==============================] - 0s 920us/step - loss: 0.1919 - binary_accuracy: 0.9391\n",
      "Epoch 4/100\n",
      "450/450 [==============================] - 0s 929us/step - loss: 0.1705 - binary_accuracy: 0.9509\n",
      "Epoch 5/100\n",
      "450/450 [==============================] - 0s 976us/step - loss: 0.1540 - binary_accuracy: 0.9564\n",
      "Epoch 6/100\n",
      "450/450 [==============================] - 0s 962us/step - loss: 0.1413 - binary_accuracy: 0.9596\n",
      "Epoch 7/100\n",
      "450/450 [==============================] - 0s 920us/step - loss: 0.1318 - binary_accuracy: 0.9627\n",
      "Epoch 8/100\n",
      "450/450 [==============================] - 0s 920us/step - loss: 0.1236 - binary_accuracy: 0.9649\n",
      "Epoch 9/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1171 - binary_accuracy: 0.9664\n",
      "Epoch 10/100\n",
      "450/450 [==============================] - 0s 891us/step - loss: 0.1119 - binary_accuracy: 0.9684\n",
      "Epoch 11/100\n",
      "450/450 [==============================] - 0s 933us/step - loss: 0.1075 - binary_accuracy: 0.9673\n",
      "Epoch 12/100\n",
      "450/450 [==============================] - 0s 939us/step - loss: 0.1033 - binary_accuracy: 0.9700\n",
      "Epoch 13/100\n",
      "450/450 [==============================] - 0s 921us/step - loss: 0.1001 - binary_accuracy: 0.9700\n",
      "Epoch 14/100\n",
      "450/450 [==============================] - 0s 964us/step - loss: 0.0982 - binary_accuracy: 0.9700\n",
      "Epoch 15/100\n",
      "450/450 [==============================] - 0s 943us/step - loss: 0.0957 - binary_accuracy: 0.9704\n",
      "Epoch 16/100\n",
      "450/450 [==============================] - 0s 918us/step - loss: 0.0938 - binary_accuracy: 0.9713\n",
      "Epoch 17/100\n",
      "450/450 [==============================] - 0s 916us/step - loss: 0.0919 - binary_accuracy: 0.9711\n",
      "Epoch 18/100\n",
      "450/450 [==============================] - 0s 944us/step - loss: 0.0902 - binary_accuracy: 0.9718\n",
      "Epoch 19/100\n",
      "450/450 [==============================] - 0s 942us/step - loss: 0.0888 - binary_accuracy: 0.9722\n",
      "Epoch 20/100\n",
      "450/450 [==============================] - 0s 958us/step - loss: 0.0874 - binary_accuracy: 0.9740\n",
      "Epoch 21/100\n",
      "450/450 [==============================] - 0s 961us/step - loss: 0.0861 - binary_accuracy: 0.9729\n",
      "Epoch 22/100\n",
      "450/450 [==============================] - 0s 911us/step - loss: 0.0855 - binary_accuracy: 0.9727\n",
      "Epoch 23/100\n",
      "450/450 [==============================] - 0s 934us/step - loss: 0.0843 - binary_accuracy: 0.9727\n",
      "Epoch 24/100\n",
      "450/450 [==============================] - 0s 960us/step - loss: 0.0834 - binary_accuracy: 0.9722\n",
      "Epoch 25/100\n",
      "450/450 [==============================] - 0s 932us/step - loss: 0.0824 - binary_accuracy: 0.9733\n",
      "Epoch 26/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0821 - binary_accuracy: 0.9727\n",
      "Epoch 27/100\n",
      "450/450 [==============================] - 0s 935us/step - loss: 0.0810 - binary_accuracy: 0.9736\n",
      "Epoch 28/100\n",
      "450/450 [==============================] - 0s 933us/step - loss: 0.0804 - binary_accuracy: 0.9731\n",
      "Epoch 29/100\n",
      "450/450 [==============================] - 0s 924us/step - loss: 0.0803 - binary_accuracy: 0.9722\n",
      "Epoch 30/100\n",
      "450/450 [==============================] - 0s 990us/step - loss: 0.0797 - binary_accuracy: 0.9731\n",
      "Epoch 31/100\n",
      "450/450 [==============================] - 0s 951us/step - loss: 0.0787 - binary_accuracy: 0.9733\n",
      "Epoch 32/100\n",
      "450/450 [==============================] - 0s 957us/step - loss: 0.0783 - binary_accuracy: 0.9756\n",
      "Epoch 33/100\n",
      "450/450 [==============================] - 0s 990us/step - loss: 0.0780 - binary_accuracy: 0.9733\n",
      "Epoch 34/100\n",
      "450/450 [==============================] - 0s 933us/step - loss: 0.0777 - binary_accuracy: 0.9740\n",
      "Epoch 35/100\n",
      "450/450 [==============================] - 0s 946us/step - loss: 0.0764 - binary_accuracy: 0.9744\n",
      "Epoch 36/100\n",
      "450/450 [==============================] - 0s 939us/step - loss: 0.0761 - binary_accuracy: 0.9742\n",
      "Epoch 37/100\n",
      "450/450 [==============================] - 0s 946us/step - loss: 0.0761 - binary_accuracy: 0.9740\n",
      "Epoch 38/100\n",
      "450/450 [==============================] - 0s 969us/step - loss: 0.0757 - binary_accuracy: 0.9731\n",
      "Epoch 39/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0756 - binary_accuracy: 0.9744\n",
      "Epoch 40/100\n",
      "450/450 [==============================] - 0s 945us/step - loss: 0.0751 - binary_accuracy: 0.9744\n",
      "Epoch 41/100\n",
      "450/450 [==============================] - 0s 937us/step - loss: 0.0748 - binary_accuracy: 0.9758\n",
      "Epoch 42/100\n",
      "450/450 [==============================] - 0s 962us/step - loss: 0.0747 - binary_accuracy: 0.9756\n",
      "Epoch 43/100\n",
      "450/450 [==============================] - 0s 946us/step - loss: 0.0741 - binary_accuracy: 0.9744\n",
      "Epoch 44/100\n",
      "450/450 [==============================] - 0s 962us/step - loss: 0.0740 - binary_accuracy: 0.9742\n",
      "Epoch 45/100\n",
      "450/450 [==============================] - 0s 966us/step - loss: 0.0736 - binary_accuracy: 0.9753\n",
      "Epoch 46/100\n",
      "450/450 [==============================] - 0s 966us/step - loss: 0.0732 - binary_accuracy: 0.9760\n",
      "Epoch 47/100\n",
      "450/450 [==============================] - 0s 962us/step - loss: 0.0730 - binary_accuracy: 0.9767\n",
      "Epoch 48/100\n",
      "450/450 [==============================] - 0s 900us/step - loss: 0.0730 - binary_accuracy: 0.9756\n",
      "Epoch 49/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0722 - binary_accuracy: 0.9760\n",
      "Epoch 50/100\n",
      "450/450 [==============================] - 0s 974us/step - loss: 0.0721 - binary_accuracy: 0.9744\n",
      "Epoch 51/100\n",
      "450/450 [==============================] - 0s 934us/step - loss: 0.0717 - binary_accuracy: 0.9767\n",
      "Epoch 52/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0718 - binary_accuracy: 0.9760\n",
      "Epoch 53/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0716 - binary_accuracy: 0.9747\n",
      "Epoch 54/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0719 - binary_accuracy: 0.9758\n",
      "Epoch 55/100\n",
      "450/450 [==============================] - 0s 965us/step - loss: 0.0710 - binary_accuracy: 0.9762\n",
      "Epoch 56/100\n",
      "450/450 [==============================] - 0s 987us/step - loss: 0.0705 - binary_accuracy: 0.9758\n",
      "Epoch 57/100\n",
      "450/450 [==============================] - 0s 949us/step - loss: 0.0710 - binary_accuracy: 0.9758\n",
      "Epoch 58/100\n",
      "450/450 [==============================] - 0s 988us/step - loss: 0.0704 - binary_accuracy: 0.9762\n",
      "Epoch 59/100\n",
      "450/450 [==============================] - 0s 955us/step - loss: 0.0705 - binary_accuracy: 0.9762\n",
      "Epoch 60/100\n",
      "450/450 [==============================] - 0s 960us/step - loss: 0.0701 - binary_accuracy: 0.9760\n",
      "Epoch 61/100\n",
      "450/450 [==============================] - 0s 921us/step - loss: 0.0703 - binary_accuracy: 0.9762\n",
      "Epoch 62/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0700 - binary_accuracy: 0.9767\n",
      "Epoch 63/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0693 - binary_accuracy: 0.9767\n",
      "Epoch 64/100\n",
      "450/450 [==============================] - 0s 945us/step - loss: 0.0698 - binary_accuracy: 0.9767\n",
      "Epoch 65/100\n",
      "450/450 [==============================] - 0s 926us/step - loss: 0.0692 - binary_accuracy: 0.9769\n",
      "Epoch 66/100\n",
      "450/450 [==============================] - 0s 998us/step - loss: 0.0691 - binary_accuracy: 0.9771\n",
      "Epoch 67/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0693 - binary_accuracy: 0.9762\n",
      "Epoch 68/100\n",
      "450/450 [==============================] - 0s 992us/step - loss: 0.0684 - binary_accuracy: 0.9778\n",
      "Epoch 69/100\n",
      "450/450 [==============================] - 0s 945us/step - loss: 0.0686 - binary_accuracy: 0.9762\n",
      "Epoch 70/100\n",
      "450/450 [==============================] - 0s 945us/step - loss: 0.0684 - binary_accuracy: 0.9776\n",
      "Epoch 71/100\n",
      "450/450 [==============================] - 0s 950us/step - loss: 0.0683 - binary_accuracy: 0.9769\n",
      "Epoch 72/100\n",
      "450/450 [==============================] - 0s 945us/step - loss: 0.0682 - binary_accuracy: 0.9767\n",
      "Epoch 73/100\n",
      "450/450 [==============================] - 0s 949us/step - loss: 0.0681 - binary_accuracy: 0.9782\n",
      "Epoch 74/100\n",
      "450/450 [==============================] - 0s 966us/step - loss: 0.0678 - binary_accuracy: 0.9776\n",
      "Epoch 75/100\n",
      "450/450 [==============================] - 0s 934us/step - loss: 0.0682 - binary_accuracy: 0.9758\n",
      "Epoch 76/100\n",
      "450/450 [==============================] - 0s 971us/step - loss: 0.0676 - binary_accuracy: 0.9776\n",
      "Epoch 77/100\n",
      "450/450 [==============================] - 0s 999us/step - loss: 0.0676 - binary_accuracy: 0.9764\n",
      "Epoch 78/100\n",
      "450/450 [==============================] - 0s 925us/step - loss: 0.0673 - binary_accuracy: 0.9771\n",
      "Epoch 79/100\n",
      "450/450 [==============================] - 0s 992us/step - loss: 0.0675 - binary_accuracy: 0.9776\n",
      "Epoch 80/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0670 - binary_accuracy: 0.9784\n",
      "Epoch 81/100\n",
      "450/450 [==============================] - 0s 956us/step - loss: 0.0670 - binary_accuracy: 0.9778\n",
      "Epoch 82/100\n",
      "450/450 [==============================] - 0s 940us/step - loss: 0.0666 - binary_accuracy: 0.9764\n",
      "Epoch 83/100\n",
      "450/450 [==============================] - 0s 957us/step - loss: 0.0670 - binary_accuracy: 0.9773\n",
      "Epoch 84/100\n",
      "450/450 [==============================] - 0s 960us/step - loss: 0.0667 - binary_accuracy: 0.9782\n",
      "Epoch 85/100\n",
      "450/450 [==============================] - 0s 925us/step - loss: 0.0657 - binary_accuracy: 0.9778\n",
      "Epoch 86/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0663 - binary_accuracy: 0.9771\n",
      "Epoch 87/100\n",
      "450/450 [==============================] - 0s 947us/step - loss: 0.0661 - binary_accuracy: 0.9780\n",
      "Epoch 88/100\n",
      "450/450 [==============================] - 0s 946us/step - loss: 0.0660 - binary_accuracy: 0.9784\n",
      "Epoch 89/100\n",
      "450/450 [==============================] - 0s 950us/step - loss: 0.0657 - binary_accuracy: 0.9784\n",
      "Epoch 90/100\n",
      "450/450 [==============================] - 0s 954us/step - loss: 0.0661 - binary_accuracy: 0.9780\n",
      "Epoch 91/100\n",
      "450/450 [==============================] - 0s 943us/step - loss: 0.0661 - binary_accuracy: 0.9767\n",
      "Epoch 92/100\n",
      "450/450 [==============================] - 0s 945us/step - loss: 0.0652 - binary_accuracy: 0.9787\n",
      "Epoch 93/100\n",
      "450/450 [==============================] - 0s 958us/step - loss: 0.0653 - binary_accuracy: 0.9771\n",
      "Epoch 94/100\n",
      "450/450 [==============================] - 0s 933us/step - loss: 0.0655 - binary_accuracy: 0.9762\n",
      "Epoch 95/100\n",
      "450/450 [==============================] - 0s 974us/step - loss: 0.0648 - binary_accuracy: 0.9776\n",
      "Epoch 96/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0648 - binary_accuracy: 0.9782\n",
      "Epoch 97/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0646 - binary_accuracy: 0.9778\n",
      "Epoch 98/100\n",
      "450/450 [==============================] - 0s 994us/step - loss: 0.0652 - binary_accuracy: 0.9771\n",
      "Epoch 99/100\n",
      "450/450 [==============================] - 0s 947us/step - loss: 0.0645 - binary_accuracy: 0.9782\n",
      "Epoch 100/100\n",
      "450/450 [==============================] - 0s 963us/step - loss: 0.0640 - binary_accuracy: 0.9784\n",
      "Epoch 1/100\n",
      "450/450 [==============================] - 0s 978us/step - loss: 0.3201 - binary_accuracy: 0.9058\n",
      "Epoch 2/100\n",
      "450/450 [==============================] - 0s 952us/step - loss: 0.2161 - binary_accuracy: 0.9058\n",
      "Epoch 3/100\n",
      "450/450 [==============================] - 0s 965us/step - loss: 0.1957 - binary_accuracy: 0.9058\n",
      "Epoch 4/100\n",
      "450/450 [==============================] - 0s 950us/step - loss: 0.1837 - binary_accuracy: 0.9058\n",
      "Epoch 5/100\n",
      "450/450 [==============================] - 0s 950us/step - loss: 0.1740 - binary_accuracy: 0.9058\n",
      "Epoch 6/100\n",
      "450/450 [==============================] - 0s 943us/step - loss: 0.1654 - binary_accuracy: 0.9058\n",
      "Epoch 7/100\n",
      "450/450 [==============================] - 0s 954us/step - loss: 0.1568 - binary_accuracy: 0.9058\n",
      "Epoch 8/100\n",
      "450/450 [==============================] - 0s 955us/step - loss: 0.1489 - binary_accuracy: 0.9058\n",
      "Epoch 9/100\n",
      "450/450 [==============================] - 0s 946us/step - loss: 0.1408 - binary_accuracy: 0.9058\n",
      "Epoch 10/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1334 - binary_accuracy: 0.9436\n",
      "Epoch 11/100\n",
      "450/450 [==============================] - 0s 944us/step - loss: 0.1265 - binary_accuracy: 0.9580\n",
      "Epoch 12/100\n",
      "450/450 [==============================] - 0s 977us/step - loss: 0.1201 - binary_accuracy: 0.9631\n",
      "Epoch 13/100\n",
      "450/450 [==============================] - 0s 942us/step - loss: 0.1144 - binary_accuracy: 0.9667\n",
      "Epoch 14/100\n",
      "450/450 [==============================] - 0s 967us/step - loss: 0.1091 - binary_accuracy: 0.9671\n",
      "Epoch 15/100\n",
      "450/450 [==============================] - 0s 946us/step - loss: 0.1039 - binary_accuracy: 0.9691\n",
      "Epoch 16/100\n",
      "450/450 [==============================] - 0s 953us/step - loss: 0.1001 - binary_accuracy: 0.9702\n",
      "Epoch 17/100\n",
      "450/450 [==============================] - 0s 972us/step - loss: 0.0956 - binary_accuracy: 0.9738\n",
      "Epoch 18/100\n",
      "450/450 [==============================] - 0s 952us/step - loss: 0.0920 - binary_accuracy: 0.9736\n",
      "Epoch 19/100\n",
      "450/450 [==============================] - 0s 991us/step - loss: 0.0890 - binary_accuracy: 0.9749\n",
      "Epoch 20/100\n",
      "450/450 [==============================] - 0s 946us/step - loss: 0.0867 - binary_accuracy: 0.9749\n",
      "Epoch 21/100\n",
      "450/450 [==============================] - 0s 949us/step - loss: 0.0837 - binary_accuracy: 0.9758\n",
      "Epoch 22/100\n",
      "450/450 [==============================] - 0s 990us/step - loss: 0.0817 - binary_accuracy: 0.9758\n",
      "Epoch 23/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0798 - binary_accuracy: 0.9782\n",
      "Epoch 24/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0775 - binary_accuracy: 0.9780\n",
      "Epoch 25/100\n",
      "450/450 [==============================] - 0s 944us/step - loss: 0.0759 - binary_accuracy: 0.9784\n",
      "Epoch 26/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0740 - binary_accuracy: 0.9778\n",
      "Epoch 27/100\n",
      "450/450 [==============================] - 0s 992us/step - loss: 0.0731 - binary_accuracy: 0.9784\n",
      "Epoch 28/100\n",
      "450/450 [==============================] - 0s 979us/step - loss: 0.0717 - binary_accuracy: 0.9789\n",
      "Epoch 29/100\n",
      "450/450 [==============================] - 0s 940us/step - loss: 0.0713 - binary_accuracy: 0.9796\n",
      "Epoch 30/100\n",
      "450/450 [==============================] - 0s 962us/step - loss: 0.0702 - binary_accuracy: 0.9796\n",
      "Epoch 31/100\n",
      "450/450 [==============================] - 0s 989us/step - loss: 0.0684 - binary_accuracy: 0.9800\n",
      "Epoch 32/100\n",
      "450/450 [==============================] - 0s 931us/step - loss: 0.0675 - binary_accuracy: 0.9807\n",
      "Epoch 33/100\n",
      "450/450 [==============================] - 0s 979us/step - loss: 0.0667 - binary_accuracy: 0.9800\n",
      "Epoch 34/100\n",
      "450/450 [==============================] - 0s 923us/step - loss: 0.0665 - binary_accuracy: 0.9800\n",
      "Epoch 35/100\n",
      "450/450 [==============================] - 0s 979us/step - loss: 0.0653 - binary_accuracy: 0.9800\n",
      "Epoch 36/100\n",
      "450/450 [==============================] - 0s 931us/step - loss: 0.0650 - binary_accuracy: 0.9798\n",
      "Epoch 37/100\n",
      "450/450 [==============================] - 0s 944us/step - loss: 0.0642 - binary_accuracy: 0.9802\n",
      "Epoch 38/100\n",
      "450/450 [==============================] - 0s 926us/step - loss: 0.0642 - binary_accuracy: 0.9816\n",
      "Epoch 39/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0634 - binary_accuracy: 0.9811\n",
      "Epoch 40/100\n",
      "450/450 [==============================] - 0s 999us/step - loss: 0.0627 - binary_accuracy: 0.9811\n",
      "Epoch 41/100\n",
      "450/450 [==============================] - 0s 996us/step - loss: 0.0625 - binary_accuracy: 0.9813\n",
      "Epoch 42/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0619 - binary_accuracy: 0.9818\n",
      "Epoch 43/100\n",
      "450/450 [==============================] - 0s 958us/step - loss: 0.0613 - binary_accuracy: 0.9804\n",
      "Epoch 44/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0615 - binary_accuracy: 0.9802\n",
      "Epoch 45/100\n",
      "450/450 [==============================] - 0s 941us/step - loss: 0.0613 - binary_accuracy: 0.9811\n",
      "Epoch 46/100\n",
      "450/450 [==============================] - 0s 972us/step - loss: 0.0608 - binary_accuracy: 0.9804\n",
      "Epoch 47/100\n",
      "450/450 [==============================] - 0s 996us/step - loss: 0.0605 - binary_accuracy: 0.9811\n",
      "Epoch 48/100\n",
      "450/450 [==============================] - 0s 936us/step - loss: 0.0603 - binary_accuracy: 0.9800\n",
      "Epoch 49/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0598 - binary_accuracy: 0.9807\n",
      "Epoch 50/100\n",
      "450/450 [==============================] - 0s 991us/step - loss: 0.0601 - binary_accuracy: 0.9807\n",
      "Epoch 51/100\n",
      "450/450 [==============================] - 0s 954us/step - loss: 0.0592 - binary_accuracy: 0.9809\n",
      "Epoch 52/100\n",
      "450/450 [==============================] - 0s 964us/step - loss: 0.0596 - binary_accuracy: 0.9804\n",
      "Epoch 53/100\n",
      "450/450 [==============================] - 0s 963us/step - loss: 0.0592 - binary_accuracy: 0.9811\n",
      "Epoch 54/100\n",
      "450/450 [==============================] - 0s 941us/step - loss: 0.0587 - binary_accuracy: 0.9820\n",
      "Epoch 55/100\n",
      "450/450 [==============================] - 0s 970us/step - loss: 0.0589 - binary_accuracy: 0.9811\n",
      "Epoch 56/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0586 - binary_accuracy: 0.9809\n",
      "Epoch 57/100\n",
      "450/450 [==============================] - 0s 963us/step - loss: 0.0583 - binary_accuracy: 0.9816\n",
      "Epoch 58/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0582 - binary_accuracy: 0.9809\n",
      "Epoch 59/100\n",
      "450/450 [==============================] - 0s 950us/step - loss: 0.0581 - binary_accuracy: 0.9822\n",
      "Epoch 60/100\n",
      "450/450 [==============================] - 0s 973us/step - loss: 0.0578 - binary_accuracy: 0.9822\n",
      "Epoch 61/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0580 - binary_accuracy: 0.9813\n",
      "Epoch 62/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0575 - binary_accuracy: 0.9818\n",
      "Epoch 63/100\n",
      "450/450 [==============================] - 0s 951us/step - loss: 0.0572 - binary_accuracy: 0.9811\n",
      "Epoch 64/100\n",
      "450/450 [==============================] - 0s 974us/step - loss: 0.0577 - binary_accuracy: 0.9811\n",
      "Epoch 65/100\n",
      "450/450 [==============================] - 0s 945us/step - loss: 0.0571 - binary_accuracy: 0.9807\n",
      "Epoch 66/100\n",
      "450/450 [==============================] - 0s 996us/step - loss: 0.0574 - binary_accuracy: 0.9818\n",
      "Epoch 67/100\n",
      "450/450 [==============================] - 0s 989us/step - loss: 0.0568 - binary_accuracy: 0.9811\n",
      "Epoch 68/100\n",
      "450/450 [==============================] - 0s 968us/step - loss: 0.0571 - binary_accuracy: 0.9809\n",
      "Epoch 69/100\n",
      "450/450 [==============================] - 0s 949us/step - loss: 0.0568 - binary_accuracy: 0.9809\n",
      "Epoch 70/100\n",
      "450/450 [==============================] - 0s 925us/step - loss: 0.0567 - binary_accuracy: 0.9809\n",
      "Epoch 71/100\n",
      "450/450 [==============================] - 0s 947us/step - loss: 0.0566 - binary_accuracy: 0.9818\n",
      "Epoch 72/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0562 - binary_accuracy: 0.9824\n",
      "Epoch 73/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0565 - binary_accuracy: 0.9811\n",
      "Epoch 74/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0566 - binary_accuracy: 0.9798\n",
      "Epoch 75/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0560 - binary_accuracy: 0.9831\n",
      "Epoch 76/100\n",
      "450/450 [==============================] - 0s 960us/step - loss: 0.0561 - binary_accuracy: 0.9811\n",
      "Epoch 77/100\n",
      "450/450 [==============================] - 0s 988us/step - loss: 0.0562 - binary_accuracy: 0.9816\n",
      "Epoch 78/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0559 - binary_accuracy: 0.9811\n",
      "Epoch 79/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0555 - binary_accuracy: 0.9829\n",
      "Epoch 80/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0560 - binary_accuracy: 0.9804\n",
      "Epoch 81/100\n",
      "450/450 [==============================] - 0s 986us/step - loss: 0.0553 - binary_accuracy: 0.9822\n",
      "Epoch 82/100\n",
      "450/450 [==============================] - 0s 986us/step - loss: 0.0559 - binary_accuracy: 0.9820\n",
      "Epoch 83/100\n",
      "450/450 [==============================] - 0s 988us/step - loss: 0.0556 - binary_accuracy: 0.9827\n",
      "Epoch 84/100\n",
      "450/450 [==============================] - 0s 963us/step - loss: 0.0558 - binary_accuracy: 0.9809\n",
      "Epoch 85/100\n",
      "450/450 [==============================] - 0s 982us/step - loss: 0.0552 - binary_accuracy: 0.9818\n",
      "Epoch 86/100\n",
      "450/450 [==============================] - 0s 958us/step - loss: 0.0554 - binary_accuracy: 0.9809\n",
      "Epoch 87/100\n",
      "450/450 [==============================] - 0s 961us/step - loss: 0.0547 - binary_accuracy: 0.9822\n",
      "Epoch 88/100\n",
      "450/450 [==============================] - 0s 957us/step - loss: 0.0552 - binary_accuracy: 0.9818\n",
      "Epoch 89/100\n",
      "450/450 [==============================] - 0s 983us/step - loss: 0.0548 - binary_accuracy: 0.9824\n",
      "Epoch 90/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0548 - binary_accuracy: 0.9820\n",
      "Epoch 91/100\n",
      "450/450 [==============================] - 0s 958us/step - loss: 0.0553 - binary_accuracy: 0.9824\n",
      "Epoch 92/100\n",
      "450/450 [==============================] - 0s 965us/step - loss: 0.0546 - binary_accuracy: 0.9831\n",
      "Epoch 93/100\n",
      "450/450 [==============================] - 0s 999us/step - loss: 0.0546 - binary_accuracy: 0.9816\n",
      "Epoch 94/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0548 - binary_accuracy: 0.9820\n",
      "Epoch 95/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0545 - binary_accuracy: 0.9811\n",
      "Epoch 96/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0542 - binary_accuracy: 0.9838\n",
      "Epoch 97/100\n",
      "450/450 [==============================] - 0s 956us/step - loss: 0.0543 - binary_accuracy: 0.9827\n",
      "Epoch 98/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0538 - binary_accuracy: 0.9829\n",
      "Epoch 99/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0544 - binary_accuracy: 0.9824\n",
      "Epoch 100/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0539 - binary_accuracy: 0.9827\n",
      "Epoch 1/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.2992 - binary_accuracy: 0.8984\n",
      "Epoch 2/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1998 - binary_accuracy: 0.9247\n",
      "Epoch 3/100\n",
      "450/450 [==============================] - 0s 974us/step - loss: 0.1727 - binary_accuracy: 0.9473\n",
      "Epoch 4/100\n",
      "450/450 [==============================] - 0s 979us/step - loss: 0.1517 - binary_accuracy: 0.9536\n",
      "Epoch 5/100\n",
      "450/450 [==============================] - 0s 986us/step - loss: 0.1326 - binary_accuracy: 0.9598\n",
      "Epoch 6/100\n",
      "450/450 [==============================] - 0s 990us/step - loss: 0.1194 - binary_accuracy: 0.9636\n",
      "Epoch 7/100\n",
      "450/450 [==============================] - 0s 995us/step - loss: 0.1100 - binary_accuracy: 0.9651\n",
      "Epoch 8/100\n",
      "450/450 [==============================] - 0s 978us/step - loss: 0.1031 - binary_accuracy: 0.9676\n",
      "Epoch 9/100\n",
      "450/450 [==============================] - 0s 962us/step - loss: 0.0972 - binary_accuracy: 0.9687\n",
      "Epoch 10/100\n",
      "450/450 [==============================] - 0s 980us/step - loss: 0.0932 - binary_accuracy: 0.9724\n",
      "Epoch 11/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0888 - binary_accuracy: 0.9727\n",
      "Epoch 12/100\n",
      "450/450 [==============================] - 0s 955us/step - loss: 0.0849 - binary_accuracy: 0.9751\n",
      "Epoch 13/100\n",
      "450/450 [==============================] - 0s 988us/step - loss: 0.0815 - binary_accuracy: 0.9760\n",
      "Epoch 14/100\n",
      "450/450 [==============================] - 0s 963us/step - loss: 0.0786 - binary_accuracy: 0.9769\n",
      "Epoch 15/100\n",
      "450/450 [==============================] - 0s 985us/step - loss: 0.0762 - binary_accuracy: 0.9756\n",
      "Epoch 16/100\n",
      "450/450 [==============================] - 0s 943us/step - loss: 0.0742 - binary_accuracy: 0.9762\n",
      "Epoch 17/100\n",
      "450/450 [==============================] - 0s 955us/step - loss: 0.0726 - binary_accuracy: 0.9764\n",
      "Epoch 18/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0708 - binary_accuracy: 0.9764\n",
      "Epoch 19/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0701 - binary_accuracy: 0.9773\n",
      "Epoch 20/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0690 - binary_accuracy: 0.9789\n",
      "Epoch 21/100\n",
      "450/450 [==============================] - 0s 958us/step - loss: 0.0680 - binary_accuracy: 0.9773\n",
      "Epoch 22/100\n",
      "450/450 [==============================] - 0s 971us/step - loss: 0.0673 - binary_accuracy: 0.9789\n",
      "Epoch 23/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0661 - binary_accuracy: 0.9798\n",
      "Epoch 24/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0655 - binary_accuracy: 0.9800\n",
      "Epoch 25/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0649 - binary_accuracy: 0.9798\n",
      "Epoch 26/100\n",
      "450/450 [==============================] - 0s 947us/step - loss: 0.0639 - binary_accuracy: 0.9804\n",
      "Epoch 27/100\n",
      "450/450 [==============================] - 0s 978us/step - loss: 0.0639 - binary_accuracy: 0.9796\n",
      "Epoch 28/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0638 - binary_accuracy: 0.9809\n",
      "Epoch 29/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0624 - binary_accuracy: 0.9811\n",
      "Epoch 30/100\n",
      "450/450 [==============================] - 0s 970us/step - loss: 0.0618 - binary_accuracy: 0.9811\n",
      "Epoch 31/100\n",
      "450/450 [==============================] - 0s 970us/step - loss: 0.0614 - binary_accuracy: 0.9811\n",
      "Epoch 32/100\n",
      "450/450 [==============================] - 0s 996us/step - loss: 0.0612 - binary_accuracy: 0.9800\n",
      "Epoch 33/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0611 - binary_accuracy: 0.9809\n",
      "Epoch 34/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0606 - binary_accuracy: 0.9796\n",
      "Epoch 35/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0604 - binary_accuracy: 0.9807\n",
      "Epoch 36/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0596 - binary_accuracy: 0.9813\n",
      "Epoch 37/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0592 - binary_accuracy: 0.9809\n",
      "Epoch 38/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0589 - binary_accuracy: 0.9809\n",
      "Epoch 39/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0591 - binary_accuracy: 0.9818\n",
      "Epoch 40/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0590 - binary_accuracy: 0.9796\n",
      "Epoch 41/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0585 - binary_accuracy: 0.9807\n",
      "Epoch 42/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0580 - binary_accuracy: 0.9796\n",
      "Epoch 43/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0582 - binary_accuracy: 0.9811\n",
      "Epoch 44/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0578 - binary_accuracy: 0.9811\n",
      "Epoch 45/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0574 - binary_accuracy: 0.9809\n",
      "Epoch 46/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0568 - binary_accuracy: 0.9807\n",
      "Epoch 47/100\n",
      "450/450 [==============================] - 0s 979us/step - loss: 0.0573 - binary_accuracy: 0.9804\n",
      "Epoch 48/100\n",
      "450/450 [==============================] - 0s 988us/step - loss: 0.0569 - binary_accuracy: 0.9813\n",
      "Epoch 49/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0567 - binary_accuracy: 0.9818\n",
      "Epoch 50/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0561 - binary_accuracy: 0.9816\n",
      "Epoch 51/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0558 - binary_accuracy: 0.9820\n",
      "Epoch 52/100\n",
      "450/450 [==============================] - 0s 982us/step - loss: 0.0555 - binary_accuracy: 0.9822\n",
      "Epoch 53/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0546 - binary_accuracy: 0.9822\n",
      "Epoch 54/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0556 - binary_accuracy: 0.9816\n",
      "Epoch 55/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0557 - binary_accuracy: 0.9809\n",
      "Epoch 56/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0554 - binary_accuracy: 0.9809\n",
      "Epoch 57/100\n",
      "450/450 [==============================] - 0s 989us/step - loss: 0.0546 - binary_accuracy: 0.9820\n",
      "Epoch 58/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0547 - binary_accuracy: 0.9822\n",
      "Epoch 59/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0547 - binary_accuracy: 0.9813\n",
      "Epoch 60/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0546 - binary_accuracy: 0.9824\n",
      "Epoch 61/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0543 - binary_accuracy: 0.9818\n",
      "Epoch 62/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0541 - binary_accuracy: 0.9822\n",
      "Epoch 63/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0542 - binary_accuracy: 0.9813\n",
      "Epoch 64/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0537 - binary_accuracy: 0.9816\n",
      "Epoch 65/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0532 - binary_accuracy: 0.9818\n",
      "Epoch 66/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0538 - binary_accuracy: 0.9824\n",
      "Epoch 67/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0535 - binary_accuracy: 0.9820\n",
      "Epoch 68/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0533 - binary_accuracy: 0.9816\n",
      "Epoch 69/100\n",
      "450/450 [==============================] - 0s 979us/step - loss: 0.0529 - binary_accuracy: 0.9807\n",
      "Epoch 70/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0529 - binary_accuracy: 0.9827\n",
      "Epoch 71/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0534 - binary_accuracy: 0.9833\n",
      "Epoch 72/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0527 - binary_accuracy: 0.9818\n",
      "Epoch 73/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0531 - binary_accuracy: 0.9822\n",
      "Epoch 74/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0525 - binary_accuracy: 0.9809\n",
      "Epoch 75/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0526 - binary_accuracy: 0.9820\n",
      "Epoch 76/100\n",
      "450/450 [==============================] - 0s 974us/step - loss: 0.0524 - binary_accuracy: 0.9831\n",
      "Epoch 77/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0522 - binary_accuracy: 0.9816\n",
      "Epoch 78/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0521 - binary_accuracy: 0.9811\n",
      "Epoch 79/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0521 - binary_accuracy: 0.9836\n",
      "Epoch 80/100\n",
      "450/450 [==============================] - 0s 997us/step - loss: 0.0525 - binary_accuracy: 0.9802\n",
      "Epoch 81/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0523 - binary_accuracy: 0.9822\n",
      "Epoch 82/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0518 - binary_accuracy: 0.9829\n",
      "Epoch 83/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0517 - binary_accuracy: 0.9822\n",
      "Epoch 84/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0517 - binary_accuracy: 0.9824\n",
      "Epoch 85/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0519 - binary_accuracy: 0.9824\n",
      "Epoch 86/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0521 - binary_accuracy: 0.9820\n",
      "Epoch 87/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0516 - binary_accuracy: 0.9829\n",
      "Epoch 88/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0513 - binary_accuracy: 0.9833\n",
      "Epoch 89/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0520 - binary_accuracy: 0.9827\n",
      "Epoch 90/100\n",
      "450/450 [==============================] - 0s 980us/step - loss: 0.0516 - binary_accuracy: 0.9829\n",
      "Epoch 91/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0517 - binary_accuracy: 0.9831\n",
      "Epoch 92/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0513 - binary_accuracy: 0.9840\n",
      "Epoch 93/100\n",
      "450/450 [==============================] - 0s 990us/step - loss: 0.0511 - binary_accuracy: 0.9824\n",
      "Epoch 94/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0517 - binary_accuracy: 0.9833\n",
      "Epoch 95/100\n",
      "450/450 [==============================] - 0s 995us/step - loss: 0.0508 - binary_accuracy: 0.9831\n",
      "Epoch 96/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0515 - binary_accuracy: 0.9827\n",
      "Epoch 97/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0513 - binary_accuracy: 0.9829\n",
      "Epoch 98/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0515 - binary_accuracy: 0.9824\n",
      "Epoch 99/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0510 - binary_accuracy: 0.9822\n",
      "Epoch 100/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0505 - binary_accuracy: 0.9827\n",
      "Epoch 1/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.3572 - binary_accuracy: 0.8956\n",
      "Epoch 2/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.2264 - binary_accuracy: 0.9040\n",
      "Epoch 3/100\n",
      "450/450 [==============================] - 0s 991us/step - loss: 0.1921 - binary_accuracy: 0.9233\n",
      "Epoch 4/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1680 - binary_accuracy: 0.9384\n",
      "Epoch 5/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1490 - binary_accuracy: 0.9478\n",
      "Epoch 6/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1341 - binary_accuracy: 0.9531\n",
      "Epoch 7/100\n",
      "450/450 [==============================] - 0s 980us/step - loss: 0.1228 - binary_accuracy: 0.9600\n",
      "Epoch 8/100\n",
      "450/450 [==============================] - 0s 995us/step - loss: 0.1136 - binary_accuracy: 0.9631\n",
      "Epoch 9/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1066 - binary_accuracy: 0.9662\n",
      "Epoch 10/100\n",
      "450/450 [==============================] - 0s 993us/step - loss: 0.1013 - binary_accuracy: 0.9684\n",
      "Epoch 11/100\n",
      "450/450 [==============================] - 0s 992us/step - loss: 0.0969 - binary_accuracy: 0.9716\n",
      "Epoch 12/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0937 - binary_accuracy: 0.9698\n",
      "Epoch 13/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0904 - binary_accuracy: 0.9716\n",
      "Epoch 14/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0883 - binary_accuracy: 0.9720\n",
      "Epoch 15/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0863 - binary_accuracy: 0.9720\n",
      "Epoch 16/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0843 - binary_accuracy: 0.9720\n",
      "Epoch 17/100\n",
      "450/450 [==============================] - 0s 995us/step - loss: 0.0826 - binary_accuracy: 0.9742\n",
      "Epoch 18/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0812 - binary_accuracy: 0.9740\n",
      "Epoch 19/100\n",
      "450/450 [==============================] - 0s 975us/step - loss: 0.0800 - binary_accuracy: 0.9733\n",
      "Epoch 20/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0793 - binary_accuracy: 0.9729\n",
      "Epoch 21/100\n",
      "450/450 [==============================] - 0s 990us/step - loss: 0.0784 - binary_accuracy: 0.9740\n",
      "Epoch 22/100\n",
      "450/450 [==============================] - 0s 970us/step - loss: 0.0774 - binary_accuracy: 0.9742\n",
      "Epoch 23/100\n",
      "450/450 [==============================] - 0s 971us/step - loss: 0.0765 - binary_accuracy: 0.9762\n",
      "Epoch 24/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0751 - binary_accuracy: 0.9767\n",
      "Epoch 25/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0740 - binary_accuracy: 0.9760\n",
      "Epoch 26/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0735 - binary_accuracy: 0.9764\n",
      "Epoch 27/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0720 - binary_accuracy: 0.9767\n",
      "Epoch 28/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0710 - binary_accuracy: 0.9776\n",
      "Epoch 29/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0702 - binary_accuracy: 0.9780\n",
      "Epoch 30/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0694 - binary_accuracy: 0.9784\n",
      "Epoch 31/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0687 - binary_accuracy: 0.9789\n",
      "Epoch 32/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0677 - binary_accuracy: 0.9782\n",
      "Epoch 33/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0672 - binary_accuracy: 0.9787\n",
      "Epoch 34/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0666 - binary_accuracy: 0.9787\n",
      "Epoch 35/100\n",
      "450/450 [==============================] - 0s 966us/step - loss: 0.0664 - binary_accuracy: 0.9791\n",
      "Epoch 36/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0656 - binary_accuracy: 0.9784\n",
      "Epoch 37/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0650 - binary_accuracy: 0.9793\n",
      "Epoch 38/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0642 - binary_accuracy: 0.9791\n",
      "Epoch 39/100\n",
      "450/450 [==============================] - 0s 992us/step - loss: 0.0646 - binary_accuracy: 0.9804\n",
      "Epoch 40/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0642 - binary_accuracy: 0.9798\n",
      "Epoch 41/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0638 - binary_accuracy: 0.9800\n",
      "Epoch 42/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0632 - binary_accuracy: 0.9789\n",
      "Epoch 43/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0628 - binary_accuracy: 0.9793\n",
      "Epoch 44/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0622 - binary_accuracy: 0.9796\n",
      "Epoch 45/100\n",
      "450/450 [==============================] - 0s 976us/step - loss: 0.0627 - binary_accuracy: 0.9796\n",
      "Epoch 46/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0621 - binary_accuracy: 0.9804\n",
      "Epoch 47/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0622 - binary_accuracy: 0.9796\n",
      "Epoch 48/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0615 - binary_accuracy: 0.9809\n",
      "Epoch 49/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0617 - binary_accuracy: 0.9802\n",
      "Epoch 50/100\n",
      "450/450 [==============================] - 0s 985us/step - loss: 0.0613 - binary_accuracy: 0.9809\n",
      "Epoch 51/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0611 - binary_accuracy: 0.9798\n",
      "Epoch 52/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0606 - binary_accuracy: 0.9811\n",
      "Epoch 53/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0607 - binary_accuracy: 0.9804\n",
      "Epoch 54/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0606 - binary_accuracy: 0.9800\n",
      "Epoch 55/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0603 - binary_accuracy: 0.9804\n",
      "Epoch 56/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0604 - binary_accuracy: 0.9804\n",
      "Epoch 57/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0604 - binary_accuracy: 0.9809\n",
      "Epoch 58/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0601 - binary_accuracy: 0.9813\n",
      "Epoch 59/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0599 - binary_accuracy: 0.9809\n",
      "Epoch 60/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0598 - binary_accuracy: 0.9804\n",
      "Epoch 61/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0595 - binary_accuracy: 0.9804\n",
      "Epoch 62/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0592 - binary_accuracy: 0.9804\n",
      "Epoch 63/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0595 - binary_accuracy: 0.9807\n",
      "Epoch 64/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0593 - binary_accuracy: 0.9802\n",
      "Epoch 65/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0589 - binary_accuracy: 0.9807\n",
      "Epoch 66/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0594 - binary_accuracy: 0.9811\n",
      "Epoch 67/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0590 - binary_accuracy: 0.9807\n",
      "Epoch 68/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0587 - binary_accuracy: 0.9813\n",
      "Epoch 69/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0587 - binary_accuracy: 0.9809\n",
      "Epoch 70/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0581 - binary_accuracy: 0.9813\n",
      "Epoch 71/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0584 - binary_accuracy: 0.9804\n",
      "Epoch 72/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0581 - binary_accuracy: 0.9822\n",
      "Epoch 73/100\n",
      "450/450 [==============================] - 0s 989us/step - loss: 0.0583 - binary_accuracy: 0.9807\n",
      "Epoch 74/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0583 - binary_accuracy: 0.9816\n",
      "Epoch 75/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0584 - binary_accuracy: 0.9809\n",
      "Epoch 76/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0581 - binary_accuracy: 0.9816\n",
      "Epoch 77/100\n",
      "450/450 [==============================] - 0s 992us/step - loss: 0.0581 - binary_accuracy: 0.9802\n",
      "Epoch 78/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0578 - binary_accuracy: 0.9804\n",
      "Epoch 79/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0574 - binary_accuracy: 0.9811\n",
      "Epoch 80/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0576 - binary_accuracy: 0.9813\n",
      "Epoch 81/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0573 - binary_accuracy: 0.9818\n",
      "Epoch 82/100\n",
      "450/450 [==============================] - 0s 989us/step - loss: 0.0576 - binary_accuracy: 0.9802\n",
      "Epoch 83/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0581 - binary_accuracy: 0.9809\n",
      "Epoch 84/100\n",
      "450/450 [==============================] - 0s 986us/step - loss: 0.0573 - binary_accuracy: 0.9811\n",
      "Epoch 85/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0574 - binary_accuracy: 0.9822\n",
      "Epoch 86/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0571 - binary_accuracy: 0.9816\n",
      "Epoch 87/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0569 - binary_accuracy: 0.9818\n",
      "Epoch 88/100\n",
      "450/450 [==============================] - 0s 988us/step - loss: 0.0576 - binary_accuracy: 0.9811\n",
      "Epoch 89/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0572 - binary_accuracy: 0.9807\n",
      "Epoch 90/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0573 - binary_accuracy: 0.9824\n",
      "Epoch 91/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0571 - binary_accuracy: 0.9816\n",
      "Epoch 92/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0574 - binary_accuracy: 0.9811\n",
      "Epoch 93/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0567 - binary_accuracy: 0.9813\n",
      "Epoch 94/100\n",
      "450/450 [==============================] - 0s 996us/step - loss: 0.0567 - binary_accuracy: 0.9804\n",
      "Epoch 95/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0566 - binary_accuracy: 0.9804\n",
      "Epoch 96/100\n",
      "450/450 [==============================] - 0s 995us/step - loss: 0.0564 - binary_accuracy: 0.9811\n",
      "Epoch 97/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0569 - binary_accuracy: 0.9816\n",
      "Epoch 98/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0565 - binary_accuracy: 0.9822\n",
      "Epoch 99/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0567 - binary_accuracy: 0.9818\n",
      "Epoch 100/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0564 - binary_accuracy: 0.9811\n",
      "Epoch 1/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.3030 - binary_accuracy: 0.9044\n",
      "Epoch 2/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.2124 - binary_accuracy: 0.9051\n",
      "Epoch 3/100\n",
      "450/450 [==============================] - 0s 999us/step - loss: 0.1939 - binary_accuracy: 0.9051\n",
      "Epoch 4/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1840 - binary_accuracy: 0.9051\n",
      "Epoch 5/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1761 - binary_accuracy: 0.9051\n",
      "Epoch 6/100\n",
      "450/450 [==============================] - 0s 979us/step - loss: 0.1676 - binary_accuracy: 0.9051\n",
      "Epoch 7/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1591 - binary_accuracy: 0.9051\n",
      "Epoch 8/100\n",
      "450/450 [==============================] - 0s 977us/step - loss: 0.1505 - binary_accuracy: 0.9051\n",
      "Epoch 9/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1429 - binary_accuracy: 0.9051\n",
      "Epoch 10/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1358 - binary_accuracy: 0.9371\n",
      "Epoch 11/100\n",
      "450/450 [==============================] - 0s 990us/step - loss: 0.1288 - binary_accuracy: 0.9556\n",
      "Epoch 12/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1230 - binary_accuracy: 0.9602\n",
      "Epoch 13/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1172 - binary_accuracy: 0.9649\n",
      "Epoch 14/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1123 - binary_accuracy: 0.9682\n",
      "Epoch 15/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1076 - binary_accuracy: 0.9700\n",
      "Epoch 16/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1029 - binary_accuracy: 0.9704\n",
      "Epoch 17/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0997 - binary_accuracy: 0.9727\n",
      "Epoch 18/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0961 - binary_accuracy: 0.9727\n",
      "Epoch 19/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0936 - binary_accuracy: 0.9729\n",
      "Epoch 20/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0907 - binary_accuracy: 0.9742\n",
      "Epoch 21/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0882 - binary_accuracy: 0.9753\n",
      "Epoch 22/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0855 - binary_accuracy: 0.9773\n",
      "Epoch 23/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0842 - binary_accuracy: 0.9760\n",
      "Epoch 24/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0823 - binary_accuracy: 0.9769\n",
      "Epoch 25/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0799 - binary_accuracy: 0.9773\n",
      "Epoch 26/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0791 - binary_accuracy: 0.9773\n",
      "Epoch 27/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0771 - binary_accuracy: 0.9793\n",
      "Epoch 28/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0760 - binary_accuracy: 0.9773\n",
      "Epoch 29/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0750 - binary_accuracy: 0.9791\n",
      "Epoch 30/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0740 - binary_accuracy: 0.9780\n",
      "Epoch 31/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0723 - binary_accuracy: 0.9807\n",
      "Epoch 32/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0717 - binary_accuracy: 0.9796\n",
      "Epoch 33/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0710 - binary_accuracy: 0.9813\n",
      "Epoch 34/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0699 - binary_accuracy: 0.9804\n",
      "Epoch 35/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0685 - binary_accuracy: 0.9820\n",
      "Epoch 36/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0688 - binary_accuracy: 0.9802\n",
      "Epoch 37/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0676 - binary_accuracy: 0.9811\n",
      "Epoch 38/100\n",
      "450/450 [==============================] - 0s 989us/step - loss: 0.0674 - binary_accuracy: 0.9820\n",
      "Epoch 39/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0663 - binary_accuracy: 0.9813\n",
      "Epoch 40/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0658 - binary_accuracy: 0.9820\n",
      "Epoch 41/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0650 - binary_accuracy: 0.9811\n",
      "Epoch 42/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0648 - binary_accuracy: 0.9816\n",
      "Epoch 43/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0647 - binary_accuracy: 0.9816\n",
      "Epoch 44/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0637 - binary_accuracy: 0.9827\n",
      "Epoch 45/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0639 - binary_accuracy: 0.9829\n",
      "Epoch 46/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0631 - binary_accuracy: 0.9818\n",
      "Epoch 47/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0628 - binary_accuracy: 0.9818\n",
      "Epoch 48/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0626 - binary_accuracy: 0.9820\n",
      "Epoch 49/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0624 - binary_accuracy: 0.9820\n",
      "Epoch 50/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0622 - binary_accuracy: 0.9811\n",
      "Epoch 51/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0619 - binary_accuracy: 0.9833\n",
      "Epoch 52/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0613 - binary_accuracy: 0.9818\n",
      "Epoch 53/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0618 - binary_accuracy: 0.9827\n",
      "Epoch 54/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0609 - binary_accuracy: 0.9831\n",
      "Epoch 55/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0610 - binary_accuracy: 0.9836\n",
      "Epoch 56/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0608 - binary_accuracy: 0.9822\n",
      "Epoch 57/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0606 - binary_accuracy: 0.9831\n",
      "Epoch 58/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0603 - binary_accuracy: 0.9822\n",
      "Epoch 59/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0601 - binary_accuracy: 0.9827\n",
      "Epoch 60/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0599 - binary_accuracy: 0.9833\n",
      "Epoch 61/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0597 - binary_accuracy: 0.9827\n",
      "Epoch 62/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0593 - binary_accuracy: 0.9818\n",
      "Epoch 63/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0596 - binary_accuracy: 0.9824\n",
      "Epoch 64/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0591 - binary_accuracy: 0.9822\n",
      "Epoch 65/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0590 - binary_accuracy: 0.9842\n",
      "Epoch 66/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0593 - binary_accuracy: 0.9818\n",
      "Epoch 67/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0585 - binary_accuracy: 0.9824\n",
      "Epoch 68/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0588 - binary_accuracy: 0.9833\n",
      "Epoch 69/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0581 - binary_accuracy: 0.9820\n",
      "Epoch 70/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0585 - binary_accuracy: 0.9824\n",
      "Epoch 71/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0584 - binary_accuracy: 0.9820\n",
      "Epoch 72/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0584 - binary_accuracy: 0.9829\n",
      "Epoch 73/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0584 - binary_accuracy: 0.9833\n",
      "Epoch 74/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0583 - binary_accuracy: 0.9827\n",
      "Epoch 75/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0579 - binary_accuracy: 0.9829\n",
      "Epoch 76/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0576 - binary_accuracy: 0.9829\n",
      "Epoch 77/100\n",
      "450/450 [==============================] - 0s 992us/step - loss: 0.0578 - binary_accuracy: 0.9833\n",
      "Epoch 78/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0577 - binary_accuracy: 0.9829\n",
      "Epoch 79/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0579 - binary_accuracy: 0.9818\n",
      "Epoch 80/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0577 - binary_accuracy: 0.9824\n",
      "Epoch 81/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0574 - binary_accuracy: 0.9820\n",
      "Epoch 82/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0578 - binary_accuracy: 0.9831\n",
      "Epoch 83/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0574 - binary_accuracy: 0.9831\n",
      "Epoch 84/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0577 - binary_accuracy: 0.9831\n",
      "Epoch 85/100\n",
      "450/450 [==============================] - 0s 999us/step - loss: 0.0573 - binary_accuracy: 0.9827\n",
      "Epoch 86/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0571 - binary_accuracy: 0.9827\n",
      "Epoch 87/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0572 - binary_accuracy: 0.9836\n",
      "Epoch 88/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0571 - binary_accuracy: 0.9831\n",
      "Epoch 89/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0569 - binary_accuracy: 0.9829\n",
      "Epoch 90/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0570 - binary_accuracy: 0.9827\n",
      "Epoch 91/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0570 - binary_accuracy: 0.9833\n",
      "Epoch 92/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0562 - binary_accuracy: 0.9838\n",
      "Epoch 93/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0570 - binary_accuracy: 0.9824\n",
      "Epoch 94/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0571 - binary_accuracy: 0.9824\n",
      "Epoch 95/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0567 - binary_accuracy: 0.9833\n",
      "Epoch 96/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0571 - binary_accuracy: 0.9831\n",
      "Epoch 97/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0569 - binary_accuracy: 0.9824\n",
      "Epoch 98/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0561 - binary_accuracy: 0.9833\n",
      "Epoch 99/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0566 - binary_accuracy: 0.9833\n",
      "Epoch 100/100\n",
      "450/450 [==============================] - 0s 988us/step - loss: 0.0570 - binary_accuracy: 0.9831\n",
      "Epoch 1/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.3253 - binary_accuracy: 0.8793\n",
      "Epoch 2/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.2083 - binary_accuracy: 0.9173\n",
      "Epoch 3/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1748 - binary_accuracy: 0.9364\n",
      "Epoch 4/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1507 - binary_accuracy: 0.9493\n",
      "Epoch 5/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1334 - binary_accuracy: 0.9560\n",
      "Epoch 6/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1214 - binary_accuracy: 0.9616\n",
      "Epoch 7/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1131 - binary_accuracy: 0.9638\n",
      "Epoch 8/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1060 - binary_accuracy: 0.9669\n",
      "Epoch 9/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1004 - binary_accuracy: 0.9682\n",
      "Epoch 10/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0962 - binary_accuracy: 0.9698\n",
      "Epoch 11/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0931 - binary_accuracy: 0.9707\n",
      "Epoch 12/100\n",
      "450/450 [==============================] - 0s 998us/step - loss: 0.0898 - binary_accuracy: 0.9733\n",
      "Epoch 13/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0880 - binary_accuracy: 0.9720\n",
      "Epoch 14/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0857 - binary_accuracy: 0.9738\n",
      "Epoch 15/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0843 - binary_accuracy: 0.9729\n",
      "Epoch 16/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0833 - binary_accuracy: 0.9742\n",
      "Epoch 17/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0812 - binary_accuracy: 0.9747\n",
      "Epoch 18/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0805 - binary_accuracy: 0.9736\n",
      "Epoch 19/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0797 - binary_accuracy: 0.9729\n",
      "Epoch 20/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0786 - binary_accuracy: 0.9751\n",
      "Epoch 21/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0772 - binary_accuracy: 0.9749\n",
      "Epoch 22/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0773 - binary_accuracy: 0.9751\n",
      "Epoch 23/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0760 - binary_accuracy: 0.9762\n",
      "Epoch 24/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0762 - binary_accuracy: 0.9762\n",
      "Epoch 25/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0754 - binary_accuracy: 0.9753\n",
      "Epoch 26/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0750 - binary_accuracy: 0.9749\n",
      "Epoch 27/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0746 - binary_accuracy: 0.9756\n",
      "Epoch 28/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0745 - binary_accuracy: 0.9740\n",
      "Epoch 29/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0738 - binary_accuracy: 0.9753\n",
      "Epoch 30/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0733 - binary_accuracy: 0.9753\n",
      "Epoch 31/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0729 - binary_accuracy: 0.9758\n",
      "Epoch 32/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0725 - binary_accuracy: 0.9764\n",
      "Epoch 33/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0722 - binary_accuracy: 0.9758\n",
      "Epoch 34/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0717 - binary_accuracy: 0.9762\n",
      "Epoch 35/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0718 - binary_accuracy: 0.9767\n",
      "Epoch 36/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0712 - binary_accuracy: 0.9764\n",
      "Epoch 37/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0712 - binary_accuracy: 0.9756\n",
      "Epoch 38/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0711 - binary_accuracy: 0.9756\n",
      "Epoch 39/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0713 - binary_accuracy: 0.9769\n",
      "Epoch 40/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0699 - binary_accuracy: 0.9767\n",
      "Epoch 41/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0706 - binary_accuracy: 0.9749\n",
      "Epoch 42/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0704 - binary_accuracy: 0.9769\n",
      "Epoch 43/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0696 - binary_accuracy: 0.9751\n",
      "Epoch 44/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0698 - binary_accuracy: 0.9769\n",
      "Epoch 45/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0693 - binary_accuracy: 0.9771\n",
      "Epoch 46/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0694 - binary_accuracy: 0.9762\n",
      "Epoch 47/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0693 - binary_accuracy: 0.9767\n",
      "Epoch 48/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0686 - binary_accuracy: 0.9778\n",
      "Epoch 49/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0685 - binary_accuracy: 0.9764\n",
      "Epoch 50/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0684 - binary_accuracy: 0.9760\n",
      "Epoch 51/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0684 - binary_accuracy: 0.9762\n",
      "Epoch 52/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0682 - binary_accuracy: 0.9780\n",
      "Epoch 53/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0679 - binary_accuracy: 0.9776\n",
      "Epoch 54/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0677 - binary_accuracy: 0.9773\n",
      "Epoch 55/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0676 - binary_accuracy: 0.9789\n",
      "Epoch 56/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0677 - binary_accuracy: 0.9780\n",
      "Epoch 57/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0668 - binary_accuracy: 0.9780\n",
      "Epoch 58/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0672 - binary_accuracy: 0.9773\n",
      "Epoch 59/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0668 - binary_accuracy: 0.9784\n",
      "Epoch 60/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0666 - binary_accuracy: 0.9773\n",
      "Epoch 61/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0671 - binary_accuracy: 0.9773\n",
      "Epoch 62/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0662 - binary_accuracy: 0.9767\n",
      "Epoch 63/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0667 - binary_accuracy: 0.9771\n",
      "Epoch 64/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0663 - binary_accuracy: 0.9773\n",
      "Epoch 65/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0660 - binary_accuracy: 0.9782\n",
      "Epoch 66/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0660 - binary_accuracy: 0.9780\n",
      "Epoch 67/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0661 - binary_accuracy: 0.9776\n",
      "Epoch 68/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0657 - binary_accuracy: 0.9787\n",
      "Epoch 69/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0656 - binary_accuracy: 0.9780\n",
      "Epoch 70/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0657 - binary_accuracy: 0.9784\n",
      "Epoch 71/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0656 - binary_accuracy: 0.9776\n",
      "Epoch 72/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0647 - binary_accuracy: 0.9780\n",
      "Epoch 73/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0652 - binary_accuracy: 0.9773\n",
      "Epoch 74/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0653 - binary_accuracy: 0.9773\n",
      "Epoch 75/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0652 - binary_accuracy: 0.9778\n",
      "Epoch 76/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0648 - binary_accuracy: 0.9780\n",
      "Epoch 77/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0642 - binary_accuracy: 0.9782\n",
      "Epoch 78/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0646 - binary_accuracy: 0.9784\n",
      "Epoch 79/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0645 - binary_accuracy: 0.9782\n",
      "Epoch 80/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0646 - binary_accuracy: 0.9769\n",
      "Epoch 81/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0647 - binary_accuracy: 0.9773\n",
      "Epoch 82/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0641 - binary_accuracy: 0.9778\n",
      "Epoch 83/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0641 - binary_accuracy: 0.9773\n",
      "Epoch 84/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0637 - binary_accuracy: 0.9784\n",
      "Epoch 85/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0641 - binary_accuracy: 0.9784\n",
      "Epoch 86/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0638 - binary_accuracy: 0.9789\n",
      "Epoch 87/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0640 - binary_accuracy: 0.9776\n",
      "Epoch 88/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0636 - binary_accuracy: 0.9793\n",
      "Epoch 89/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0634 - binary_accuracy: 0.9793\n",
      "Epoch 90/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0629 - binary_accuracy: 0.9778\n",
      "Epoch 91/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0634 - binary_accuracy: 0.9787\n",
      "Epoch 92/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0635 - binary_accuracy: 0.9798\n",
      "Epoch 93/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0637 - binary_accuracy: 0.9787\n",
      "Epoch 94/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0632 - binary_accuracy: 0.9787\n",
      "Epoch 95/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0630 - binary_accuracy: 0.9791\n",
      "Epoch 96/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0628 - binary_accuracy: 0.9784\n",
      "Epoch 97/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0631 - binary_accuracy: 0.9791\n",
      "Epoch 98/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0629 - binary_accuracy: 0.9784\n",
      "Epoch 99/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0629 - binary_accuracy: 0.9780\n",
      "Epoch 100/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0628 - binary_accuracy: 0.9791\n",
      "Epoch 1/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.3437 - binary_accuracy: 0.8984\n",
      "Epoch 2/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.2186 - binary_accuracy: 0.9200\n",
      "Epoch 3/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1860 - binary_accuracy: 0.9404\n",
      "Epoch 4/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1655 - binary_accuracy: 0.9493\n",
      "Epoch 5/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1500 - binary_accuracy: 0.9580\n",
      "Epoch 6/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1382 - binary_accuracy: 0.9618\n",
      "Epoch 7/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1292 - binary_accuracy: 0.9647\n",
      "Epoch 8/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1217 - binary_accuracy: 0.9664\n",
      "Epoch 9/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1162 - binary_accuracy: 0.9671\n",
      "Epoch 10/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1112 - binary_accuracy: 0.9678\n",
      "Epoch 11/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1071 - binary_accuracy: 0.9700\n",
      "Epoch 12/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1042 - binary_accuracy: 0.9704\n",
      "Epoch 13/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1017 - binary_accuracy: 0.9696\n",
      "Epoch 14/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0979 - binary_accuracy: 0.9724\n",
      "Epoch 15/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0960 - binary_accuracy: 0.9720\n",
      "Epoch 16/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0947 - binary_accuracy: 0.9711\n",
      "Epoch 17/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0928 - binary_accuracy: 0.9733\n",
      "Epoch 18/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0913 - binary_accuracy: 0.9720\n",
      "Epoch 19/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0897 - binary_accuracy: 0.9742\n",
      "Epoch 20/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0888 - binary_accuracy: 0.9736\n",
      "Epoch 21/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0875 - binary_accuracy: 0.9731\n",
      "Epoch 22/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0869 - binary_accuracy: 0.9736\n",
      "Epoch 23/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0863 - binary_accuracy: 0.9747\n",
      "Epoch 24/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0851 - binary_accuracy: 0.9742\n",
      "Epoch 25/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0838 - binary_accuracy: 0.9740\n",
      "Epoch 26/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0834 - binary_accuracy: 0.9753\n",
      "Epoch 27/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0828 - binary_accuracy: 0.9749\n",
      "Epoch 28/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0817 - binary_accuracy: 0.9753\n",
      "Epoch 29/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0811 - binary_accuracy: 0.9762\n",
      "Epoch 30/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0805 - binary_accuracy: 0.9758\n",
      "Epoch 31/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0802 - binary_accuracy: 0.9764\n",
      "Epoch 32/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0797 - binary_accuracy: 0.9773\n",
      "Epoch 33/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0791 - binary_accuracy: 0.9764\n",
      "Epoch 34/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0786 - binary_accuracy: 0.9776\n",
      "Epoch 35/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0782 - binary_accuracy: 0.9760\n",
      "Epoch 36/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0776 - binary_accuracy: 0.9771\n",
      "Epoch 37/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0775 - binary_accuracy: 0.9762\n",
      "Epoch 38/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0770 - binary_accuracy: 0.9771\n",
      "Epoch 39/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0763 - binary_accuracy: 0.9780\n",
      "Epoch 40/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0761 - binary_accuracy: 0.9771\n",
      "Epoch 41/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0758 - binary_accuracy: 0.9773\n",
      "Epoch 42/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0755 - binary_accuracy: 0.9793\n",
      "Epoch 43/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0752 - binary_accuracy: 0.9787\n",
      "Epoch 44/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0748 - binary_accuracy: 0.9793\n",
      "Epoch 45/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0743 - binary_accuracy: 0.9776\n",
      "Epoch 46/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0736 - binary_accuracy: 0.9787\n",
      "Epoch 47/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0740 - binary_accuracy: 0.9791\n",
      "Epoch 48/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0737 - binary_accuracy: 0.9784\n",
      "Epoch 49/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0730 - binary_accuracy: 0.9778\n",
      "Epoch 50/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0734 - binary_accuracy: 0.9780\n",
      "Epoch 51/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0725 - binary_accuracy: 0.9784\n",
      "Epoch 52/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0714 - binary_accuracy: 0.9796\n",
      "Epoch 53/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0723 - binary_accuracy: 0.9773\n",
      "Epoch 54/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0721 - binary_accuracy: 0.9776\n",
      "Epoch 55/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0719 - binary_accuracy: 0.9793\n",
      "Epoch 56/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0714 - binary_accuracy: 0.9787\n",
      "Epoch 57/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0710 - binary_accuracy: 0.9787\n",
      "Epoch 58/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0709 - binary_accuracy: 0.9793\n",
      "Epoch 59/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0707 - binary_accuracy: 0.9800\n",
      "Epoch 60/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0705 - binary_accuracy: 0.9791\n",
      "Epoch 61/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0703 - binary_accuracy: 0.9796\n",
      "Epoch 62/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0701 - binary_accuracy: 0.9811\n",
      "Epoch 63/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0698 - binary_accuracy: 0.9791\n",
      "Epoch 64/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0700 - binary_accuracy: 0.9798\n",
      "Epoch 65/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0701 - binary_accuracy: 0.9789\n",
      "Epoch 66/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0693 - binary_accuracy: 0.9789\n",
      "Epoch 67/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0689 - binary_accuracy: 0.9804\n",
      "Epoch 68/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0688 - binary_accuracy: 0.9804\n",
      "Epoch 69/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0688 - binary_accuracy: 0.9798\n",
      "Epoch 70/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0689 - binary_accuracy: 0.9804\n",
      "Epoch 71/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0685 - binary_accuracy: 0.9791\n",
      "Epoch 72/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0680 - binary_accuracy: 0.9800\n",
      "Epoch 73/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0683 - binary_accuracy: 0.9807\n",
      "Epoch 74/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0678 - binary_accuracy: 0.9807\n",
      "Epoch 75/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0681 - binary_accuracy: 0.9802\n",
      "Epoch 76/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0677 - binary_accuracy: 0.9796\n",
      "Epoch 77/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0676 - binary_accuracy: 0.9796\n",
      "Epoch 78/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0670 - binary_accuracy: 0.9802\n",
      "Epoch 79/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0672 - binary_accuracy: 0.9804\n",
      "Epoch 80/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0671 - binary_accuracy: 0.9807\n",
      "Epoch 81/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0668 - binary_accuracy: 0.9800\n",
      "Epoch 82/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0665 - binary_accuracy: 0.9796\n",
      "Epoch 83/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0668 - binary_accuracy: 0.9798\n",
      "Epoch 84/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0663 - binary_accuracy: 0.9791\n",
      "Epoch 85/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0664 - binary_accuracy: 0.9802\n",
      "Epoch 86/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0663 - binary_accuracy: 0.9807\n",
      "Epoch 87/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0662 - binary_accuracy: 0.9807\n",
      "Epoch 88/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0658 - binary_accuracy: 0.9811\n",
      "Epoch 89/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0662 - binary_accuracy: 0.9811\n",
      "Epoch 90/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0657 - binary_accuracy: 0.9813\n",
      "Epoch 91/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0656 - binary_accuracy: 0.9818\n",
      "Epoch 92/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0658 - binary_accuracy: 0.9804\n",
      "Epoch 93/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0653 - binary_accuracy: 0.9804\n",
      "Epoch 94/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0656 - binary_accuracy: 0.9804\n",
      "Epoch 95/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0653 - binary_accuracy: 0.9800\n",
      "Epoch 96/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0648 - binary_accuracy: 0.9804\n",
      "Epoch 97/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0648 - binary_accuracy: 0.9809\n",
      "Epoch 98/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0647 - binary_accuracy: 0.9811\n",
      "Epoch 99/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0646 - binary_accuracy: 0.9824\n",
      "Epoch 100/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0651 - binary_accuracy: 0.9804\n",
      "Epoch 1/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.3096 - binary_accuracy: 0.9002\n",
      "Epoch 2/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.2154 - binary_accuracy: 0.9104\n",
      "Epoch 3/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1810 - binary_accuracy: 0.9300\n",
      "Epoch 4/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1550 - binary_accuracy: 0.9460\n",
      "Epoch 5/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1365 - binary_accuracy: 0.9542\n",
      "Epoch 6/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1236 - binary_accuracy: 0.9600\n",
      "Epoch 7/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1149 - binary_accuracy: 0.9629\n",
      "Epoch 8/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1078 - binary_accuracy: 0.9664\n",
      "Epoch 9/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1034 - binary_accuracy: 0.9660\n",
      "Epoch 10/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0985 - binary_accuracy: 0.9678\n",
      "Epoch 11/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0953 - binary_accuracy: 0.9693\n",
      "Epoch 12/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0921 - binary_accuracy: 0.9709\n",
      "Epoch 13/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0896 - binary_accuracy: 0.9700\n",
      "Epoch 14/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0881 - binary_accuracy: 0.9711\n",
      "Epoch 15/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0864 - binary_accuracy: 0.9707\n",
      "Epoch 16/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0842 - binary_accuracy: 0.9727\n",
      "Epoch 17/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0840 - binary_accuracy: 0.9713\n",
      "Epoch 18/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0824 - binary_accuracy: 0.9729\n",
      "Epoch 19/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0815 - binary_accuracy: 0.9727\n",
      "Epoch 20/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0813 - binary_accuracy: 0.9733\n",
      "Epoch 21/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0799 - binary_accuracy: 0.9729\n",
      "Epoch 22/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0799 - binary_accuracy: 0.9731\n",
      "Epoch 23/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0790 - binary_accuracy: 0.9731\n",
      "Epoch 24/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0784 - binary_accuracy: 0.9729\n",
      "Epoch 25/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0775 - binary_accuracy: 0.9738\n",
      "Epoch 26/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0773 - binary_accuracy: 0.9742\n",
      "Epoch 27/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0765 - binary_accuracy: 0.9731\n",
      "Epoch 28/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0766 - binary_accuracy: 0.9756\n",
      "Epoch 29/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0765 - binary_accuracy: 0.9740\n",
      "Epoch 30/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0756 - binary_accuracy: 0.9742\n",
      "Epoch 31/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0750 - binary_accuracy: 0.9758\n",
      "Epoch 32/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0749 - binary_accuracy: 0.9742\n",
      "Epoch 33/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0737 - binary_accuracy: 0.9749\n",
      "Epoch 34/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0735 - binary_accuracy: 0.9767\n",
      "Epoch 35/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0729 - binary_accuracy: 0.9767\n",
      "Epoch 36/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0720 - binary_accuracy: 0.9758\n",
      "Epoch 37/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0709 - binary_accuracy: 0.9773\n",
      "Epoch 38/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0705 - binary_accuracy: 0.9776\n",
      "Epoch 39/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0702 - binary_accuracy: 0.9764\n",
      "Epoch 40/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0695 - binary_accuracy: 0.9769\n",
      "Epoch 41/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0681 - binary_accuracy: 0.9789\n",
      "Epoch 42/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0683 - binary_accuracy: 0.9769\n",
      "Epoch 43/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0677 - binary_accuracy: 0.9778\n",
      "Epoch 44/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0672 - binary_accuracy: 0.9780\n",
      "Epoch 45/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0665 - binary_accuracy: 0.9780\n",
      "Epoch 46/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0658 - binary_accuracy: 0.9796\n",
      "Epoch 47/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0658 - binary_accuracy: 0.9784\n",
      "Epoch 48/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0655 - binary_accuracy: 0.9787\n",
      "Epoch 49/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0648 - binary_accuracy: 0.9791\n",
      "Epoch 50/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0642 - binary_accuracy: 0.9780\n",
      "Epoch 51/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0645 - binary_accuracy: 0.9789\n",
      "Epoch 52/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0645 - binary_accuracy: 0.9791\n",
      "Epoch 53/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0641 - binary_accuracy: 0.9778\n",
      "Epoch 54/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0626 - binary_accuracy: 0.9800\n",
      "Epoch 55/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0638 - binary_accuracy: 0.9773\n",
      "Epoch 56/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0630 - binary_accuracy: 0.9778\n",
      "Epoch 57/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0632 - binary_accuracy: 0.9778\n",
      "Epoch 58/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0629 - binary_accuracy: 0.9778\n",
      "Epoch 59/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0624 - binary_accuracy: 0.9793\n",
      "Epoch 60/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0621 - binary_accuracy: 0.9776\n",
      "Epoch 61/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0617 - binary_accuracy: 0.9782\n",
      "Epoch 62/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0619 - binary_accuracy: 0.9789\n",
      "Epoch 63/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0616 - binary_accuracy: 0.9784\n",
      "Epoch 64/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0610 - binary_accuracy: 0.9787\n",
      "Epoch 65/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0614 - binary_accuracy: 0.9791\n",
      "Epoch 66/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0609 - binary_accuracy: 0.9791\n",
      "Epoch 67/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0610 - binary_accuracy: 0.9791\n",
      "Epoch 68/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0608 - binary_accuracy: 0.9778\n",
      "Epoch 69/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0610 - binary_accuracy: 0.9804\n",
      "Epoch 70/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0603 - binary_accuracy: 0.9789\n",
      "Epoch 71/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0604 - binary_accuracy: 0.9791\n",
      "Epoch 72/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0608 - binary_accuracy: 0.9791\n",
      "Epoch 73/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0596 - binary_accuracy: 0.9809\n",
      "Epoch 74/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0604 - binary_accuracy: 0.9793\n",
      "Epoch 75/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0601 - binary_accuracy: 0.9784\n",
      "Epoch 76/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0596 - binary_accuracy: 0.9793\n",
      "Epoch 77/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0595 - binary_accuracy: 0.9787\n",
      "Epoch 78/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0586 - binary_accuracy: 0.9793\n",
      "Epoch 79/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0593 - binary_accuracy: 0.9784\n",
      "Epoch 80/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0582 - binary_accuracy: 0.9802\n",
      "Epoch 81/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0589 - binary_accuracy: 0.9800\n",
      "Epoch 82/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0587 - binary_accuracy: 0.9793\n",
      "Epoch 83/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0584 - binary_accuracy: 0.9796\n",
      "Epoch 84/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0591 - binary_accuracy: 0.9793\n",
      "Epoch 85/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0581 - binary_accuracy: 0.9800\n",
      "Epoch 86/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0581 - binary_accuracy: 0.9802\n",
      "Epoch 87/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0578 - binary_accuracy: 0.9804\n",
      "Epoch 88/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0579 - binary_accuracy: 0.9804\n",
      "Epoch 89/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0578 - binary_accuracy: 0.9793\n",
      "Epoch 90/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0580 - binary_accuracy: 0.9811\n",
      "Epoch 91/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0571 - binary_accuracy: 0.9811\n",
      "Epoch 92/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0572 - binary_accuracy: 0.9802\n",
      "Epoch 93/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0576 - binary_accuracy: 0.9807\n",
      "Epoch 94/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0576 - binary_accuracy: 0.9800\n",
      "Epoch 95/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0573 - binary_accuracy: 0.9793\n",
      "Epoch 96/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0566 - binary_accuracy: 0.9818\n",
      "Epoch 97/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0564 - binary_accuracy: 0.9800\n",
      "Epoch 98/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0577 - binary_accuracy: 0.9800\n",
      "Epoch 99/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0568 - binary_accuracy: 0.9802\n",
      "Epoch 100/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0564 - binary_accuracy: 0.9804\n",
      "Epoch 1/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.6176 - binary_accuracy: 0.8707\n",
      "Epoch 2/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.4949 - binary_accuracy: 0.9009\n",
      "Epoch 3/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.4090 - binary_accuracy: 0.9062\n",
      "Epoch 4/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.3456 - binary_accuracy: 0.9209\n",
      "Epoch 5/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.2978 - binary_accuracy: 0.9271\n",
      "Epoch 6/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.2624 - binary_accuracy: 0.9347\n",
      "Epoch 7/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.2353 - binary_accuracy: 0.9373\n",
      "Epoch 8/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.2142 - binary_accuracy: 0.9396\n",
      "Epoch 9/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1981 - binary_accuracy: 0.9409\n",
      "Epoch 10/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1854 - binary_accuracy: 0.9424\n",
      "Epoch 11/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1752 - binary_accuracy: 0.9433\n",
      "Epoch 12/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1674 - binary_accuracy: 0.9453\n",
      "Epoch 13/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1613 - binary_accuracy: 0.9462\n",
      "Epoch 14/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1563 - binary_accuracy: 0.9469\n",
      "Epoch 15/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1523 - binary_accuracy: 0.9471\n",
      "Epoch 16/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1489 - binary_accuracy: 0.9493\n",
      "Epoch 17/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1462 - binary_accuracy: 0.9491\n",
      "Epoch 18/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1442 - binary_accuracy: 0.9504\n",
      "Epoch 19/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1421 - binary_accuracy: 0.9509\n",
      "Epoch 20/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1407 - binary_accuracy: 0.9504\n",
      "Epoch 21/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1394 - binary_accuracy: 0.9511\n",
      "Epoch 22/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1383 - binary_accuracy: 0.9504\n",
      "Epoch 23/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1374 - binary_accuracy: 0.9518\n",
      "Epoch 24/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1366 - binary_accuracy: 0.9518\n",
      "Epoch 25/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1359 - binary_accuracy: 0.9518\n",
      "Epoch 26/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1353 - binary_accuracy: 0.9511\n",
      "Epoch 27/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1346 - binary_accuracy: 0.9527\n",
      "Epoch 28/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1345 - binary_accuracy: 0.9520\n",
      "Epoch 29/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1343 - binary_accuracy: 0.9502\n",
      "Epoch 30/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1335 - binary_accuracy: 0.9524\n",
      "Epoch 31/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1334 - binary_accuracy: 0.9516\n",
      "Epoch 32/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1331 - binary_accuracy: 0.9511\n",
      "Epoch 33/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1326 - binary_accuracy: 0.9513\n",
      "Epoch 34/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1326 - binary_accuracy: 0.9522\n",
      "Epoch 35/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1322 - binary_accuracy: 0.9520\n",
      "Epoch 36/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1323 - binary_accuracy: 0.9511\n",
      "Epoch 37/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1321 - binary_accuracy: 0.9520\n",
      "Epoch 38/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1319 - binary_accuracy: 0.9520\n",
      "Epoch 39/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1317 - binary_accuracy: 0.9529\n",
      "Epoch 40/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1316 - binary_accuracy: 0.9520\n",
      "Epoch 41/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1319 - binary_accuracy: 0.9524\n",
      "Epoch 42/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1311 - binary_accuracy: 0.9522\n",
      "Epoch 43/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1315 - binary_accuracy: 0.9529\n",
      "Epoch 44/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1315 - binary_accuracy: 0.9520\n",
      "Epoch 45/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1312 - binary_accuracy: 0.9513\n",
      "Epoch 46/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1311 - binary_accuracy: 0.9511\n",
      "Epoch 47/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1313 - binary_accuracy: 0.9520\n",
      "Epoch 48/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1310 - binary_accuracy: 0.9522\n",
      "Epoch 49/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1310 - binary_accuracy: 0.9520\n",
      "Epoch 50/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1307 - binary_accuracy: 0.9516\n",
      "Epoch 51/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1309 - binary_accuracy: 0.9509\n",
      "Epoch 52/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1307 - binary_accuracy: 0.9529\n",
      "Epoch 53/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1306 - binary_accuracy: 0.9507\n",
      "Epoch 54/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1308 - binary_accuracy: 0.9516\n",
      "Epoch 55/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1309 - binary_accuracy: 0.9516\n",
      "Epoch 56/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1305 - binary_accuracy: 0.9536\n",
      "Epoch 57/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1305 - binary_accuracy: 0.9529\n",
      "Epoch 58/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1304 - binary_accuracy: 0.9524\n",
      "Epoch 59/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1305 - binary_accuracy: 0.9513\n",
      "Epoch 60/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1304 - binary_accuracy: 0.9524\n",
      "Epoch 61/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1305 - binary_accuracy: 0.9527\n",
      "Epoch 62/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1304 - binary_accuracy: 0.9518\n",
      "Epoch 63/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1307 - binary_accuracy: 0.9522\n",
      "Epoch 64/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1302 - binary_accuracy: 0.9527\n",
      "Epoch 65/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1304 - binary_accuracy: 0.9522\n",
      "Epoch 66/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1304 - binary_accuracy: 0.9518\n",
      "Epoch 67/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1303 - binary_accuracy: 0.9522\n",
      "Epoch 68/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1304 - binary_accuracy: 0.9527\n",
      "Epoch 69/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1301 - binary_accuracy: 0.9509\n",
      "Epoch 70/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1302 - binary_accuracy: 0.9518\n",
      "Epoch 71/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1305 - binary_accuracy: 0.9516\n",
      "Epoch 72/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1303 - binary_accuracy: 0.9518\n",
      "Epoch 73/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1305 - binary_accuracy: 0.9529\n",
      "Epoch 74/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1303 - binary_accuracy: 0.9518\n",
      "Epoch 75/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1303 - binary_accuracy: 0.9522\n",
      "Epoch 76/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1305 - binary_accuracy: 0.9529\n",
      "Epoch 77/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1304 - binary_accuracy: 0.9527\n",
      "Epoch 78/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1303 - binary_accuracy: 0.9509\n",
      "Epoch 79/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1303 - binary_accuracy: 0.9513\n",
      "Epoch 80/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1301 - binary_accuracy: 0.9518\n",
      "Epoch 81/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1301 - binary_accuracy: 0.9524\n",
      "Epoch 82/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1299 - binary_accuracy: 0.9524\n",
      "Epoch 83/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1301 - binary_accuracy: 0.9513\n",
      "Epoch 84/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1299 - binary_accuracy: 0.9524\n",
      "Epoch 85/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1303 - binary_accuracy: 0.9522\n",
      "Epoch 86/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1301 - binary_accuracy: 0.9518\n",
      "Epoch 87/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1302 - binary_accuracy: 0.9516\n",
      "Epoch 88/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1303 - binary_accuracy: 0.9516\n",
      "Epoch 89/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1302 - binary_accuracy: 0.9529\n",
      "Epoch 90/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1300 - binary_accuracy: 0.9518\n",
      "Epoch 91/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1301 - binary_accuracy: 0.9511\n",
      "Epoch 92/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1302 - binary_accuracy: 0.9520\n",
      "Epoch 93/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1299 - binary_accuracy: 0.9527\n",
      "Epoch 94/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1302 - binary_accuracy: 0.9522\n",
      "Epoch 95/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1302 - binary_accuracy: 0.9516\n",
      "Epoch 96/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1299 - binary_accuracy: 0.9527\n",
      "Epoch 97/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1300 - binary_accuracy: 0.9509\n",
      "Epoch 98/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1303 - binary_accuracy: 0.9518\n",
      "Epoch 99/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1297 - binary_accuracy: 0.9527\n",
      "Epoch 100/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1304 - binary_accuracy: 0.9511\n"
     ]
    }
   ],
   "source": [
    "modelo_cv = KerasClassifier(build_fn=RedeNeural, epochs=100, batch_size=10)\n",
    "resultados = cross_val_score(estimator = modelo_cv, X = X2, y=y, cv=10, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rOdzDfURvs2H"
   },
   "source": [
    "Vemos os 10 resultados desse processo abaixo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "id": "tNJb8wci7PaY",
    "outputId": "e442945a-167b-489b-9e3d-344fbf40015b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.976, 0.984, 0.984, 0.974, 0.976, 0.972, 0.976, 0.976, 0.988,\n",
       "       0.952])"
      ]
     },
     "execution_count": 26,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-IB9O6Pqog_R"
   },
   "source": [
    "A média da acurácia que obtivemos do processo de validação cruzada pode ser vista abaixo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "gov6LH7Q7Phr",
    "outputId": "ded86f49-444d-4a41-f1d2-eb0a41e89b5a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9757999999999999"
      ]
     },
     "execution_count": 27,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultados.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6sSPvqNUu3f5"
   },
   "source": [
    "O desvio padrão dos resultados da validação cruzada vai nos mostrar se há ou não evidência para o problema de *overfitting*, que é quando o modelo está sobreajustado, ou seja, ao invés de aprender e encontrar padrões nos dados o modelo está \"decorando\" os dados e isso pode gerar erros quando o modelo for aplicado para outros dados que não foram aplicados ao modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "X54fCdlq7PcD",
    "outputId": "49661e87-1f45-4aa9-cbc6-1d55b97c09d5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.009314504817756022"
      ]
     },
     "execution_count": 28,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultados.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1WjaG7r4nQWJ"
   },
   "source": [
    "## Testes\n",
    "\n",
    "Vamos realizar mais alguns testes para a rede neural inserindo outros componentes, como outras camadas ou zerando alguns neurônios das camadas de entrada e camadas ocultas.\n",
    "\n",
    "### Teste 1\n",
    "\n",
    "Vamos criar novamente nossa rede neural, mas vamos inserir uma outra camada oculta, que idêntica a camada oculta anterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "A9oxURZ17POW",
    "outputId": "a82b0a7b-bc99-42c0-87d3-76cf81efc913"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.4012 - binary_accuracy: 0.9040\n",
      "Epoch 2/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.2344 - binary_accuracy: 0.9062\n",
      "Epoch 3/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.1986 - binary_accuracy: 0.9062\n",
      "Epoch 4/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.1773 - binary_accuracy: 0.9062\n",
      "Epoch 5/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.1597 - binary_accuracy: 0.9062\n",
      "Epoch 6/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.1449 - binary_accuracy: 0.9062\n",
      "Epoch 7/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.1326 - binary_accuracy: 0.9413\n",
      "Epoch 8/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.1247 - binary_accuracy: 0.9617\n",
      "Epoch 9/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.1178 - binary_accuracy: 0.9630\n",
      "Epoch 10/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.1117 - binary_accuracy: 0.9665\n",
      "Epoch 11/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.1061 - binary_accuracy: 0.9682\n",
      "Epoch 12/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.0975 - binary_accuracy: 0.9725\n",
      "Epoch 13/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.0896 - binary_accuracy: 0.9728\n",
      "Epoch 14/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.0842 - binary_accuracy: 0.9737\n",
      "Epoch 15/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.0792 - binary_accuracy: 0.9758\n",
      "Epoch 16/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.0768 - binary_accuracy: 0.9765\n",
      "Epoch 17/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.0757 - binary_accuracy: 0.9762\n",
      "Epoch 18/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.0727 - binary_accuracy: 0.9772\n",
      "Epoch 19/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.0717 - binary_accuracy: 0.9785\n",
      "Epoch 20/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.0703 - binary_accuracy: 0.9783\n",
      "Epoch 21/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.0693 - binary_accuracy: 0.9783\n",
      "Epoch 22/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.0677 - binary_accuracy: 0.9783\n",
      "Epoch 23/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.0677 - binary_accuracy: 0.9793\n",
      "Epoch 24/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.0670 - binary_accuracy: 0.9800\n",
      "Epoch 25/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.0659 - binary_accuracy: 0.9793\n",
      "Epoch 26/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.0657 - binary_accuracy: 0.9793\n",
      "Epoch 27/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.0659 - binary_accuracy: 0.9783\n",
      "Epoch 28/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.0650 - binary_accuracy: 0.9803\n",
      "Epoch 29/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.0640 - binary_accuracy: 0.9800\n",
      "Epoch 30/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.0653 - binary_accuracy: 0.9815\n",
      "Epoch 31/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.0640 - binary_accuracy: 0.9812\n",
      "Epoch 32/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.0631 - binary_accuracy: 0.9805\n",
      "Epoch 33/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.0642 - binary_accuracy: 0.9797\n",
      "Epoch 34/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.0634 - binary_accuracy: 0.9815\n",
      "Epoch 35/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.0633 - binary_accuracy: 0.9812\n",
      "Epoch 36/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.0632 - binary_accuracy: 0.9803\n",
      "Epoch 37/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.0630 - binary_accuracy: 0.9818\n",
      "Epoch 38/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.0625 - binary_accuracy: 0.9795\n",
      "Epoch 39/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.0624 - binary_accuracy: 0.9808\n",
      "Epoch 40/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.0621 - binary_accuracy: 0.9820\n",
      "Epoch 41/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.0614 - binary_accuracy: 0.9820\n",
      "Epoch 42/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.0616 - binary_accuracy: 0.9818\n",
      "Epoch 43/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.0611 - binary_accuracy: 0.9808\n",
      "Epoch 44/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.0596 - binary_accuracy: 0.9827\n",
      "Epoch 45/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.0603 - binary_accuracy: 0.9818\n",
      "Epoch 46/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.0601 - binary_accuracy: 0.9815\n",
      "Epoch 47/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.0603 - binary_accuracy: 0.9815\n",
      "Epoch 48/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.0599 - binary_accuracy: 0.9815\n",
      "Epoch 49/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.0594 - binary_accuracy: 0.9825\n",
      "Epoch 50/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.0603 - binary_accuracy: 0.9797\n",
      "Epoch 51/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.0594 - binary_accuracy: 0.9815\n",
      "Epoch 52/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.0594 - binary_accuracy: 0.9820\n",
      "Epoch 53/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.0590 - binary_accuracy: 0.9820\n",
      "Epoch 54/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.0592 - binary_accuracy: 0.9820\n",
      "Epoch 55/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.0593 - binary_accuracy: 0.9825\n",
      "Epoch 56/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.0589 - binary_accuracy: 0.9822\n",
      "Epoch 57/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.0588 - binary_accuracy: 0.9822\n",
      "Epoch 58/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.0577 - binary_accuracy: 0.9825\n",
      "Epoch 59/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.0578 - binary_accuracy: 0.9810\n",
      "Epoch 60/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.0582 - binary_accuracy: 0.9822\n",
      "Epoch 61/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.0580 - binary_accuracy: 0.9830\n",
      "Epoch 62/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.0585 - binary_accuracy: 0.9815\n",
      "Epoch 63/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.0582 - binary_accuracy: 0.9825\n",
      "Epoch 64/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.0572 - binary_accuracy: 0.9818\n",
      "Epoch 65/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.0576 - binary_accuracy: 0.9815\n",
      "Epoch 66/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.0572 - binary_accuracy: 0.9818\n",
      "Epoch 67/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.0575 - binary_accuracy: 0.9825\n",
      "Epoch 68/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.0570 - binary_accuracy: 0.9827\n",
      "Epoch 69/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.0573 - binary_accuracy: 0.9825\n",
      "Epoch 70/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.0565 - binary_accuracy: 0.9822\n",
      "Epoch 71/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.0570 - binary_accuracy: 0.9820\n",
      "Epoch 72/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.0561 - binary_accuracy: 0.9837\n",
      "Epoch 73/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.0570 - binary_accuracy: 0.9830\n",
      "Epoch 74/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.0559 - binary_accuracy: 0.9825\n",
      "Epoch 75/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.0558 - binary_accuracy: 0.9833\n",
      "Epoch 76/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.0564 - binary_accuracy: 0.9835\n",
      "Epoch 77/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.0555 - binary_accuracy: 0.9827\n",
      "Epoch 78/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.0553 - binary_accuracy: 0.9833\n",
      "Epoch 79/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.0557 - binary_accuracy: 0.9840\n",
      "Epoch 80/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.0543 - binary_accuracy: 0.9840\n",
      "Epoch 81/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.0560 - binary_accuracy: 0.9835\n",
      "Epoch 82/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.0544 - binary_accuracy: 0.9843\n",
      "Epoch 83/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.0546 - binary_accuracy: 0.9830\n",
      "Epoch 84/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.0548 - binary_accuracy: 0.9830\n",
      "Epoch 85/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.0536 - binary_accuracy: 0.9837\n",
      "Epoch 86/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.0543 - binary_accuracy: 0.9837\n",
      "Epoch 87/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.0553 - binary_accuracy: 0.9822\n",
      "Epoch 88/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.0535 - binary_accuracy: 0.9847\n",
      "Epoch 89/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.0533 - binary_accuracy: 0.9852\n",
      "Epoch 90/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.0538 - binary_accuracy: 0.9835\n",
      "Epoch 91/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.0531 - binary_accuracy: 0.9835\n",
      "Epoch 92/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.0533 - binary_accuracy: 0.9833\n",
      "Epoch 93/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.0529 - binary_accuracy: 0.9843\n",
      "Epoch 94/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.0533 - binary_accuracy: 0.9827\n",
      "Epoch 95/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.0524 - binary_accuracy: 0.9860\n",
      "Epoch 96/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.0524 - binary_accuracy: 0.9847\n",
      "Epoch 97/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.0521 - binary_accuracy: 0.9845\n",
      "Epoch 98/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.0518 - binary_accuracy: 0.9850\n",
      "Epoch 99/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.0524 - binary_accuracy: 0.9837\n",
      "Epoch 100/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.0515 - binary_accuracy: 0.9855\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f0c6f8c43c8>"
      ]
     },
     "execution_count": 29,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelo1=Sequential()\n",
    "modelo1.add(Dense(units=6, activation='relu', kernel_initializer='random_uniform', input_dim=11))\n",
    "modelo1.add(Dense(units=6, activation='relu', kernel_initializer='random_uniform'))\n",
    "modelo1.add(Dense(units=1,activation='sigmoid'))\n",
    "modelo1.compile(optimizer='adam',loss='binary_crossentropy', metrics=['binary_accuracy'])\n",
    "modelo1.fit(X_treino,y_treino, batch_size=11, epochs = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iLke-IGE4rub"
   },
   "source": [
    "Vamos gerar as previsões."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LBVckrsq7PFs"
   },
   "outputs": [],
   "source": [
    "previsoes1=modelo1.predict(X_teste)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cUlZJWkO4wW1"
   },
   "source": [
    "Vamos substituir os valores que forem abaixo de 50% por zero e acima desse valor por 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mm2iVjM87PA2"
   },
   "outputs": [],
   "source": [
    "lista=[]\n",
    "for i in previsoes1:\n",
    "  if i > 0.5:\n",
    "    i=1\n",
    "  else:\n",
    "    i=0\n",
    "  lista.append(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b1oSNAQ74398"
   },
   "source": [
    "Vamos criar um *dataset* com os valores reais e nossas previsões."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 416
    },
    "id": "wqtj3RKA7O-l",
    "outputId": "9b1f649f-5e8a-4a0c-bfc0-d6b7cb317594"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Personal Loan</th>\n",
       "      <th>prev</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1501</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2586</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2653</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1055</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>705</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4711</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2313</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3214</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2732</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1926</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Personal Loan  prev\n",
       "1501              0     0\n",
       "2586              1     1\n",
       "2653              0     0\n",
       "1055              0     0\n",
       "705               0     0\n",
       "...             ...   ...\n",
       "4711              0     0\n",
       "2313              0     0\n",
       "3214              0     0\n",
       "2732              0     0\n",
       "1926              0     0\n",
       "\n",
       "[1000 rows x 2 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_teste3=y_teste\n",
    "y_teste3=pd.DataFrame(y_teste2)\n",
    "y_teste3['prev']=pd.DataFrame(lista, index=y_teste3.index)\n",
    "y_teste3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kMvFFNzY5H-g"
   },
   "source": [
    "Observando a acurácia dessa nova rede neural, vemos que foi ligeiramente melhor que o nosso modelo original."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "wxwKVpWj7O9c",
    "outputId": "d70bfdf1-4f6c-4b37-b40d-d492dbc4e540"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A acurácia do modelo de Rede Neural foi de 98.6 %\n"
     ]
    }
   ],
   "source": [
    "print('A acurácia do modelo de Rede Neural foi de',(accuracy_score(y_teste3['Personal Loan'],y_teste3['prev']))*100,'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GY2CN6Ty5Ub0"
   },
   "source": [
    "#### Matriz de confusão da nova rede neural.\n",
    "\n",
    "Vemos que essa nova rede neural conseguiu prever 4 observações, de forma correta, a mais, para a classe 0, que o modelo original, mas errou duas observações para a classe 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "id": "L3jLQmRc7O3-",
    "outputId": "c058390c-4c6e-403c-e9fb-e297668e50f9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[889   6]\n",
      " [  8  97]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_teste3['Personal Loan'],y_teste3['prev']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dLG2Gqld6arx"
   },
   "source": [
    "#### Métricas de avaliação\n",
    "\n",
    "Comparando com as métricas do modelo anterior, para a classe 0, houve uma piora na precisão e melhora no *recall*, mas o *f1-score* se manteve. Para a classe 1, o desempenho da precisão foi melhor, mas o *recall* foi um pouco menor e o *f1-score* se manteve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "id": "bEJRiI957OyT",
    "outputId": "608eaf07-9708-4795-a457-b20473f54f7e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       895\n",
      "           1       0.94      0.92      0.93       105\n",
      "\n",
      "    accuracy                           0.99      1000\n",
      "   macro avg       0.97      0.96      0.96      1000\n",
      "weighted avg       0.99      0.99      0.99      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_teste3['Personal Loan'],y_teste3['prev']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rgs7hwyW7AjB"
   },
   "source": [
    "Pesos da nossa rede neural."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 433
    },
    "id": "q47WVDoTcsjL",
    "outputId": "684175ae-6bc1-4293-b808-2f0f4c327c78"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 4.46843915e-02, -1.45944301e-02,  3.81892502e-01,\n",
       "          2.35224500e-01, -1.67724803e-01,  3.92277865e-03],\n",
       "        [-4.28952053e-02, -2.37028986e-01,  3.86557393e-02,\n",
       "         -1.62395567e-01,  1.55157939e-01,  7.93859456e-03],\n",
       "        [-1.79629344e-02, -9.45458770e-01, -8.03451300e-01,\n",
       "         -6.09801888e-01,  1.53142318e-01, -3.81053388e-02],\n",
       "        [-1.05321277e-02, -1.34191096e-01,  8.29314291e-02,\n",
       "          1.02760687e-01, -2.60580927e-01, -1.50612965e-02],\n",
       "        [ 8.91773589e-03, -4.53116536e-01, -2.44948834e-01,\n",
       "          6.93955049e-02, -6.55082171e-04,  3.04615032e-02],\n",
       "        [-4.04234938e-02,  2.19649166e-01, -1.81713864e-01,\n",
       "         -2.15410013e-02, -7.07644403e-01, -6.47586286e-02],\n",
       "        [-1.25318365e-02,  7.66835660e-02, -1.58495709e-01,\n",
       "         -1.07711209e-02,  7.22233299e-03, -1.78338066e-02],\n",
       "        [-1.07516395e-02, -2.20292613e-01,  8.54593754e-01,\n",
       "         -5.99088483e-02,  3.20303999e-02,  2.32286137e-02],\n",
       "        [-3.38172056e-02, -8.13539922e-02, -5.72557390e-01,\n",
       "         -9.01892483e-01, -2.46422276e-01,  2.57808082e-02],\n",
       "        [-7.06324577e-02,  1.16141759e-01,  2.68670350e-01,\n",
       "         -1.13777481e-01,  8.23895335e-02, -3.64441499e-02],\n",
       "        [-1.87397674e-02,  3.45455468e-01,  3.43999654e-01,\n",
       "         -2.88821667e-01,  1.23948023e-01,  4.65145428e-03]], dtype=float32),\n",
       " array([-0.04626523,  0.84154236,  0.5386394 ,  0.9492964 ,  1.3423136 ,\n",
       "        -0.01949489], dtype=float32)]"
      ]
     },
     "execution_count": 36,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelo1.layers[0].get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 260
    },
    "id": "tyafKrGBcsxC",
    "outputId": "33fce282-323c-4939-b40c-b512823f169d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-1.3545973e-02,  6.7896228e-03,  2.7769525e-02,  3.4820903e-02,\n",
       "         -2.5366103e-02,  1.5676085e-02],\n",
       "        [-8.9527345e-01,  6.6187161e-01, -1.8030968e-03, -2.3995956e-02,\n",
       "         -2.5570620e-02,  8.0352986e-01],\n",
       "        [-6.0025328e-01,  6.2593305e-01, -5.4856107e-02, -1.9539690e-02,\n",
       "         -1.9331086e-02,  6.9475007e-01],\n",
       "        [-9.3963414e-01,  3.5747012e-01, -8.4677702e-03, -3.0730296e-02,\n",
       "         -4.3778908e-02,  4.5757005e-01],\n",
       "        [-2.7314129e+00,  2.6989093e+00, -1.9008467e-02,  1.2474742e-02,\n",
       "         -1.3684966e-02,  2.8375010e+00],\n",
       "        [ 5.5488162e-03, -1.9383196e-02,  1.3830485e-02, -4.4838667e-02,\n",
       "         -3.6670588e-02, -3.7404362e-02]], dtype=float32),\n",
       " array([ 1.2249306 ,  0.0251304 , -0.01108523, -0.01680324,  0.        ,\n",
       "         0.02462866], dtype=float32)]"
      ]
     },
     "execution_count": 37,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelo1.layers[1].get_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SSRnKhxp7LgH"
   },
   "source": [
    "Agora iremos para a validação cruzada para nossa nova rede neural, vamos fazer os mesmos procedimentos que fizemos para o modelo original. Começarei criando novamente uma função que irá gerar nossa nova rede neural."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OLsyHOco7Owu"
   },
   "outputs": [],
   "source": [
    "def RedeNeural1():\n",
    "  modelo1=Sequential()\n",
    "  modelo1.add(Dense(units=6, activation='relu', kernel_initializer='random_uniform', input_dim=11))\n",
    "  modelo1.add(Dense(units=6, activation='relu', kernel_initializer='random_uniform'))\n",
    "  modelo1.add(Dense(units=1,activation='sigmoid'))\n",
    "  modelo1.compile(optimizer='adam',loss='binary_crossentropy', metrics=['binary_accuracy'])\n",
    "\n",
    "  return modelo1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2JXoQ_rP7jj4"
   },
   "source": [
    "Agora aplicaremos nossa *cross validation*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "8KTc3QkK7Opv",
    "outputId": "5a2b42b6-2804-4584-d236-40f3f89430fe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "450/450 [==============================] - 0s 963us/step - loss: 0.3299 - binary_accuracy: 0.9044\n",
      "Epoch 2/100\n",
      "450/450 [==============================] - 0s 987us/step - loss: 0.2047 - binary_accuracy: 0.9044\n",
      "Epoch 3/100\n",
      "450/450 [==============================] - 0s 965us/step - loss: 0.1895 - binary_accuracy: 0.9044\n",
      "Epoch 4/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1824 - binary_accuracy: 0.9044\n",
      "Epoch 5/100\n",
      "450/450 [==============================] - 0s 973us/step - loss: 0.1791 - binary_accuracy: 0.9044\n",
      "Epoch 6/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1762 - binary_accuracy: 0.9044\n",
      "Epoch 7/100\n",
      "450/450 [==============================] - 0s 978us/step - loss: 0.1722 - binary_accuracy: 0.9044\n",
      "Epoch 8/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1627 - binary_accuracy: 0.9044\n",
      "Epoch 9/100\n",
      "450/450 [==============================] - 0s 990us/step - loss: 0.1442 - binary_accuracy: 0.9340\n",
      "Epoch 10/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1302 - binary_accuracy: 0.9560\n",
      "Epoch 11/100\n",
      "450/450 [==============================] - 0s 959us/step - loss: 0.1189 - binary_accuracy: 0.9658\n",
      "Epoch 12/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1099 - binary_accuracy: 0.9684\n",
      "Epoch 13/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1027 - binary_accuracy: 0.9724\n",
      "Epoch 14/100\n",
      "450/450 [==============================] - 0s 964us/step - loss: 0.0959 - binary_accuracy: 0.9736\n",
      "Epoch 15/100\n",
      "450/450 [==============================] - 0s 986us/step - loss: 0.0908 - binary_accuracy: 0.9762\n",
      "Epoch 16/100\n",
      "450/450 [==============================] - 0s 986us/step - loss: 0.0871 - binary_accuracy: 0.9780\n",
      "Epoch 17/100\n",
      "450/450 [==============================] - 0s 976us/step - loss: 0.0830 - binary_accuracy: 0.9778\n",
      "Epoch 18/100\n",
      "450/450 [==============================] - 0s 971us/step - loss: 0.0797 - binary_accuracy: 0.9804\n",
      "Epoch 19/100\n",
      "450/450 [==============================] - 0s 962us/step - loss: 0.0766 - binary_accuracy: 0.9800\n",
      "Epoch 20/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0740 - binary_accuracy: 0.9804\n",
      "Epoch 21/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0715 - binary_accuracy: 0.9804\n",
      "Epoch 22/100\n",
      "450/450 [==============================] - 0s 966us/step - loss: 0.0697 - binary_accuracy: 0.9820\n",
      "Epoch 23/100\n",
      "450/450 [==============================] - 0s 983us/step - loss: 0.0685 - binary_accuracy: 0.9804\n",
      "Epoch 24/100\n",
      "450/450 [==============================] - 0s 989us/step - loss: 0.0673 - binary_accuracy: 0.9827\n",
      "Epoch 25/100\n",
      "450/450 [==============================] - 0s 990us/step - loss: 0.0659 - binary_accuracy: 0.9813\n",
      "Epoch 26/100\n",
      "450/450 [==============================] - 0s 954us/step - loss: 0.0648 - binary_accuracy: 0.9816\n",
      "Epoch 27/100\n",
      "450/450 [==============================] - 0s 991us/step - loss: 0.0645 - binary_accuracy: 0.9813\n",
      "Epoch 28/100\n",
      "450/450 [==============================] - 0s 957us/step - loss: 0.0636 - binary_accuracy: 0.9820\n",
      "Epoch 29/100\n",
      "450/450 [==============================] - 0s 962us/step - loss: 0.0622 - binary_accuracy: 0.9827\n",
      "Epoch 30/100\n",
      "450/450 [==============================] - 0s 994us/step - loss: 0.0618 - binary_accuracy: 0.9820\n",
      "Epoch 31/100\n",
      "450/450 [==============================] - 0s 984us/step - loss: 0.0614 - binary_accuracy: 0.9816\n",
      "Epoch 32/100\n",
      "450/450 [==============================] - 0s 975us/step - loss: 0.0605 - binary_accuracy: 0.9838\n",
      "Epoch 33/100\n",
      "450/450 [==============================] - 0s 985us/step - loss: 0.0606 - binary_accuracy: 0.9824\n",
      "Epoch 34/100\n",
      "450/450 [==============================] - 0s 998us/step - loss: 0.0598 - binary_accuracy: 0.9824\n",
      "Epoch 35/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0599 - binary_accuracy: 0.9816\n",
      "Epoch 36/100\n",
      "450/450 [==============================] - 0s 976us/step - loss: 0.0591 - binary_accuracy: 0.9833\n",
      "Epoch 37/100\n",
      "450/450 [==============================] - 0s 943us/step - loss: 0.0590 - binary_accuracy: 0.9822\n",
      "Epoch 38/100\n",
      "450/450 [==============================] - 0s 995us/step - loss: 0.0582 - binary_accuracy: 0.9827\n",
      "Epoch 39/100\n",
      "450/450 [==============================] - 0s 991us/step - loss: 0.0574 - binary_accuracy: 0.9829\n",
      "Epoch 40/100\n",
      "450/450 [==============================] - 0s 976us/step - loss: 0.0567 - binary_accuracy: 0.9833\n",
      "Epoch 41/100\n",
      "450/450 [==============================] - 0s 977us/step - loss: 0.0561 - binary_accuracy: 0.9824\n",
      "Epoch 42/100\n",
      "450/450 [==============================] - 0s 983us/step - loss: 0.0558 - binary_accuracy: 0.9827\n",
      "Epoch 43/100\n",
      "450/450 [==============================] - 0s 991us/step - loss: 0.0549 - binary_accuracy: 0.9842\n",
      "Epoch 44/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0546 - binary_accuracy: 0.9822\n",
      "Epoch 45/100\n",
      "450/450 [==============================] - 0s 955us/step - loss: 0.0547 - binary_accuracy: 0.9829\n",
      "Epoch 46/100\n",
      "450/450 [==============================] - 0s 993us/step - loss: 0.0534 - binary_accuracy: 0.9836\n",
      "Epoch 47/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0543 - binary_accuracy: 0.9827\n",
      "Epoch 48/100\n",
      "450/450 [==============================] - 0s 989us/step - loss: 0.0524 - binary_accuracy: 0.9838\n",
      "Epoch 49/100\n",
      "450/450 [==============================] - 0s 968us/step - loss: 0.0541 - binary_accuracy: 0.9831\n",
      "Epoch 50/100\n",
      "450/450 [==============================] - 0s 999us/step - loss: 0.0532 - binary_accuracy: 0.9829\n",
      "Epoch 51/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0522 - binary_accuracy: 0.9844\n",
      "Epoch 52/100\n",
      "450/450 [==============================] - 0s 993us/step - loss: 0.0521 - binary_accuracy: 0.9827\n",
      "Epoch 53/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0507 - binary_accuracy: 0.9853\n",
      "Epoch 54/100\n",
      "450/450 [==============================] - 0s 999us/step - loss: 0.0509 - binary_accuracy: 0.9838\n",
      "Epoch 55/100\n",
      "450/450 [==============================] - 0s 990us/step - loss: 0.0512 - binary_accuracy: 0.9844\n",
      "Epoch 56/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0507 - binary_accuracy: 0.9849\n",
      "Epoch 57/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0506 - binary_accuracy: 0.9853\n",
      "Epoch 58/100\n",
      "450/450 [==============================] - 0s 974us/step - loss: 0.0498 - binary_accuracy: 0.9856\n",
      "Epoch 59/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0502 - binary_accuracy: 0.9847\n",
      "Epoch 60/100\n",
      "450/450 [==============================] - 0s 980us/step - loss: 0.0491 - binary_accuracy: 0.9856\n",
      "Epoch 61/100\n",
      "450/450 [==============================] - 0s 988us/step - loss: 0.0498 - binary_accuracy: 0.9842\n",
      "Epoch 62/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0497 - binary_accuracy: 0.9851\n",
      "Epoch 63/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0487 - binary_accuracy: 0.9856\n",
      "Epoch 64/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0497 - binary_accuracy: 0.9844\n",
      "Epoch 65/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0482 - binary_accuracy: 0.9847\n",
      "Epoch 66/100\n",
      "450/450 [==============================] - 0s 960us/step - loss: 0.0485 - binary_accuracy: 0.9851\n",
      "Epoch 67/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0487 - binary_accuracy: 0.9847\n",
      "Epoch 68/100\n",
      "450/450 [==============================] - 0s 998us/step - loss: 0.0486 - binary_accuracy: 0.9851\n",
      "Epoch 69/100\n",
      "450/450 [==============================] - 0s 984us/step - loss: 0.0485 - binary_accuracy: 0.9853\n",
      "Epoch 70/100\n",
      "450/450 [==============================] - 0s 984us/step - loss: 0.0480 - binary_accuracy: 0.9851\n",
      "Epoch 71/100\n",
      "450/450 [==============================] - 0s 982us/step - loss: 0.0476 - binary_accuracy: 0.9862\n",
      "Epoch 72/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0483 - binary_accuracy: 0.9853\n",
      "Epoch 73/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0478 - binary_accuracy: 0.9853\n",
      "Epoch 74/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0473 - binary_accuracy: 0.9860\n",
      "Epoch 75/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0473 - binary_accuracy: 0.9860\n",
      "Epoch 76/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0471 - binary_accuracy: 0.9867\n",
      "Epoch 77/100\n",
      "450/450 [==============================] - 0s 979us/step - loss: 0.0471 - binary_accuracy: 0.9858\n",
      "Epoch 78/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0463 - binary_accuracy: 0.9851\n",
      "Epoch 79/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0469 - binary_accuracy: 0.9858\n",
      "Epoch 80/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0467 - binary_accuracy: 0.9851\n",
      "Epoch 81/100\n",
      "450/450 [==============================] - 0s 993us/step - loss: 0.0466 - binary_accuracy: 0.9860\n",
      "Epoch 82/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0460 - binary_accuracy: 0.9867\n",
      "Epoch 83/100\n",
      "450/450 [==============================] - 0s 992us/step - loss: 0.0469 - binary_accuracy: 0.9858\n",
      "Epoch 84/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0464 - binary_accuracy: 0.9856\n",
      "Epoch 85/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0459 - binary_accuracy: 0.9862\n",
      "Epoch 86/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0460 - binary_accuracy: 0.9856\n",
      "Epoch 87/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0449 - binary_accuracy: 0.9864\n",
      "Epoch 88/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0456 - binary_accuracy: 0.9862\n",
      "Epoch 89/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0454 - binary_accuracy: 0.9869\n",
      "Epoch 90/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0463 - binary_accuracy: 0.9847\n",
      "Epoch 91/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0462 - binary_accuracy: 0.9853\n",
      "Epoch 92/100\n",
      "450/450 [==============================] - 0s 966us/step - loss: 0.0448 - binary_accuracy: 0.9867\n",
      "Epoch 93/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0453 - binary_accuracy: 0.9856\n",
      "Epoch 94/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0451 - binary_accuracy: 0.9869\n",
      "Epoch 95/100\n",
      "450/450 [==============================] - 0s 996us/step - loss: 0.0440 - binary_accuracy: 0.9871\n",
      "Epoch 96/100\n",
      "450/450 [==============================] - 0s 981us/step - loss: 0.0442 - binary_accuracy: 0.9873\n",
      "Epoch 97/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0450 - binary_accuracy: 0.9858\n",
      "Epoch 98/100\n",
      "450/450 [==============================] - 0s 995us/step - loss: 0.0443 - binary_accuracy: 0.9864\n",
      "Epoch 99/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0454 - binary_accuracy: 0.9869\n",
      "Epoch 100/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0447 - binary_accuracy: 0.9851\n",
      "Epoch 1/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.3670 - binary_accuracy: 0.9011\n",
      "Epoch 2/100\n",
      "450/450 [==============================] - 0s 983us/step - loss: 0.1993 - binary_accuracy: 0.9036\n",
      "Epoch 3/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1646 - binary_accuracy: 0.9036\n",
      "Epoch 4/100\n",
      "450/450 [==============================] - 0s 967us/step - loss: 0.1453 - binary_accuracy: 0.9036\n",
      "Epoch 5/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1316 - binary_accuracy: 0.9169\n",
      "Epoch 6/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1214 - binary_accuracy: 0.9640\n",
      "Epoch 7/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1125 - binary_accuracy: 0.9669\n",
      "Epoch 8/100\n",
      "450/450 [==============================] - 0s 972us/step - loss: 0.1067 - binary_accuracy: 0.9707\n",
      "Epoch 9/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1015 - binary_accuracy: 0.9711\n",
      "Epoch 10/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0947 - binary_accuracy: 0.9747\n",
      "Epoch 11/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0901 - binary_accuracy: 0.9762\n",
      "Epoch 12/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0870 - binary_accuracy: 0.9767\n",
      "Epoch 13/100\n",
      "450/450 [==============================] - 0s 994us/step - loss: 0.0838 - binary_accuracy: 0.9787\n",
      "Epoch 14/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0805 - binary_accuracy: 0.9800\n",
      "Epoch 15/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0788 - binary_accuracy: 0.9798\n",
      "Epoch 16/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0763 - binary_accuracy: 0.9787\n",
      "Epoch 17/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0742 - binary_accuracy: 0.9807\n",
      "Epoch 18/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0732 - binary_accuracy: 0.9802\n",
      "Epoch 19/100\n",
      "450/450 [==============================] - 0s 995us/step - loss: 0.0714 - binary_accuracy: 0.9791\n",
      "Epoch 20/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0703 - binary_accuracy: 0.9796\n",
      "Epoch 21/100\n",
      "450/450 [==============================] - 0s 988us/step - loss: 0.0681 - binary_accuracy: 0.9804\n",
      "Epoch 22/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0678 - binary_accuracy: 0.9809\n",
      "Epoch 23/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0663 - binary_accuracy: 0.9818\n",
      "Epoch 24/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0659 - binary_accuracy: 0.9798\n",
      "Epoch 25/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0651 - binary_accuracy: 0.9818\n",
      "Epoch 26/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0648 - binary_accuracy: 0.9809\n",
      "Epoch 27/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0633 - binary_accuracy: 0.9816\n",
      "Epoch 28/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0631 - binary_accuracy: 0.9813\n",
      "Epoch 29/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0633 - binary_accuracy: 0.9796\n",
      "Epoch 30/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0619 - binary_accuracy: 0.9811\n",
      "Epoch 31/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0625 - binary_accuracy: 0.9822\n",
      "Epoch 32/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0615 - binary_accuracy: 0.9829\n",
      "Epoch 33/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0617 - binary_accuracy: 0.9813\n",
      "Epoch 34/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0603 - binary_accuracy: 0.9811\n",
      "Epoch 35/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0599 - binary_accuracy: 0.9831\n",
      "Epoch 36/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0599 - binary_accuracy: 0.9813\n",
      "Epoch 37/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0602 - binary_accuracy: 0.9793\n",
      "Epoch 38/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0594 - binary_accuracy: 0.9813\n",
      "Epoch 39/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0599 - binary_accuracy: 0.9816\n",
      "Epoch 40/100\n",
      "450/450 [==============================] - 0s 1000us/step - loss: 0.0589 - binary_accuracy: 0.9822\n",
      "Epoch 41/100\n",
      "450/450 [==============================] - 0s 989us/step - loss: 0.0593 - binary_accuracy: 0.9822\n",
      "Epoch 42/100\n",
      "450/450 [==============================] - 0s 994us/step - loss: 0.0589 - binary_accuracy: 0.9827\n",
      "Epoch 43/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0586 - binary_accuracy: 0.9822\n",
      "Epoch 44/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0590 - binary_accuracy: 0.9804\n",
      "Epoch 45/100\n",
      "450/450 [==============================] - 0s 992us/step - loss: 0.0588 - binary_accuracy: 0.9820\n",
      "Epoch 46/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0584 - binary_accuracy: 0.9831\n",
      "Epoch 47/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0579 - binary_accuracy: 0.9816\n",
      "Epoch 48/100\n",
      "450/450 [==============================] - 0s 989us/step - loss: 0.0583 - binary_accuracy: 0.9822\n",
      "Epoch 49/100\n",
      "450/450 [==============================] - 0s 995us/step - loss: 0.0578 - binary_accuracy: 0.9829\n",
      "Epoch 50/100\n",
      "450/450 [==============================] - 0s 992us/step - loss: 0.0580 - binary_accuracy: 0.9824\n",
      "Epoch 51/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0571 - binary_accuracy: 0.9818\n",
      "Epoch 52/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0572 - binary_accuracy: 0.9816\n",
      "Epoch 53/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0583 - binary_accuracy: 0.9820\n",
      "Epoch 54/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0579 - binary_accuracy: 0.9809\n",
      "Epoch 55/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0575 - binary_accuracy: 0.9838\n",
      "Epoch 56/100\n",
      "450/450 [==============================] - 0s 992us/step - loss: 0.0571 - binary_accuracy: 0.9833\n",
      "Epoch 57/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0571 - binary_accuracy: 0.9829\n",
      "Epoch 58/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0562 - binary_accuracy: 0.9827\n",
      "Epoch 59/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0563 - binary_accuracy: 0.9829\n",
      "Epoch 60/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0563 - binary_accuracy: 0.9831\n",
      "Epoch 61/100\n",
      "450/450 [==============================] - 0s 991us/step - loss: 0.0568 - binary_accuracy: 0.9827\n",
      "Epoch 62/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0566 - binary_accuracy: 0.9838\n",
      "Epoch 63/100\n",
      "450/450 [==============================] - 0s 982us/step - loss: 0.0556 - binary_accuracy: 0.9838\n",
      "Epoch 64/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0554 - binary_accuracy: 0.9824\n",
      "Epoch 65/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0552 - binary_accuracy: 0.9816\n",
      "Epoch 66/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0555 - binary_accuracy: 0.9822\n",
      "Epoch 67/100\n",
      "450/450 [==============================] - 0s 990us/step - loss: 0.0541 - binary_accuracy: 0.9840\n",
      "Epoch 68/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0549 - binary_accuracy: 0.9813\n",
      "Epoch 69/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0550 - binary_accuracy: 0.9829\n",
      "Epoch 70/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0544 - binary_accuracy: 0.9836\n",
      "Epoch 71/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0541 - binary_accuracy: 0.9836\n",
      "Epoch 72/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0538 - binary_accuracy: 0.9824\n",
      "Epoch 73/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0540 - binary_accuracy: 0.9836\n",
      "Epoch 74/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0520 - binary_accuracy: 0.9838\n",
      "Epoch 75/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0530 - binary_accuracy: 0.9818\n",
      "Epoch 76/100\n",
      "450/450 [==============================] - 0s 1000us/step - loss: 0.0526 - binary_accuracy: 0.9842\n",
      "Epoch 77/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0525 - binary_accuracy: 0.9833\n",
      "Epoch 78/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0524 - binary_accuracy: 0.9836\n",
      "Epoch 79/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0525 - binary_accuracy: 0.9831\n",
      "Epoch 80/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0521 - binary_accuracy: 0.9833\n",
      "Epoch 81/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0526 - binary_accuracy: 0.9838\n",
      "Epoch 82/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0521 - binary_accuracy: 0.9844\n",
      "Epoch 83/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0516 - binary_accuracy: 0.9820\n",
      "Epoch 84/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0520 - binary_accuracy: 0.9842\n",
      "Epoch 85/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0514 - binary_accuracy: 0.9833\n",
      "Epoch 86/100\n",
      "450/450 [==============================] - 0s 988us/step - loss: 0.0514 - binary_accuracy: 0.9836\n",
      "Epoch 87/100\n",
      "450/450 [==============================] - 0s 970us/step - loss: 0.0509 - binary_accuracy: 0.9847\n",
      "Epoch 88/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0508 - binary_accuracy: 0.9842\n",
      "Epoch 89/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0507 - binary_accuracy: 0.9831\n",
      "Epoch 90/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0505 - binary_accuracy: 0.9840\n",
      "Epoch 91/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0505 - binary_accuracy: 0.9827\n",
      "Epoch 92/100\n",
      "450/450 [==============================] - 0s 990us/step - loss: 0.0505 - binary_accuracy: 0.9822\n",
      "Epoch 93/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0504 - binary_accuracy: 0.9836\n",
      "Epoch 94/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0504 - binary_accuracy: 0.9840\n",
      "Epoch 95/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0501 - binary_accuracy: 0.9833\n",
      "Epoch 96/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0505 - binary_accuracy: 0.9831\n",
      "Epoch 97/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0494 - binary_accuracy: 0.9844\n",
      "Epoch 98/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0502 - binary_accuracy: 0.9838\n",
      "Epoch 99/100\n",
      "450/450 [==============================] - 0s 990us/step - loss: 0.0494 - binary_accuracy: 0.9838\n",
      "Epoch 100/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0497 - binary_accuracy: 0.9847\n",
      "Epoch 1/100\n",
      "450/450 [==============================] - 0s 993us/step - loss: 0.3091 - binary_accuracy: 0.9058\n",
      "Epoch 2/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1958 - binary_accuracy: 0.9058\n",
      "Epoch 3/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1835 - binary_accuracy: 0.9058\n",
      "Epoch 4/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1748 - binary_accuracy: 0.9058\n",
      "Epoch 5/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1592 - binary_accuracy: 0.9058\n",
      "Epoch 6/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1400 - binary_accuracy: 0.9318\n",
      "Epoch 7/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1254 - binary_accuracy: 0.9602\n",
      "Epoch 8/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1144 - binary_accuracy: 0.9667\n",
      "Epoch 9/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1063 - binary_accuracy: 0.9713\n",
      "Epoch 10/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0994 - binary_accuracy: 0.9736\n",
      "Epoch 11/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0936 - binary_accuracy: 0.9756\n",
      "Epoch 12/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0883 - binary_accuracy: 0.9784\n",
      "Epoch 13/100\n",
      "450/450 [==============================] - 0s 989us/step - loss: 0.0839 - binary_accuracy: 0.9800\n",
      "Epoch 14/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0807 - binary_accuracy: 0.9791\n",
      "Epoch 15/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0773 - binary_accuracy: 0.9800\n",
      "Epoch 16/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0754 - binary_accuracy: 0.9807\n",
      "Epoch 17/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0734 - binary_accuracy: 0.9804\n",
      "Epoch 18/100\n",
      "450/450 [==============================] - 0s 992us/step - loss: 0.0715 - binary_accuracy: 0.9802\n",
      "Epoch 19/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0691 - binary_accuracy: 0.9811\n",
      "Epoch 20/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0677 - binary_accuracy: 0.9793\n",
      "Epoch 21/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0677 - binary_accuracy: 0.9813\n",
      "Epoch 22/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0667 - binary_accuracy: 0.9811\n",
      "Epoch 23/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0658 - binary_accuracy: 0.9807\n",
      "Epoch 24/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0645 - binary_accuracy: 0.9816\n",
      "Epoch 25/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0647 - binary_accuracy: 0.9816\n",
      "Epoch 26/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0632 - binary_accuracy: 0.9822\n",
      "Epoch 27/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0630 - binary_accuracy: 0.9802\n",
      "Epoch 28/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0622 - binary_accuracy: 0.9822\n",
      "Epoch 29/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0622 - binary_accuracy: 0.9816\n",
      "Epoch 30/100\n",
      "450/450 [==============================] - 0s 979us/step - loss: 0.0616 - binary_accuracy: 0.9822\n",
      "Epoch 31/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0603 - binary_accuracy: 0.9824\n",
      "Epoch 32/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0610 - binary_accuracy: 0.9813\n",
      "Epoch 33/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0612 - binary_accuracy: 0.9809\n",
      "Epoch 34/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0614 - binary_accuracy: 0.9809\n",
      "Epoch 35/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0598 - binary_accuracy: 0.9818\n",
      "Epoch 36/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0599 - binary_accuracy: 0.9807\n",
      "Epoch 37/100\n",
      "450/450 [==============================] - 0s 995us/step - loss: 0.0606 - binary_accuracy: 0.9820\n",
      "Epoch 38/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0584 - binary_accuracy: 0.9833\n",
      "Epoch 39/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0601 - binary_accuracy: 0.9796\n",
      "Epoch 40/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0584 - binary_accuracy: 0.9833\n",
      "Epoch 41/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0587 - binary_accuracy: 0.9813\n",
      "Epoch 42/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0595 - binary_accuracy: 0.9827\n",
      "Epoch 43/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0582 - binary_accuracy: 0.9822\n",
      "Epoch 44/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0583 - binary_accuracy: 0.9829\n",
      "Epoch 45/100\n",
      "450/450 [==============================] - 0s 995us/step - loss: 0.0586 - binary_accuracy: 0.9804\n",
      "Epoch 46/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0588 - binary_accuracy: 0.9822\n",
      "Epoch 47/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0572 - binary_accuracy: 0.9833\n",
      "Epoch 48/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0579 - binary_accuracy: 0.9807\n",
      "Epoch 49/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0590 - binary_accuracy: 0.9827\n",
      "Epoch 50/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0575 - binary_accuracy: 0.9813\n",
      "Epoch 51/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0573 - binary_accuracy: 0.9824\n",
      "Epoch 52/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0572 - binary_accuracy: 0.9827\n",
      "Epoch 53/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0575 - binary_accuracy: 0.9811\n",
      "Epoch 54/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0570 - binary_accuracy: 0.9818\n",
      "Epoch 55/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0572 - binary_accuracy: 0.9822\n",
      "Epoch 56/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0569 - binary_accuracy: 0.9816\n",
      "Epoch 57/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0576 - binary_accuracy: 0.9831\n",
      "Epoch 58/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0574 - binary_accuracy: 0.9816\n",
      "Epoch 59/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0565 - binary_accuracy: 0.9847\n",
      "Epoch 60/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0570 - binary_accuracy: 0.9824\n",
      "Epoch 61/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0566 - binary_accuracy: 0.9822\n",
      "Epoch 62/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0570 - binary_accuracy: 0.9816\n",
      "Epoch 63/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0572 - binary_accuracy: 0.9820\n",
      "Epoch 64/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0564 - binary_accuracy: 0.9813\n",
      "Epoch 65/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0564 - binary_accuracy: 0.9818\n",
      "Epoch 66/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0550 - binary_accuracy: 0.9829\n",
      "Epoch 67/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0556 - binary_accuracy: 0.9818\n",
      "Epoch 68/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0557 - binary_accuracy: 0.9827\n",
      "Epoch 69/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0552 - binary_accuracy: 0.9820\n",
      "Epoch 70/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0552 - binary_accuracy: 0.9844\n",
      "Epoch 71/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0557 - binary_accuracy: 0.9820\n",
      "Epoch 72/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0550 - binary_accuracy: 0.9840\n",
      "Epoch 73/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0558 - binary_accuracy: 0.9818\n",
      "Epoch 74/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0550 - binary_accuracy: 0.9833\n",
      "Epoch 75/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0555 - binary_accuracy: 0.9836\n",
      "Epoch 76/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0541 - binary_accuracy: 0.9829\n",
      "Epoch 77/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0553 - binary_accuracy: 0.9833\n",
      "Epoch 78/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0545 - binary_accuracy: 0.9831\n",
      "Epoch 79/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0546 - binary_accuracy: 0.9829\n",
      "Epoch 80/100\n",
      "450/450 [==============================] - 0s 999us/step - loss: 0.0545 - binary_accuracy: 0.9847\n",
      "Epoch 81/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0547 - binary_accuracy: 0.9824\n",
      "Epoch 82/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0541 - binary_accuracy: 0.9849\n",
      "Epoch 83/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0538 - binary_accuracy: 0.9829\n",
      "Epoch 84/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0547 - binary_accuracy: 0.9827\n",
      "Epoch 85/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0553 - binary_accuracy: 0.9816\n",
      "Epoch 86/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0538 - binary_accuracy: 0.9831\n",
      "Epoch 87/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0540 - binary_accuracy: 0.9847\n",
      "Epoch 88/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0549 - binary_accuracy: 0.9829\n",
      "Epoch 89/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0542 - binary_accuracy: 0.9836\n",
      "Epoch 90/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0544 - binary_accuracy: 0.9831\n",
      "Epoch 91/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0536 - binary_accuracy: 0.9840\n",
      "Epoch 92/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0538 - binary_accuracy: 0.9827\n",
      "Epoch 93/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0532 - binary_accuracy: 0.9833\n",
      "Epoch 94/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0544 - binary_accuracy: 0.9842\n",
      "Epoch 95/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0539 - binary_accuracy: 0.9827\n",
      "Epoch 96/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0536 - binary_accuracy: 0.9842\n",
      "Epoch 97/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0537 - binary_accuracy: 0.9818\n",
      "Epoch 98/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0538 - binary_accuracy: 0.9842\n",
      "Epoch 99/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0538 - binary_accuracy: 0.9827\n",
      "Epoch 100/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0537 - binary_accuracy: 0.9831\n",
      "Epoch 1/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.3536 - binary_accuracy: 0.9020\n",
      "Epoch 2/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.2046 - binary_accuracy: 0.9040\n",
      "Epoch 3/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1877 - binary_accuracy: 0.9040\n",
      "Epoch 4/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1767 - binary_accuracy: 0.9096\n",
      "Epoch 5/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1392 - binary_accuracy: 0.9613\n",
      "Epoch 6/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1097 - binary_accuracy: 0.9702\n",
      "Epoch 7/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0965 - binary_accuracy: 0.9718\n",
      "Epoch 8/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0910 - binary_accuracy: 0.9720\n",
      "Epoch 9/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0866 - binary_accuracy: 0.9722\n",
      "Epoch 10/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0829 - binary_accuracy: 0.9736\n",
      "Epoch 11/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0824 - binary_accuracy: 0.9760\n",
      "Epoch 12/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0806 - binary_accuracy: 0.9758\n",
      "Epoch 13/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0785 - binary_accuracy: 0.9756\n",
      "Epoch 14/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0784 - binary_accuracy: 0.9747\n",
      "Epoch 15/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0764 - binary_accuracy: 0.9762\n",
      "Epoch 16/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0760 - binary_accuracy: 0.9758\n",
      "Epoch 17/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0752 - binary_accuracy: 0.9769\n",
      "Epoch 18/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0740 - binary_accuracy: 0.9769\n",
      "Epoch 19/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0740 - binary_accuracy: 0.9764\n",
      "Epoch 20/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0729 - binary_accuracy: 0.9769\n",
      "Epoch 21/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0721 - binary_accuracy: 0.9776\n",
      "Epoch 22/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0712 - binary_accuracy: 0.9776\n",
      "Epoch 23/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0707 - binary_accuracy: 0.9778\n",
      "Epoch 24/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0703 - binary_accuracy: 0.9771\n",
      "Epoch 25/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0691 - binary_accuracy: 0.9784\n",
      "Epoch 26/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0691 - binary_accuracy: 0.9778\n",
      "Epoch 27/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0685 - binary_accuracy: 0.9767\n",
      "Epoch 28/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0685 - binary_accuracy: 0.9771\n",
      "Epoch 29/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0673 - binary_accuracy: 0.9776\n",
      "Epoch 30/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0670 - binary_accuracy: 0.9791\n",
      "Epoch 31/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0666 - binary_accuracy: 0.9778\n",
      "Epoch 32/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0658 - binary_accuracy: 0.9771\n",
      "Epoch 33/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0657 - binary_accuracy: 0.9796\n",
      "Epoch 34/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0660 - binary_accuracy: 0.9787\n",
      "Epoch 35/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0659 - binary_accuracy: 0.9787\n",
      "Epoch 36/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0648 - binary_accuracy: 0.9789\n",
      "Epoch 37/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0656 - binary_accuracy: 0.9782\n",
      "Epoch 38/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0646 - binary_accuracy: 0.9800\n",
      "Epoch 39/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0648 - binary_accuracy: 0.9791\n",
      "Epoch 40/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0644 - binary_accuracy: 0.9796\n",
      "Epoch 41/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0635 - binary_accuracy: 0.9791\n",
      "Epoch 42/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0628 - binary_accuracy: 0.9798\n",
      "Epoch 43/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0632 - binary_accuracy: 0.9809\n",
      "Epoch 44/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0638 - binary_accuracy: 0.9780\n",
      "Epoch 45/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0622 - binary_accuracy: 0.9784\n",
      "Epoch 46/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0641 - binary_accuracy: 0.9787\n",
      "Epoch 47/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0617 - binary_accuracy: 0.9789\n",
      "Epoch 48/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0619 - binary_accuracy: 0.9798\n",
      "Epoch 49/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0623 - binary_accuracy: 0.9798\n",
      "Epoch 50/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0616 - binary_accuracy: 0.9796\n",
      "Epoch 51/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0614 - binary_accuracy: 0.9784\n",
      "Epoch 52/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0627 - binary_accuracy: 0.9784\n",
      "Epoch 53/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0612 - binary_accuracy: 0.9798\n",
      "Epoch 54/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0610 - binary_accuracy: 0.9798\n",
      "Epoch 55/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0614 - binary_accuracy: 0.9800\n",
      "Epoch 56/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0607 - binary_accuracy: 0.9791\n",
      "Epoch 57/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0599 - binary_accuracy: 0.9791\n",
      "Epoch 58/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0601 - binary_accuracy: 0.9798\n",
      "Epoch 59/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0605 - binary_accuracy: 0.9796\n",
      "Epoch 60/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0606 - binary_accuracy: 0.9802\n",
      "Epoch 61/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0595 - binary_accuracy: 0.9789\n",
      "Epoch 62/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0601 - binary_accuracy: 0.9804\n",
      "Epoch 63/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0589 - binary_accuracy: 0.9807\n",
      "Epoch 64/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0605 - binary_accuracy: 0.9802\n",
      "Epoch 65/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0596 - binary_accuracy: 0.9807\n",
      "Epoch 66/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0585 - binary_accuracy: 0.9800\n",
      "Epoch 67/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0587 - binary_accuracy: 0.9800\n",
      "Epoch 68/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0586 - binary_accuracy: 0.9804\n",
      "Epoch 69/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0591 - binary_accuracy: 0.9798\n",
      "Epoch 70/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0585 - binary_accuracy: 0.9802\n",
      "Epoch 71/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0580 - binary_accuracy: 0.9798\n",
      "Epoch 72/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0570 - binary_accuracy: 0.9804\n",
      "Epoch 73/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0575 - binary_accuracy: 0.9802\n",
      "Epoch 74/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0588 - binary_accuracy: 0.9800\n",
      "Epoch 75/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0569 - binary_accuracy: 0.9793\n",
      "Epoch 76/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0585 - binary_accuracy: 0.9813\n",
      "Epoch 77/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0574 - binary_accuracy: 0.9807\n",
      "Epoch 78/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0573 - binary_accuracy: 0.9809\n",
      "Epoch 79/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0567 - binary_accuracy: 0.9802\n",
      "Epoch 80/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0561 - binary_accuracy: 0.9811\n",
      "Epoch 81/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0581 - binary_accuracy: 0.9789\n",
      "Epoch 82/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0570 - binary_accuracy: 0.9820\n",
      "Epoch 83/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0566 - binary_accuracy: 0.9796\n",
      "Epoch 84/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0569 - binary_accuracy: 0.9811\n",
      "Epoch 85/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0575 - binary_accuracy: 0.9793\n",
      "Epoch 86/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0562 - binary_accuracy: 0.9807\n",
      "Epoch 87/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0571 - binary_accuracy: 0.9802\n",
      "Epoch 88/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0566 - binary_accuracy: 0.9807\n",
      "Epoch 89/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0570 - binary_accuracy: 0.9796\n",
      "Epoch 90/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0569 - binary_accuracy: 0.9807\n",
      "Epoch 91/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0555 - binary_accuracy: 0.9798\n",
      "Epoch 92/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0563 - binary_accuracy: 0.9807\n",
      "Epoch 93/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0548 - binary_accuracy: 0.9816\n",
      "Epoch 94/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0557 - binary_accuracy: 0.9818\n",
      "Epoch 95/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0552 - binary_accuracy: 0.9791\n",
      "Epoch 96/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0555 - binary_accuracy: 0.9809\n",
      "Epoch 97/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0560 - binary_accuracy: 0.9816\n",
      "Epoch 98/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0550 - binary_accuracy: 0.9807\n",
      "Epoch 99/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0553 - binary_accuracy: 0.9809\n",
      "Epoch 100/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0555 - binary_accuracy: 0.9798\n",
      "Epoch 1/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.3710 - binary_accuracy: 0.9027\n",
      "Epoch 2/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.2013 - binary_accuracy: 0.9156\n",
      "Epoch 3/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1565 - binary_accuracy: 0.9502\n",
      "Epoch 4/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1247 - binary_accuracy: 0.9671\n",
      "Epoch 5/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1055 - binary_accuracy: 0.9720\n",
      "Epoch 6/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0950 - binary_accuracy: 0.9718\n",
      "Epoch 7/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0888 - binary_accuracy: 0.9742\n",
      "Epoch 8/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0855 - binary_accuracy: 0.9740\n",
      "Epoch 9/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0826 - binary_accuracy: 0.9747\n",
      "Epoch 10/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0820 - binary_accuracy: 0.9736\n",
      "Epoch 11/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0802 - binary_accuracy: 0.9753\n",
      "Epoch 12/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0780 - binary_accuracy: 0.9756\n",
      "Epoch 13/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0770 - binary_accuracy: 0.9760\n",
      "Epoch 14/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0766 - binary_accuracy: 0.9764\n",
      "Epoch 15/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0753 - binary_accuracy: 0.9760\n",
      "Epoch 16/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0749 - binary_accuracy: 0.9767\n",
      "Epoch 17/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0732 - binary_accuracy: 0.9762\n",
      "Epoch 18/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0733 - binary_accuracy: 0.9767\n",
      "Epoch 19/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0727 - binary_accuracy: 0.9764\n",
      "Epoch 20/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0725 - binary_accuracy: 0.9773\n",
      "Epoch 21/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0718 - binary_accuracy: 0.9789\n",
      "Epoch 22/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0710 - binary_accuracy: 0.9780\n",
      "Epoch 23/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0702 - binary_accuracy: 0.9769\n",
      "Epoch 24/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0697 - binary_accuracy: 0.9769\n",
      "Epoch 25/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0694 - binary_accuracy: 0.9782\n",
      "Epoch 26/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0698 - binary_accuracy: 0.9773\n",
      "Epoch 27/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0691 - binary_accuracy: 0.9789\n",
      "Epoch 28/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0676 - binary_accuracy: 0.9778\n",
      "Epoch 29/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0678 - binary_accuracy: 0.9778\n",
      "Epoch 30/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0669 - binary_accuracy: 0.9791\n",
      "Epoch 31/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0673 - binary_accuracy: 0.9780\n",
      "Epoch 32/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0667 - binary_accuracy: 0.9796\n",
      "Epoch 33/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0663 - binary_accuracy: 0.9791\n",
      "Epoch 34/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0666 - binary_accuracy: 0.9804\n",
      "Epoch 35/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0661 - binary_accuracy: 0.9791\n",
      "Epoch 36/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0653 - binary_accuracy: 0.9789\n",
      "Epoch 37/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0653 - binary_accuracy: 0.9798\n",
      "Epoch 38/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0647 - binary_accuracy: 0.9809\n",
      "Epoch 39/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0641 - binary_accuracy: 0.9809\n",
      "Epoch 40/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0649 - binary_accuracy: 0.9796\n",
      "Epoch 41/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0629 - binary_accuracy: 0.9791\n",
      "Epoch 42/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0639 - binary_accuracy: 0.9816\n",
      "Epoch 43/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0626 - binary_accuracy: 0.9800\n",
      "Epoch 44/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0627 - binary_accuracy: 0.9798\n",
      "Epoch 45/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0626 - binary_accuracy: 0.9804\n",
      "Epoch 46/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0622 - binary_accuracy: 0.9818\n",
      "Epoch 47/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0620 - binary_accuracy: 0.9800\n",
      "Epoch 48/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0622 - binary_accuracy: 0.9793\n",
      "Epoch 49/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0621 - binary_accuracy: 0.9818\n",
      "Epoch 50/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0607 - binary_accuracy: 0.9800\n",
      "Epoch 51/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0609 - binary_accuracy: 0.9804\n",
      "Epoch 52/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0600 - binary_accuracy: 0.9800\n",
      "Epoch 53/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0615 - binary_accuracy: 0.9807\n",
      "Epoch 54/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0597 - binary_accuracy: 0.9809\n",
      "Epoch 55/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0600 - binary_accuracy: 0.9816\n",
      "Epoch 56/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0604 - binary_accuracy: 0.9798\n",
      "Epoch 57/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0596 - binary_accuracy: 0.9820\n",
      "Epoch 58/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0596 - binary_accuracy: 0.9793\n",
      "Epoch 59/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0586 - binary_accuracy: 0.9807\n",
      "Epoch 60/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0586 - binary_accuracy: 0.9798\n",
      "Epoch 61/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0588 - binary_accuracy: 0.9809\n",
      "Epoch 62/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0579 - binary_accuracy: 0.9818\n",
      "Epoch 63/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0583 - binary_accuracy: 0.9818\n",
      "Epoch 64/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0578 - binary_accuracy: 0.9824\n",
      "Epoch 65/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0572 - binary_accuracy: 0.9811\n",
      "Epoch 66/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0568 - binary_accuracy: 0.9833\n",
      "Epoch 67/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0569 - binary_accuracy: 0.9802\n",
      "Epoch 68/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0561 - binary_accuracy: 0.9813\n",
      "Epoch 69/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0556 - binary_accuracy: 0.9809\n",
      "Epoch 70/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0546 - binary_accuracy: 0.9827\n",
      "Epoch 71/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0552 - binary_accuracy: 0.9833\n",
      "Epoch 72/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0547 - binary_accuracy: 0.9840\n",
      "Epoch 73/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0546 - binary_accuracy: 0.9811\n",
      "Epoch 74/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0533 - binary_accuracy: 0.9831\n",
      "Epoch 75/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0547 - binary_accuracy: 0.9831\n",
      "Epoch 76/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0547 - binary_accuracy: 0.9833\n",
      "Epoch 77/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0530 - binary_accuracy: 0.9831\n",
      "Epoch 78/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0535 - binary_accuracy: 0.9836\n",
      "Epoch 79/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0527 - binary_accuracy: 0.9838\n",
      "Epoch 80/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0523 - binary_accuracy: 0.9838\n",
      "Epoch 81/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0523 - binary_accuracy: 0.9847\n",
      "Epoch 82/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0527 - binary_accuracy: 0.9838\n",
      "Epoch 83/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0518 - binary_accuracy: 0.9840\n",
      "Epoch 84/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0522 - binary_accuracy: 0.9844\n",
      "Epoch 85/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0526 - binary_accuracy: 0.9833\n",
      "Epoch 86/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0515 - binary_accuracy: 0.9844\n",
      "Epoch 87/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0516 - binary_accuracy: 0.9842\n",
      "Epoch 88/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0513 - binary_accuracy: 0.9842\n",
      "Epoch 89/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0516 - binary_accuracy: 0.9840\n",
      "Epoch 90/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0505 - binary_accuracy: 0.9840\n",
      "Epoch 91/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0506 - binary_accuracy: 0.9838\n",
      "Epoch 92/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0511 - binary_accuracy: 0.9833\n",
      "Epoch 93/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0504 - binary_accuracy: 0.9842\n",
      "Epoch 94/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0501 - binary_accuracy: 0.9838\n",
      "Epoch 95/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0494 - binary_accuracy: 0.9842\n",
      "Epoch 96/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0500 - binary_accuracy: 0.9833\n",
      "Epoch 97/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0488 - binary_accuracy: 0.9849\n",
      "Epoch 98/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0499 - binary_accuracy: 0.9840\n",
      "Epoch 99/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0492 - binary_accuracy: 0.9851\n",
      "Epoch 100/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0496 - binary_accuracy: 0.9847\n",
      "Epoch 1/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.3401 - binary_accuracy: 0.9044\n",
      "Epoch 2/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1982 - binary_accuracy: 0.9051\n",
      "Epoch 3/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1713 - binary_accuracy: 0.9051\n",
      "Epoch 4/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1485 - binary_accuracy: 0.9051\n",
      "Epoch 5/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1334 - binary_accuracy: 0.9456\n",
      "Epoch 6/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1217 - binary_accuracy: 0.9627\n",
      "Epoch 7/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1130 - binary_accuracy: 0.9664\n",
      "Epoch 8/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1057 - binary_accuracy: 0.9689\n",
      "Epoch 9/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0994 - binary_accuracy: 0.9713\n",
      "Epoch 10/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0939 - binary_accuracy: 0.9751\n",
      "Epoch 11/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0897 - binary_accuracy: 0.9760\n",
      "Epoch 12/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0854 - binary_accuracy: 0.9760\n",
      "Epoch 13/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0828 - binary_accuracy: 0.9760\n",
      "Epoch 14/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0796 - binary_accuracy: 0.9782\n",
      "Epoch 15/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0767 - binary_accuracy: 0.9798\n",
      "Epoch 16/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0747 - binary_accuracy: 0.9789\n",
      "Epoch 17/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0737 - binary_accuracy: 0.9798\n",
      "Epoch 18/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0722 - binary_accuracy: 0.9800\n",
      "Epoch 19/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0706 - binary_accuracy: 0.9798\n",
      "Epoch 20/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0691 - binary_accuracy: 0.9798\n",
      "Epoch 21/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0679 - binary_accuracy: 0.9809\n",
      "Epoch 22/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0673 - binary_accuracy: 0.9816\n",
      "Epoch 23/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0664 - binary_accuracy: 0.9804\n",
      "Epoch 24/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0656 - binary_accuracy: 0.9802\n",
      "Epoch 25/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0647 - binary_accuracy: 0.9820\n",
      "Epoch 26/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0645 - binary_accuracy: 0.9813\n",
      "Epoch 27/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0644 - binary_accuracy: 0.9813\n",
      "Epoch 28/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0630 - binary_accuracy: 0.9829\n",
      "Epoch 29/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0634 - binary_accuracy: 0.9816\n",
      "Epoch 30/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0615 - binary_accuracy: 0.9818\n",
      "Epoch 31/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0631 - binary_accuracy: 0.9831\n",
      "Epoch 32/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0614 - binary_accuracy: 0.9811\n",
      "Epoch 33/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0625 - binary_accuracy: 0.9816\n",
      "Epoch 34/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0615 - binary_accuracy: 0.9818\n",
      "Epoch 35/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0612 - binary_accuracy: 0.9831\n",
      "Epoch 36/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0614 - binary_accuracy: 0.9818\n",
      "Epoch 37/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0606 - binary_accuracy: 0.9813\n",
      "Epoch 38/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0605 - binary_accuracy: 0.9822\n",
      "Epoch 39/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0603 - binary_accuracy: 0.9800\n",
      "Epoch 40/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0600 - binary_accuracy: 0.9824\n",
      "Epoch 41/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0603 - binary_accuracy: 0.9816\n",
      "Epoch 42/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0600 - binary_accuracy: 0.9818\n",
      "Epoch 43/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0598 - binary_accuracy: 0.9818\n",
      "Epoch 44/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0598 - binary_accuracy: 0.9824\n",
      "Epoch 45/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0600 - binary_accuracy: 0.9813\n",
      "Epoch 46/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0596 - binary_accuracy: 0.9820\n",
      "Epoch 47/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0604 - binary_accuracy: 0.9816\n",
      "Epoch 48/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0587 - binary_accuracy: 0.9822\n",
      "Epoch 49/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0590 - binary_accuracy: 0.9820\n",
      "Epoch 50/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0592 - binary_accuracy: 0.9800\n",
      "Epoch 51/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0593 - binary_accuracy: 0.9816\n",
      "Epoch 52/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0588 - binary_accuracy: 0.9827\n",
      "Epoch 53/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0588 - binary_accuracy: 0.9829\n",
      "Epoch 54/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0590 - binary_accuracy: 0.9820\n",
      "Epoch 55/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0578 - binary_accuracy: 0.9822\n",
      "Epoch 56/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0589 - binary_accuracy: 0.9816\n",
      "Epoch 57/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0590 - binary_accuracy: 0.9818\n",
      "Epoch 58/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0581 - binary_accuracy: 0.9818\n",
      "Epoch 59/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0589 - binary_accuracy: 0.9818\n",
      "Epoch 60/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0584 - binary_accuracy: 0.9811\n",
      "Epoch 61/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0580 - binary_accuracy: 0.9824\n",
      "Epoch 62/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0579 - binary_accuracy: 0.9809\n",
      "Epoch 63/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0580 - binary_accuracy: 0.9827\n",
      "Epoch 64/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0579 - binary_accuracy: 0.9824\n",
      "Epoch 65/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0574 - binary_accuracy: 0.9811\n",
      "Epoch 66/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0570 - binary_accuracy: 0.9824\n",
      "Epoch 67/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0564 - binary_accuracy: 0.9827\n",
      "Epoch 68/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0564 - binary_accuracy: 0.9811\n",
      "Epoch 69/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0565 - binary_accuracy: 0.9824\n",
      "Epoch 70/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0561 - binary_accuracy: 0.9822\n",
      "Epoch 71/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0561 - binary_accuracy: 0.9822\n",
      "Epoch 72/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0570 - binary_accuracy: 0.9813\n",
      "Epoch 73/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0566 - binary_accuracy: 0.9816\n",
      "Epoch 74/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0562 - binary_accuracy: 0.9831\n",
      "Epoch 75/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0558 - binary_accuracy: 0.9827\n",
      "Epoch 76/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0547 - binary_accuracy: 0.9833\n",
      "Epoch 77/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0553 - binary_accuracy: 0.9827\n",
      "Epoch 78/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0563 - binary_accuracy: 0.9818\n",
      "Epoch 79/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0556 - binary_accuracy: 0.9824\n",
      "Epoch 80/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0547 - binary_accuracy: 0.9829\n",
      "Epoch 81/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0549 - binary_accuracy: 0.9833\n",
      "Epoch 82/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0554 - binary_accuracy: 0.9820\n",
      "Epoch 83/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0542 - binary_accuracy: 0.9838\n",
      "Epoch 84/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0539 - binary_accuracy: 0.9831\n",
      "Epoch 85/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0551 - binary_accuracy: 0.9818\n",
      "Epoch 86/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.0540 - binary_accuracy: 0.9838\n",
      "Epoch 87/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0547 - binary_accuracy: 0.9818\n",
      "Epoch 88/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0547 - binary_accuracy: 0.9838\n",
      "Epoch 89/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0530 - binary_accuracy: 0.9840\n",
      "Epoch 90/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0531 - binary_accuracy: 0.9827\n",
      "Epoch 91/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0539 - binary_accuracy: 0.9829\n",
      "Epoch 92/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0532 - binary_accuracy: 0.9829\n",
      "Epoch 93/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0536 - binary_accuracy: 0.9822\n",
      "Epoch 94/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0526 - binary_accuracy: 0.9829\n",
      "Epoch 95/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0536 - binary_accuracy: 0.9831\n",
      "Epoch 96/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0534 - binary_accuracy: 0.9829\n",
      "Epoch 97/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0530 - binary_accuracy: 0.9824\n",
      "Epoch 98/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0528 - binary_accuracy: 0.9840\n",
      "Epoch 99/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0524 - binary_accuracy: 0.9833\n",
      "Epoch 100/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0521 - binary_accuracy: 0.9840\n",
      "Epoch 1/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.6150 - binary_accuracy: 0.9013\n",
      "Epoch 2/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.4988 - binary_accuracy: 0.9033\n",
      "Epoch 3/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.4260 - binary_accuracy: 0.9033\n",
      "Epoch 4/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.3812 - binary_accuracy: 0.9033\n",
      "Epoch 5/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.3542 - binary_accuracy: 0.9033\n",
      "Epoch 6/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.3381 - binary_accuracy: 0.9033\n",
      "Epoch 7/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.3287 - binary_accuracy: 0.9033\n",
      "Epoch 8/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.3233 - binary_accuracy: 0.9033\n",
      "Epoch 9/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.3205 - binary_accuracy: 0.9033\n",
      "Epoch 10/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.3190 - binary_accuracy: 0.9033\n",
      "Epoch 11/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.3183 - binary_accuracy: 0.9033\n",
      "Epoch 12/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.3180 - binary_accuracy: 0.9033\n",
      "Epoch 13/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.3179 - binary_accuracy: 0.9033\n",
      "Epoch 14/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.3178 - binary_accuracy: 0.9033\n",
      "Epoch 15/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.3178 - binary_accuracy: 0.9033\n",
      "Epoch 16/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.3177 - binary_accuracy: 0.9033\n",
      "Epoch 17/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.3177 - binary_accuracy: 0.9033\n",
      "Epoch 18/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.3178 - binary_accuracy: 0.9033\n",
      "Epoch 19/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.3177 - binary_accuracy: 0.9033\n",
      "Epoch 20/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.3177 - binary_accuracy: 0.9033\n",
      "Epoch 21/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.3177 - binary_accuracy: 0.9033\n",
      "Epoch 22/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.3178 - binary_accuracy: 0.9033\n",
      "Epoch 23/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.3178 - binary_accuracy: 0.9033\n",
      "Epoch 24/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.3177 - binary_accuracy: 0.9033\n",
      "Epoch 25/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.3177 - binary_accuracy: 0.9033\n",
      "Epoch 26/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.3177 - binary_accuracy: 0.9033\n",
      "Epoch 27/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.3177 - binary_accuracy: 0.9033\n",
      "Epoch 28/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.3177 - binary_accuracy: 0.9033\n",
      "Epoch 29/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.3177 - binary_accuracy: 0.9033\n",
      "Epoch 30/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.3177 - binary_accuracy: 0.9033\n",
      "Epoch 31/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.3177 - binary_accuracy: 0.9033\n",
      "Epoch 32/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.3177 - binary_accuracy: 0.9033\n",
      "Epoch 33/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.3177 - binary_accuracy: 0.9033\n",
      "Epoch 34/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.3177 - binary_accuracy: 0.9033\n",
      "Epoch 35/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.3177 - binary_accuracy: 0.9033\n",
      "Epoch 36/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.3178 - binary_accuracy: 0.9033\n",
      "Epoch 37/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.3177 - binary_accuracy: 0.9033\n",
      "Epoch 38/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.3177 - binary_accuracy: 0.9033\n",
      "Epoch 39/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.3177 - binary_accuracy: 0.9033\n",
      "Epoch 40/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.3177 - binary_accuracy: 0.9033\n",
      "Epoch 41/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.3177 - binary_accuracy: 0.9033\n",
      "Epoch 42/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.3177 - binary_accuracy: 0.9033\n",
      "Epoch 43/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.3177 - binary_accuracy: 0.9033\n",
      "Epoch 44/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.3177 - binary_accuracy: 0.9033\n",
      "Epoch 45/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.3177 - binary_accuracy: 0.9033\n",
      "Epoch 46/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.3177 - binary_accuracy: 0.9033\n",
      "Epoch 47/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.3177 - binary_accuracy: 0.9033\n",
      "Epoch 48/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.3177 - binary_accuracy: 0.9033\n",
      "Epoch 49/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.3177 - binary_accuracy: 0.9033\n",
      "Epoch 50/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.3178 - binary_accuracy: 0.9033\n",
      "Epoch 51/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.3177 - binary_accuracy: 0.9033\n",
      "Epoch 52/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.3177 - binary_accuracy: 0.9033\n",
      "Epoch 53/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.3178 - binary_accuracy: 0.9033\n",
      "Epoch 54/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.3177 - binary_accuracy: 0.9033\n",
      "Epoch 55/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.3178 - binary_accuracy: 0.9033\n",
      "Epoch 56/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.3177 - binary_accuracy: 0.9033\n",
      "Epoch 57/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.3177 - binary_accuracy: 0.9033\n",
      "Epoch 58/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.3177 - binary_accuracy: 0.9033\n",
      "Epoch 59/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.3177 - binary_accuracy: 0.9033\n",
      "Epoch 60/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.3177 - binary_accuracy: 0.9033\n",
      "Epoch 61/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.3177 - binary_accuracy: 0.9033\n",
      "Epoch 62/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.3177 - binary_accuracy: 0.9033\n",
      "Epoch 63/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.3177 - binary_accuracy: 0.9033\n",
      "Epoch 64/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.3177 - binary_accuracy: 0.9033\n",
      "Epoch 65/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.3177 - binary_accuracy: 0.9033\n",
      "Epoch 66/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.3177 - binary_accuracy: 0.9033\n",
      "Epoch 67/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.3177 - binary_accuracy: 0.9033\n",
      "Epoch 68/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.3177 - binary_accuracy: 0.9033\n",
      "Epoch 69/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.3177 - binary_accuracy: 0.9033\n",
      "Epoch 70/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.3177 - binary_accuracy: 0.9033\n",
      "Epoch 71/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.3177 - binary_accuracy: 0.9033\n",
      "Epoch 72/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.3177 - binary_accuracy: 0.9033\n",
      "Epoch 73/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.3177 - binary_accuracy: 0.9033\n",
      "Epoch 74/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.3177 - binary_accuracy: 0.9033\n",
      "Epoch 75/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.3177 - binary_accuracy: 0.9033\n",
      "Epoch 76/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.3177 - binary_accuracy: 0.9033\n",
      "Epoch 77/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.3177 - binary_accuracy: 0.9033\n",
      "Epoch 78/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.3177 - binary_accuracy: 0.9033\n",
      "Epoch 79/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.3177 - binary_accuracy: 0.9033\n",
      "Epoch 80/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.3177 - binary_accuracy: 0.9033\n",
      "Epoch 81/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.3177 - binary_accuracy: 0.9033\n",
      "Epoch 82/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.3178 - binary_accuracy: 0.9033\n",
      "Epoch 83/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.3178 - binary_accuracy: 0.9033\n",
      "Epoch 84/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.3177 - binary_accuracy: 0.9033\n",
      "Epoch 85/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.3177 - binary_accuracy: 0.9033\n",
      "Epoch 86/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.3177 - binary_accuracy: 0.9033\n",
      "Epoch 87/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.3177 - binary_accuracy: 0.9033\n",
      "Epoch 88/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.3177 - binary_accuracy: 0.9033\n",
      "Epoch 89/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.3177 - binary_accuracy: 0.9033\n",
      "Epoch 90/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.3177 - binary_accuracy: 0.9033\n",
      "Epoch 91/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.3177 - binary_accuracy: 0.9033\n",
      "Epoch 92/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.3177 - binary_accuracy: 0.9033\n",
      "Epoch 93/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.3177 - binary_accuracy: 0.9033\n",
      "Epoch 94/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.3177 - binary_accuracy: 0.9033\n",
      "Epoch 95/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.3177 - binary_accuracy: 0.9033\n",
      "Epoch 96/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.3177 - binary_accuracy: 0.9033\n",
      "Epoch 97/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.3177 - binary_accuracy: 0.9033\n",
      "Epoch 98/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.3177 - binary_accuracy: 0.9033\n",
      "Epoch 99/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.3177 - binary_accuracy: 0.9033\n",
      "Epoch 100/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.3177 - binary_accuracy: 0.9033\n",
      "Epoch 1/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.3343 - binary_accuracy: 0.9029\n",
      "Epoch 2/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.2033 - binary_accuracy: 0.9029\n",
      "Epoch 3/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1903 - binary_accuracy: 0.9029\n",
      "Epoch 4/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1838 - binary_accuracy: 0.9029\n",
      "Epoch 5/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1801 - binary_accuracy: 0.9029\n",
      "Epoch 6/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1751 - binary_accuracy: 0.9029\n",
      "Epoch 7/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1680 - binary_accuracy: 0.9029\n",
      "Epoch 8/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1523 - binary_accuracy: 0.9184\n",
      "Epoch 9/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1374 - binary_accuracy: 0.9509\n",
      "Epoch 10/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1252 - binary_accuracy: 0.9616\n",
      "Epoch 11/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1151 - binary_accuracy: 0.9662\n",
      "Epoch 12/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1075 - binary_accuracy: 0.9704\n",
      "Epoch 13/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1011 - binary_accuracy: 0.9720\n",
      "Epoch 14/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0962 - binary_accuracy: 0.9736\n",
      "Epoch 15/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0910 - binary_accuracy: 0.9769\n",
      "Epoch 16/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0870 - binary_accuracy: 0.9776\n",
      "Epoch 17/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0834 - binary_accuracy: 0.9782\n",
      "Epoch 18/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0806 - binary_accuracy: 0.9800\n",
      "Epoch 19/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0781 - binary_accuracy: 0.9784\n",
      "Epoch 20/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0756 - binary_accuracy: 0.9800\n",
      "Epoch 21/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0747 - binary_accuracy: 0.9807\n",
      "Epoch 22/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0726 - binary_accuracy: 0.9798\n",
      "Epoch 23/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0720 - binary_accuracy: 0.9804\n",
      "Epoch 24/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0701 - binary_accuracy: 0.9816\n",
      "Epoch 25/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0701 - binary_accuracy: 0.9807\n",
      "Epoch 26/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0689 - binary_accuracy: 0.9802\n",
      "Epoch 27/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0670 - binary_accuracy: 0.9820\n",
      "Epoch 28/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0679 - binary_accuracy: 0.9793\n",
      "Epoch 29/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0662 - binary_accuracy: 0.9811\n",
      "Epoch 30/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0663 - binary_accuracy: 0.9816\n",
      "Epoch 31/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0658 - binary_accuracy: 0.9807\n",
      "Epoch 32/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0649 - binary_accuracy: 0.9818\n",
      "Epoch 33/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0652 - binary_accuracy: 0.9813\n",
      "Epoch 34/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0647 - binary_accuracy: 0.9816\n",
      "Epoch 35/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0646 - binary_accuracy: 0.9822\n",
      "Epoch 36/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0648 - binary_accuracy: 0.9811\n",
      "Epoch 37/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0640 - binary_accuracy: 0.9807\n",
      "Epoch 38/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0631 - binary_accuracy: 0.9816\n",
      "Epoch 39/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0633 - binary_accuracy: 0.9809\n",
      "Epoch 40/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0634 - binary_accuracy: 0.9809\n",
      "Epoch 41/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0629 - binary_accuracy: 0.9822\n",
      "Epoch 42/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0626 - binary_accuracy: 0.9809\n",
      "Epoch 43/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0621 - binary_accuracy: 0.9818\n",
      "Epoch 44/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0622 - binary_accuracy: 0.9809\n",
      "Epoch 45/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0629 - binary_accuracy: 0.9798\n",
      "Epoch 46/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0617 - binary_accuracy: 0.9827\n",
      "Epoch 47/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0613 - binary_accuracy: 0.9813\n",
      "Epoch 48/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0622 - binary_accuracy: 0.9804\n",
      "Epoch 49/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0613 - binary_accuracy: 0.9816\n",
      "Epoch 50/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0615 - binary_accuracy: 0.9813\n",
      "Epoch 51/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0614 - binary_accuracy: 0.9807\n",
      "Epoch 52/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0608 - binary_accuracy: 0.9813\n",
      "Epoch 53/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0608 - binary_accuracy: 0.9807\n",
      "Epoch 54/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0610 - binary_accuracy: 0.9824\n",
      "Epoch 55/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0609 - binary_accuracy: 0.9813\n",
      "Epoch 56/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0612 - binary_accuracy: 0.9807\n",
      "Epoch 57/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0605 - binary_accuracy: 0.9807\n",
      "Epoch 58/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0605 - binary_accuracy: 0.9827\n",
      "Epoch 59/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0601 - binary_accuracy: 0.9811\n",
      "Epoch 60/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0597 - binary_accuracy: 0.9813\n",
      "Epoch 61/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0591 - binary_accuracy: 0.9811\n",
      "Epoch 62/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0599 - binary_accuracy: 0.9809\n",
      "Epoch 63/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0598 - binary_accuracy: 0.9804\n",
      "Epoch 64/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0595 - binary_accuracy: 0.9816\n",
      "Epoch 65/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0596 - binary_accuracy: 0.9813\n",
      "Epoch 66/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0593 - binary_accuracy: 0.9813\n",
      "Epoch 67/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0590 - binary_accuracy: 0.9804\n",
      "Epoch 68/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0592 - binary_accuracy: 0.9807\n",
      "Epoch 69/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0593 - binary_accuracy: 0.9816\n",
      "Epoch 70/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0580 - binary_accuracy: 0.9836\n",
      "Epoch 71/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0592 - binary_accuracy: 0.9811\n",
      "Epoch 72/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0587 - binary_accuracy: 0.9822\n",
      "Epoch 73/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0590 - binary_accuracy: 0.9809\n",
      "Epoch 74/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0587 - binary_accuracy: 0.9818\n",
      "Epoch 75/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0581 - binary_accuracy: 0.9816\n",
      "Epoch 76/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0594 - binary_accuracy: 0.9809\n",
      "Epoch 77/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0597 - binary_accuracy: 0.9802\n",
      "Epoch 78/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0594 - binary_accuracy: 0.9816\n",
      "Epoch 79/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0584 - binary_accuracy: 0.9816\n",
      "Epoch 80/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0584 - binary_accuracy: 0.9824\n",
      "Epoch 81/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0586 - binary_accuracy: 0.9802\n",
      "Epoch 82/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0584 - binary_accuracy: 0.9827\n",
      "Epoch 83/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0583 - binary_accuracy: 0.9824\n",
      "Epoch 84/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0578 - binary_accuracy: 0.9820\n",
      "Epoch 85/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0581 - binary_accuracy: 0.9836\n",
      "Epoch 86/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0585 - binary_accuracy: 0.9802\n",
      "Epoch 87/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0577 - binary_accuracy: 0.9811\n",
      "Epoch 88/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0581 - binary_accuracy: 0.9822\n",
      "Epoch 89/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0579 - binary_accuracy: 0.9824\n",
      "Epoch 90/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0577 - binary_accuracy: 0.9813\n",
      "Epoch 91/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0580 - binary_accuracy: 0.9818\n",
      "Epoch 92/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0574 - binary_accuracy: 0.9813\n",
      "Epoch 93/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0591 - binary_accuracy: 0.9809\n",
      "Epoch 94/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0571 - binary_accuracy: 0.9827\n",
      "Epoch 95/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0583 - binary_accuracy: 0.9816\n",
      "Epoch 96/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0583 - binary_accuracy: 0.9816\n",
      "Epoch 97/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0578 - binary_accuracy: 0.9824\n",
      "Epoch 98/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0573 - binary_accuracy: 0.9824\n",
      "Epoch 99/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0583 - binary_accuracy: 0.9816\n",
      "Epoch 100/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0581 - binary_accuracy: 0.9813\n",
      "Epoch 1/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.3636 - binary_accuracy: 0.9004\n",
      "Epoch 2/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.2172 - binary_accuracy: 0.9042\n",
      "Epoch 3/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1953 - binary_accuracy: 0.9042\n",
      "Epoch 4/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1809 - binary_accuracy: 0.9042\n",
      "Epoch 5/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1648 - binary_accuracy: 0.9042\n",
      "Epoch 6/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1457 - binary_accuracy: 0.9164\n",
      "Epoch 7/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1245 - binary_accuracy: 0.9631\n",
      "Epoch 8/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1080 - binary_accuracy: 0.9671\n",
      "Epoch 9/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0969 - binary_accuracy: 0.9696\n",
      "Epoch 10/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0892 - binary_accuracy: 0.9733\n",
      "Epoch 11/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0841 - binary_accuracy: 0.9760\n",
      "Epoch 12/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0794 - binary_accuracy: 0.9753\n",
      "Epoch 13/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0765 - binary_accuracy: 0.9782\n",
      "Epoch 14/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0733 - binary_accuracy: 0.9780\n",
      "Epoch 15/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0722 - binary_accuracy: 0.9784\n",
      "Epoch 16/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0696 - binary_accuracy: 0.9798\n",
      "Epoch 17/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0680 - binary_accuracy: 0.9796\n",
      "Epoch 18/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0664 - binary_accuracy: 0.9796\n",
      "Epoch 19/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0655 - binary_accuracy: 0.9798\n",
      "Epoch 20/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0639 - binary_accuracy: 0.9807\n",
      "Epoch 21/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0633 - binary_accuracy: 0.9789\n",
      "Epoch 22/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0628 - binary_accuracy: 0.9816\n",
      "Epoch 23/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0629 - binary_accuracy: 0.9809\n",
      "Epoch 24/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0622 - binary_accuracy: 0.9809\n",
      "Epoch 25/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0617 - binary_accuracy: 0.9811\n",
      "Epoch 26/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0611 - binary_accuracy: 0.9800\n",
      "Epoch 27/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0606 - binary_accuracy: 0.9816\n",
      "Epoch 28/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0605 - binary_accuracy: 0.9811\n",
      "Epoch 29/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0597 - binary_accuracy: 0.9820\n",
      "Epoch 30/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0599 - binary_accuracy: 0.9798\n",
      "Epoch 31/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0587 - binary_accuracy: 0.9809\n",
      "Epoch 32/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0594 - binary_accuracy: 0.9820\n",
      "Epoch 33/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0584 - binary_accuracy: 0.9816\n",
      "Epoch 34/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0586 - binary_accuracy: 0.9827\n",
      "Epoch 35/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0569 - binary_accuracy: 0.9836\n",
      "Epoch 36/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0584 - binary_accuracy: 0.9822\n",
      "Epoch 37/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0572 - binary_accuracy: 0.9820\n",
      "Epoch 38/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0577 - binary_accuracy: 0.9827\n",
      "Epoch 39/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0565 - binary_accuracy: 0.9829\n",
      "Epoch 40/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0572 - binary_accuracy: 0.9829\n",
      "Epoch 41/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0566 - binary_accuracy: 0.9829\n",
      "Epoch 42/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0559 - binary_accuracy: 0.9836\n",
      "Epoch 43/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0560 - binary_accuracy: 0.9840\n",
      "Epoch 44/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0559 - binary_accuracy: 0.9840\n",
      "Epoch 45/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0554 - binary_accuracy: 0.9827\n",
      "Epoch 46/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0553 - binary_accuracy: 0.9831\n",
      "Epoch 47/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0549 - binary_accuracy: 0.9847\n",
      "Epoch 48/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0549 - binary_accuracy: 0.9833\n",
      "Epoch 49/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0545 - binary_accuracy: 0.9836\n",
      "Epoch 50/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0540 - binary_accuracy: 0.9842\n",
      "Epoch 51/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0545 - binary_accuracy: 0.9838\n",
      "Epoch 52/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0543 - binary_accuracy: 0.9851\n",
      "Epoch 53/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0528 - binary_accuracy: 0.9849\n",
      "Epoch 54/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0540 - binary_accuracy: 0.9840\n",
      "Epoch 55/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0533 - binary_accuracy: 0.9838\n",
      "Epoch 56/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0529 - binary_accuracy: 0.9844\n",
      "Epoch 57/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0540 - binary_accuracy: 0.9840\n",
      "Epoch 58/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0534 - binary_accuracy: 0.9829\n",
      "Epoch 59/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0528 - binary_accuracy: 0.9842\n",
      "Epoch 60/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0527 - binary_accuracy: 0.9851\n",
      "Epoch 61/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0531 - binary_accuracy: 0.9838\n",
      "Epoch 62/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0525 - binary_accuracy: 0.9849\n",
      "Epoch 63/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0521 - binary_accuracy: 0.9847\n",
      "Epoch 64/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0517 - binary_accuracy: 0.9842\n",
      "Epoch 65/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0518 - binary_accuracy: 0.9847\n",
      "Epoch 66/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0520 - binary_accuracy: 0.9849\n",
      "Epoch 67/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0512 - binary_accuracy: 0.9858\n",
      "Epoch 68/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0515 - binary_accuracy: 0.9862\n",
      "Epoch 69/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0513 - binary_accuracy: 0.9856\n",
      "Epoch 70/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0509 - binary_accuracy: 0.9856\n",
      "Epoch 71/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0510 - binary_accuracy: 0.9853\n",
      "Epoch 72/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0509 - binary_accuracy: 0.9864\n",
      "Epoch 73/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0502 - binary_accuracy: 0.9856\n",
      "Epoch 74/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0506 - binary_accuracy: 0.9869\n",
      "Epoch 75/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0509 - binary_accuracy: 0.9853\n",
      "Epoch 76/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0501 - binary_accuracy: 0.9853\n",
      "Epoch 77/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0501 - binary_accuracy: 0.9864\n",
      "Epoch 78/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0501 - binary_accuracy: 0.9862\n",
      "Epoch 79/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0498 - binary_accuracy: 0.9864\n",
      "Epoch 80/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0501 - binary_accuracy: 0.9862\n",
      "Epoch 81/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0496 - binary_accuracy: 0.9864\n",
      "Epoch 82/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0495 - binary_accuracy: 0.9867\n",
      "Epoch 83/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0496 - binary_accuracy: 0.9849\n",
      "Epoch 84/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0495 - binary_accuracy: 0.9864\n",
      "Epoch 85/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0501 - binary_accuracy: 0.9869\n",
      "Epoch 86/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0493 - binary_accuracy: 0.9858\n",
      "Epoch 87/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0489 - binary_accuracy: 0.9864\n",
      "Epoch 88/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0496 - binary_accuracy: 0.9856\n",
      "Epoch 89/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0492 - binary_accuracy: 0.9878\n",
      "Epoch 90/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0491 - binary_accuracy: 0.9862\n",
      "Epoch 91/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0487 - binary_accuracy: 0.9871\n",
      "Epoch 92/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0486 - binary_accuracy: 0.9864\n",
      "Epoch 93/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0480 - binary_accuracy: 0.9876\n",
      "Epoch 94/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0484 - binary_accuracy: 0.9860\n",
      "Epoch 95/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0489 - binary_accuracy: 0.9858\n",
      "Epoch 96/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0484 - binary_accuracy: 0.9860\n",
      "Epoch 97/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0478 - binary_accuracy: 0.9871\n",
      "Epoch 98/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0484 - binary_accuracy: 0.9867\n",
      "Epoch 99/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0475 - binary_accuracy: 0.9869\n",
      "Epoch 100/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0483 - binary_accuracy: 0.9856\n",
      "Epoch 1/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.3312 - binary_accuracy: 0.9000\n",
      "Epoch 2/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1961 - binary_accuracy: 0.9009\n",
      "Epoch 3/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1674 - binary_accuracy: 0.9009\n",
      "Epoch 4/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1441 - binary_accuracy: 0.9193\n",
      "Epoch 5/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1297 - binary_accuracy: 0.9591\n",
      "Epoch 6/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1190 - binary_accuracy: 0.9644\n",
      "Epoch 7/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1104 - binary_accuracy: 0.9676\n",
      "Epoch 8/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1032 - binary_accuracy: 0.9707\n",
      "Epoch 9/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0966 - binary_accuracy: 0.9749\n",
      "Epoch 10/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0922 - binary_accuracy: 0.9751\n",
      "Epoch 11/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0870 - binary_accuracy: 0.9771\n",
      "Epoch 12/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0832 - binary_accuracy: 0.9782\n",
      "Epoch 13/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0803 - binary_accuracy: 0.9780\n",
      "Epoch 14/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0775 - binary_accuracy: 0.9807\n",
      "Epoch 15/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0751 - binary_accuracy: 0.9798\n",
      "Epoch 16/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0741 - binary_accuracy: 0.9778\n",
      "Epoch 17/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0724 - binary_accuracy: 0.9800\n",
      "Epoch 18/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0697 - binary_accuracy: 0.9807\n",
      "Epoch 19/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0695 - binary_accuracy: 0.9807\n",
      "Epoch 20/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0677 - binary_accuracy: 0.9807\n",
      "Epoch 21/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0681 - binary_accuracy: 0.9798\n",
      "Epoch 22/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0661 - binary_accuracy: 0.9816\n",
      "Epoch 23/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0660 - binary_accuracy: 0.9802\n",
      "Epoch 24/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0649 - binary_accuracy: 0.9818\n",
      "Epoch 25/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0649 - binary_accuracy: 0.9831\n",
      "Epoch 26/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0640 - binary_accuracy: 0.9807\n",
      "Epoch 27/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0640 - binary_accuracy: 0.9804\n",
      "Epoch 28/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0629 - binary_accuracy: 0.9824\n",
      "Epoch 29/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.0630 - binary_accuracy: 0.9807\n",
      "Epoch 30/100\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.0622 - binary_accuracy: 0.9813\n",
      "Epoch 31/100\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.0621 - binary_accuracy: 0.9822\n",
      "Epoch 32/100\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.0616 - binary_accuracy: 0.9829\n",
      "Epoch 33/100\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.0618 - binary_accuracy: 0.9822\n",
      "Epoch 34/100\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.0612 - binary_accuracy: 0.9798\n",
      "Epoch 35/100\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.0608 - binary_accuracy: 0.9818\n",
      "Epoch 36/100\n",
      "450/450 [==============================] - 1s 3ms/step - loss: 0.0612 - binary_accuracy: 0.9816\n",
      "Epoch 37/100\n",
      "450/450 [==============================] - 1s 2ms/step - loss: 0.0613 - binary_accuracy: 0.9804\n",
      "Epoch 38/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0605 - binary_accuracy: 0.9820\n",
      "Epoch 39/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0611 - binary_accuracy: 0.9824\n",
      "Epoch 40/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0603 - binary_accuracy: 0.9818\n",
      "Epoch 41/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0598 - binary_accuracy: 0.9809\n",
      "Epoch 42/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0600 - binary_accuracy: 0.9813\n",
      "Epoch 43/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0596 - binary_accuracy: 0.9822\n",
      "Epoch 44/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0596 - binary_accuracy: 0.9827\n",
      "Epoch 45/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0595 - binary_accuracy: 0.9811\n",
      "Epoch 46/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0597 - binary_accuracy: 0.9818\n",
      "Epoch 47/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0598 - binary_accuracy: 0.9816\n",
      "Epoch 48/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0594 - binary_accuracy: 0.9820\n",
      "Epoch 49/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0595 - binary_accuracy: 0.9816\n",
      "Epoch 50/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0592 - binary_accuracy: 0.9822\n",
      "Epoch 51/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0579 - binary_accuracy: 0.9831\n",
      "Epoch 52/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0590 - binary_accuracy: 0.9818\n",
      "Epoch 53/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0587 - binary_accuracy: 0.9824\n",
      "Epoch 54/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.0588 - binary_accuracy: 0.9829\n",
      "Epoch 55/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0581 - binary_accuracy: 0.9822\n",
      "Epoch 56/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0584 - binary_accuracy: 0.9836\n",
      "Epoch 57/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0581 - binary_accuracy: 0.9824\n",
      "Epoch 58/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0580 - binary_accuracy: 0.9824\n",
      "Epoch 59/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0578 - binary_accuracy: 0.9831\n",
      "Epoch 60/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0566 - binary_accuracy: 0.9824\n",
      "Epoch 61/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0578 - binary_accuracy: 0.9822\n",
      "Epoch 62/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0575 - binary_accuracy: 0.9811\n",
      "Epoch 63/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0564 - binary_accuracy: 0.9820\n",
      "Epoch 64/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0566 - binary_accuracy: 0.9816\n",
      "Epoch 65/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0572 - binary_accuracy: 0.9820\n",
      "Epoch 66/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0570 - binary_accuracy: 0.9829\n",
      "Epoch 67/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0577 - binary_accuracy: 0.9818\n",
      "Epoch 68/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0570 - binary_accuracy: 0.9833\n",
      "Epoch 69/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0575 - binary_accuracy: 0.9816\n",
      "Epoch 70/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0568 - binary_accuracy: 0.9836\n",
      "Epoch 71/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0565 - binary_accuracy: 0.9822\n",
      "Epoch 72/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0572 - binary_accuracy: 0.9818\n",
      "Epoch 73/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0557 - binary_accuracy: 0.9824\n",
      "Epoch 74/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0568 - binary_accuracy: 0.9824\n",
      "Epoch 75/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0575 - binary_accuracy: 0.9816\n",
      "Epoch 76/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0566 - binary_accuracy: 0.9827\n",
      "Epoch 77/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0560 - binary_accuracy: 0.9822\n",
      "Epoch 78/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0561 - binary_accuracy: 0.9827\n",
      "Epoch 79/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0563 - binary_accuracy: 0.9831\n",
      "Epoch 80/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0560 - binary_accuracy: 0.9807\n",
      "Epoch 81/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0559 - binary_accuracy: 0.9829\n",
      "Epoch 82/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0554 - binary_accuracy: 0.9829\n",
      "Epoch 83/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0556 - binary_accuracy: 0.9822\n",
      "Epoch 84/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0557 - binary_accuracy: 0.9813\n",
      "Epoch 85/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0553 - binary_accuracy: 0.9836\n",
      "Epoch 86/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0551 - binary_accuracy: 0.9822\n",
      "Epoch 87/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0545 - binary_accuracy: 0.9831\n",
      "Epoch 88/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0562 - binary_accuracy: 0.9838\n",
      "Epoch 89/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0551 - binary_accuracy: 0.9836\n",
      "Epoch 90/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0555 - binary_accuracy: 0.9831\n",
      "Epoch 91/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0553 - binary_accuracy: 0.9842\n",
      "Epoch 92/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0548 - binary_accuracy: 0.9829\n",
      "Epoch 93/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0555 - binary_accuracy: 0.9836\n",
      "Epoch 94/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0553 - binary_accuracy: 0.9838\n",
      "Epoch 95/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0551 - binary_accuracy: 0.9829\n",
      "Epoch 96/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0546 - binary_accuracy: 0.9836\n",
      "Epoch 97/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0550 - binary_accuracy: 0.9829\n",
      "Epoch 98/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0548 - binary_accuracy: 0.9824\n",
      "Epoch 99/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0554 - binary_accuracy: 0.9818\n",
      "Epoch 100/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0540 - binary_accuracy: 0.9827\n"
     ]
    }
   ],
   "source": [
    "modelo1_cv = KerasClassifier(build_fn=RedeNeural1, epochs=100, batch_size=10)\n",
    "resultados1 = cross_val_score(estimator = modelo1_cv, X = X2, y=y, cv=10, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-2iOU1FK75Eh"
   },
   "source": [
    "E agora vemos os resultados que geramos da nossa validação cruzada.\n",
    "\n",
    "A acurácia média aumentou assim como o desvio padrão aumentou um pouco."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104
    },
    "id": "Z1Fv2vho7OoF",
    "outputId": "526a4845-0fe6-445d-a838-dbff0aab3cba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados da validação cruzada : [0.976 0.98  0.986 0.984 0.98  0.976 0.91  0.982 0.984 0.982]\n",
      "\n",
      "Média dos resultados da validação cruzada : 0.9739999999999999\n",
      "\n",
      "Desvio padrão dos resultados da validação cruzada : 0.02155922076513897\n"
     ]
    }
   ],
   "source": [
    "print('Resultados da validação cruzada :',resultados1)\n",
    "print('')\n",
    "print('Média dos resultados da validação cruzada :',resultados1.mean())\n",
    "print('')\n",
    "print('Desvio padrão dos resultados da validação cruzada :',resultados1.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YqCq_uItfO9F"
   },
   "source": [
    "### Teste 2\n",
    "\n",
    "Inserindo *Dropout*, que é um algoritmo para treinamento de redes neurais, que se fundamenta na eliminação aleatória de neurônios durante o processo de aprendizagem, para evitar a sobreadaptação aos dados (*overfitting*).\n",
    "\n",
    "Vamos criar nosso modelo novamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "KNTLIgVO7Oda",
    "outputId": "e7f17879-0ae0-4b0d-d9ab-e8517b6ec397"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.5030 - binary_accuracy: 0.9030\n",
      "Epoch 2/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.3285 - binary_accuracy: 0.9062\n",
      "Epoch 3/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.2815 - binary_accuracy: 0.9128\n",
      "Epoch 4/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.2395 - binary_accuracy: 0.9218\n",
      "Epoch 5/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.2214 - binary_accuracy: 0.9342\n",
      "Epoch 6/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.1918 - binary_accuracy: 0.9423\n",
      "Epoch 7/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.1796 - binary_accuracy: 0.9448\n",
      "Epoch 8/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.1656 - binary_accuracy: 0.9492\n",
      "Epoch 9/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.1508 - binary_accuracy: 0.9532\n",
      "Epoch 10/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.1486 - binary_accuracy: 0.9507\n",
      "Epoch 11/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.1462 - binary_accuracy: 0.9557\n",
      "Epoch 12/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.1412 - binary_accuracy: 0.9540\n",
      "Epoch 13/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.1343 - binary_accuracy: 0.9560\n",
      "Epoch 14/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.1376 - binary_accuracy: 0.9520\n",
      "Epoch 15/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.1266 - binary_accuracy: 0.9578\n",
      "Epoch 16/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.1257 - binary_accuracy: 0.9585\n",
      "Epoch 17/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.1287 - binary_accuracy: 0.9582\n",
      "Epoch 18/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.1212 - binary_accuracy: 0.9575\n",
      "Epoch 19/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.1233 - binary_accuracy: 0.9563\n",
      "Epoch 20/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.1245 - binary_accuracy: 0.9563\n",
      "Epoch 21/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.1149 - binary_accuracy: 0.9605\n",
      "Epoch 22/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.1153 - binary_accuracy: 0.9615\n",
      "Epoch 23/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.1099 - binary_accuracy: 0.9575\n",
      "Epoch 24/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.1192 - binary_accuracy: 0.9585\n",
      "Epoch 25/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.1191 - binary_accuracy: 0.9588\n",
      "Epoch 26/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.1072 - binary_accuracy: 0.9635\n",
      "Epoch 27/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.1121 - binary_accuracy: 0.9622\n",
      "Epoch 28/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.1040 - binary_accuracy: 0.9635\n",
      "Epoch 29/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.1103 - binary_accuracy: 0.9630\n",
      "Epoch 30/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.1110 - binary_accuracy: 0.9607\n",
      "Epoch 31/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.1122 - binary_accuracy: 0.9597\n",
      "Epoch 32/100\n",
      "364/364 [==============================] - 1s 1ms/step - loss: 0.1106 - binary_accuracy: 0.9625\n",
      "Epoch 33/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.1083 - binary_accuracy: 0.9653\n",
      "Epoch 34/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.1039 - binary_accuracy: 0.9610\n",
      "Epoch 35/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.1109 - binary_accuracy: 0.9572\n",
      "Epoch 36/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.1113 - binary_accuracy: 0.9613\n",
      "Epoch 37/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.1037 - binary_accuracy: 0.9638\n",
      "Epoch 38/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.1044 - binary_accuracy: 0.9638\n",
      "Epoch 39/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.1052 - binary_accuracy: 0.9617\n",
      "Epoch 40/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.1044 - binary_accuracy: 0.9628\n",
      "Epoch 41/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.1092 - binary_accuracy: 0.9613\n",
      "Epoch 42/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.1040 - binary_accuracy: 0.9660\n",
      "Epoch 43/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.1094 - binary_accuracy: 0.9628\n",
      "Epoch 44/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.1000 - binary_accuracy: 0.9660\n",
      "Epoch 45/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.1048 - binary_accuracy: 0.9653\n",
      "Epoch 46/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.1111 - binary_accuracy: 0.9580\n",
      "Epoch 47/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.1003 - binary_accuracy: 0.9645\n",
      "Epoch 48/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.0982 - binary_accuracy: 0.9660\n",
      "Epoch 49/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.1030 - binary_accuracy: 0.9653\n",
      "Epoch 50/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.0965 - binary_accuracy: 0.9657\n",
      "Epoch 51/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.0997 - binary_accuracy: 0.9620\n",
      "Epoch 52/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.1012 - binary_accuracy: 0.9655\n",
      "Epoch 53/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.1012 - binary_accuracy: 0.9645\n",
      "Epoch 54/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.1090 - binary_accuracy: 0.9605\n",
      "Epoch 55/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.0973 - binary_accuracy: 0.9655\n",
      "Epoch 56/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.0953 - binary_accuracy: 0.9685\n",
      "Epoch 57/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.1029 - binary_accuracy: 0.9628\n",
      "Epoch 58/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.0981 - binary_accuracy: 0.9657\n",
      "Epoch 59/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.0950 - binary_accuracy: 0.9630\n",
      "Epoch 60/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.1010 - binary_accuracy: 0.9663\n",
      "Epoch 61/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.0939 - binary_accuracy: 0.9688\n",
      "Epoch 62/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.0952 - binary_accuracy: 0.9675\n",
      "Epoch 63/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.0980 - binary_accuracy: 0.9653\n",
      "Epoch 64/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.0947 - binary_accuracy: 0.9688\n",
      "Epoch 65/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.1049 - binary_accuracy: 0.9630\n",
      "Epoch 66/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.0985 - binary_accuracy: 0.9638\n",
      "Epoch 67/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.1023 - binary_accuracy: 0.9620\n",
      "Epoch 68/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.1010 - binary_accuracy: 0.9645\n",
      "Epoch 69/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.1021 - binary_accuracy: 0.9632\n",
      "Epoch 70/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.1022 - binary_accuracy: 0.9622\n",
      "Epoch 71/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.0948 - binary_accuracy: 0.9660\n",
      "Epoch 72/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.0957 - binary_accuracy: 0.9647\n",
      "Epoch 73/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.1007 - binary_accuracy: 0.9632\n",
      "Epoch 74/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.0990 - binary_accuracy: 0.9640\n",
      "Epoch 75/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.0993 - binary_accuracy: 0.9660\n",
      "Epoch 76/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.1018 - binary_accuracy: 0.9678\n",
      "Epoch 77/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.1012 - binary_accuracy: 0.9630\n",
      "Epoch 78/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.0965 - binary_accuracy: 0.9670\n",
      "Epoch 79/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.0916 - binary_accuracy: 0.9697\n",
      "Epoch 80/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.0947 - binary_accuracy: 0.9675\n",
      "Epoch 81/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.0920 - binary_accuracy: 0.9690\n",
      "Epoch 82/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.0954 - binary_accuracy: 0.9663\n",
      "Epoch 83/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.0974 - binary_accuracy: 0.9638\n",
      "Epoch 84/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.0984 - binary_accuracy: 0.9663\n",
      "Epoch 85/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.0955 - binary_accuracy: 0.9657\n",
      "Epoch 86/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.0967 - binary_accuracy: 0.9663\n",
      "Epoch 87/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.1046 - binary_accuracy: 0.9632\n",
      "Epoch 88/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.1004 - binary_accuracy: 0.9668\n",
      "Epoch 89/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.0911 - binary_accuracy: 0.9718\n",
      "Epoch 90/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.1016 - binary_accuracy: 0.9632\n",
      "Epoch 91/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.0969 - binary_accuracy: 0.9657\n",
      "Epoch 92/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.1048 - binary_accuracy: 0.9620\n",
      "Epoch 93/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.0922 - binary_accuracy: 0.9688\n",
      "Epoch 94/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.0993 - binary_accuracy: 0.9645\n",
      "Epoch 95/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.0950 - binary_accuracy: 0.9670\n",
      "Epoch 96/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.0938 - binary_accuracy: 0.9670\n",
      "Epoch 97/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.0925 - binary_accuracy: 0.9688\n",
      "Epoch 98/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.0983 - binary_accuracy: 0.9668\n",
      "Epoch 99/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.0945 - binary_accuracy: 0.9678\n",
      "Epoch 100/100\n",
      "364/364 [==============================] - 0s 1ms/step - loss: 0.0996 - binary_accuracy: 0.9665\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f0c70922eb8>"
      ]
     },
     "execution_count": 41,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelo2=Sequential()\n",
    "modelo2.add(Dense(units=6, activation='relu', kernel_initializer='random_uniform', input_dim=11))\n",
    "modelo2.add(Dropout(0.2))\n",
    "modelo2.add(Dense(units=6, activation='relu', kernel_initializer='random_uniform'))\n",
    "modelo2.add(Dropout(0.2))\n",
    "modelo2.add(Dense(units=1,activation='sigmoid'))\n",
    "modelo2.compile(optimizer='adam',loss='binary_crossentropy', metrics=['binary_accuracy'])\n",
    "modelo2.fit(X_treino,y_treino, batch_size=11, epochs = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TddVUt_U8W8s"
   },
   "source": [
    "Vamos gerar as previsões e realizar a substituição que realizamos para que os valores sejam 0 ou 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t8rg4E1T7OcC"
   },
   "outputs": [],
   "source": [
    "previsoes2=modelo2.predict(X_teste)\n",
    "\n",
    "lista=[]\n",
    "for i in previsoes2:\n",
    "  if i > 0.5:\n",
    "    i=1\n",
    "  else:\n",
    "    i=0\n",
    "  lista.append(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T7Bcq8I18Zbg"
   },
   "source": [
    "Criando *dataset* com os valores reais e previstos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 416
    },
    "id": "XYvzKUj67OXd",
    "outputId": "d390d7ce-9e2d-4d81-ad33-42f3e49c6f43"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Personal Loan</th>\n",
       "      <th>prev</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1501</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2586</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2653</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1055</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>705</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4711</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2313</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3214</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2732</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1926</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Personal Loan  prev\n",
       "1501              0     0\n",
       "2586              1     1\n",
       "2653              0     0\n",
       "1055              0     0\n",
       "705               0     0\n",
       "...             ...   ...\n",
       "4711              0     0\n",
       "2313              0     0\n",
       "3214              0     0\n",
       "2732              0     0\n",
       "1926              0     0\n",
       "\n",
       "[1000 rows x 2 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_teste4=y_teste\n",
    "y_teste4=pd.DataFrame(y_teste2)\n",
    "y_teste4['prev']=pd.DataFrame(lista, index=y_teste4.index)\n",
    "y_teste4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-kb8Gt2p8hpq"
   },
   "source": [
    "#### Acurácia\n",
    "\n",
    "A acurácia foi um pouco menor que o modelo anterior, mas igual a do modelo original."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "4LgsWU5c7OVt",
    "outputId": "697ac92c-ea09-4867-fbc5-0a77bb72398a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A acurácia do modelo de Rede Neural foi de 98.3 %\n"
     ]
    }
   ],
   "source": [
    "print('A acurácia do modelo de Rede Neural foi de',(accuracy_score(y_teste4['Personal Loan'],y_teste4['prev']))*100,'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BJlXrAB38rvi"
   },
   "source": [
    "#### Matriz de confusão\n",
    "\n",
    "O modelo errou mais em relação ao anterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "id": "4JREXcb27OQ9",
    "outputId": "eb4123c9-5ddb-47c5-932d-2e25748ff6b2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[893   2]\n",
      " [ 15  90]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_teste4['Personal Loan'],y_teste4['prev']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pzC3hSEO80G7"
   },
   "source": [
    "#### Métricas de avaliação\n",
    "\n",
    "Comparando com os modelos anteriores, houve uma piora no desempenho dessa nova rede neural."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "id": "vKEeNNY87ONB",
    "outputId": "4a391cdf-149a-430f-9dcf-695884586256"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99       895\n",
      "           1       0.98      0.86      0.91       105\n",
      "\n",
      "    accuracy                           0.98      1000\n",
      "   macro avg       0.98      0.93      0.95      1000\n",
      "weighted avg       0.98      0.98      0.98      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_teste4['Personal Loan'],y_teste4['prev']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zFHU50s19UfH"
   },
   "source": [
    "Pesos da rede neural."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 433
    },
    "id": "42rsQwJl7OLI",
    "outputId": "50cadc03-1450-4f67-a132-ad19f786d50b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[-3.8575325e-02,  5.9925351e-02,  3.9990064e-02, -1.3791503e-01,\n",
      "        -8.9924760e-02,  2.1561614e-01],\n",
      "       [ 8.3848536e-02, -6.7914121e-02, -2.1505122e-01,  1.6622497e-01,\n",
      "         9.6192814e-02, -7.4593306e-02],\n",
      "       [ 3.4802631e-01, -1.3632306e+00, -1.3330355e+00,  1.6723599e-01,\n",
      "         3.8256362e-01, -1.4042505e+00],\n",
      "       [ 2.4737675e-01,  1.4265648e-01,  3.8115278e-02, -2.6269811e-01,\n",
      "         2.1694817e-01,  2.0917353e-01],\n",
      "       [-2.2841746e-02, -6.8935990e-01, -3.7196684e-01, -6.1358828e-03,\n",
      "         1.3313382e-03, -4.1452959e-01],\n",
      "       [ 3.9401847e-01,  2.4626887e-01,  3.0131412e-01, -6.8221748e-01,\n",
      "         4.2106429e-01,  1.7552319e-01],\n",
      "       [-1.8150639e-03, -5.2451592e-02,  2.7029267e-02, -1.3822905e-02,\n",
      "        -1.7487695e-02, -1.2545277e-01],\n",
      "       [-8.0143608e-02, -8.1743319e-03, -1.2276497e-01, -7.3138669e-02,\n",
      "        -2.6627347e-01,  1.0825288e-01],\n",
      "       [ 4.2848006e-01, -6.1834073e-01, -5.3965032e-01, -2.0978883e-01,\n",
      "         5.6087106e-01, -9.0553659e-01],\n",
      "       [-5.4144654e-02,  4.7654856e-02,  9.3799710e-02,  6.2760226e-02,\n",
      "        -7.1673028e-02,  1.3097177e-01],\n",
      "       [-1.8121821e-01,  9.8297738e-02,  8.3676681e-02,  6.4574987e-02,\n",
      "        -2.4016808e-01,  3.2427576e-01]], dtype=float32), array([-1.0978539 ,  0.25123897,  0.2886681 ,  1.1018943 , -1.2032462 ,\n",
      "        0.1834936 ], dtype=float32)]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(modelo2.layers[0].get_weights())\n",
    "print(modelo2.layers[1].get_weights())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nlO4nxSw9YKg"
   },
   "source": [
    "Mesmo com o desempenho inferior desse novo modelo, vamos aplicar a validação cruzada.\n",
    "\n",
    "Vamos criar a função para criar a rede neural."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VOY4ahed7OJY"
   },
   "outputs": [],
   "source": [
    "def RedeNeural2():\n",
    "  modelo2=Sequential()\n",
    "  modelo2.add(Dense(units=6, activation='relu', kernel_initializer='random_uniform', input_dim=11))\n",
    "  modelo2.add(Dropout(0.2))\n",
    "  modelo2.add(Dense(units=6, activation='relu', kernel_initializer='random_uniform'))\n",
    "  modelo2.add(Dropout(0.2))\n",
    "  modelo2.add(Dense(units=1,activation='sigmoid'))\n",
    "  modelo2.compile(optimizer='adam',loss='binary_crossentropy', metrics=['binary_accuracy'])\n",
    "\n",
    "  return modelo2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HhwQScc59-22"
   },
   "source": [
    "E aplicar a validação cruzada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "AUdksevX7OFJ",
    "outputId": "757f64bd-a579-46f8-d183-024ffd3e85a5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.3870 - binary_accuracy: 0.9000\n",
      "Epoch 2/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.2296 - binary_accuracy: 0.9044\n",
      "Epoch 3/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.2099 - binary_accuracy: 0.9044\n",
      "Epoch 4/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.2014 - binary_accuracy: 0.9044\n",
      "Epoch 5/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1910 - binary_accuracy: 0.9044\n",
      "Epoch 6/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1897 - binary_accuracy: 0.9044\n",
      "Epoch 7/100\n",
      "450/450 [==============================] - 0s 998us/step - loss: 0.1867 - binary_accuracy: 0.9044\n",
      "Epoch 8/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1847 - binary_accuracy: 0.9044\n",
      "Epoch 9/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1862 - binary_accuracy: 0.9044\n",
      "Epoch 10/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1851 - binary_accuracy: 0.9044\n",
      "Epoch 11/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1786 - binary_accuracy: 0.9044\n",
      "Epoch 12/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1791 - binary_accuracy: 0.9044\n",
      "Epoch 13/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1783 - binary_accuracy: 0.9044\n",
      "Epoch 14/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1661 - binary_accuracy: 0.9044\n",
      "Epoch 15/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1591 - binary_accuracy: 0.9044\n",
      "Epoch 16/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1564 - binary_accuracy: 0.9044\n",
      "Epoch 17/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1518 - binary_accuracy: 0.9044\n",
      "Epoch 18/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1509 - binary_accuracy: 0.9044\n",
      "Epoch 19/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1472 - binary_accuracy: 0.9058\n",
      "Epoch 20/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1439 - binary_accuracy: 0.9338\n",
      "Epoch 21/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1400 - binary_accuracy: 0.9382\n",
      "Epoch 22/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1401 - binary_accuracy: 0.9360\n",
      "Epoch 23/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1445 - binary_accuracy: 0.9340\n",
      "Epoch 24/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1386 - binary_accuracy: 0.9420\n",
      "Epoch 25/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1430 - binary_accuracy: 0.9338\n",
      "Epoch 26/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1354 - binary_accuracy: 0.9362\n",
      "Epoch 27/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1318 - binary_accuracy: 0.9444\n",
      "Epoch 28/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1382 - binary_accuracy: 0.9382\n",
      "Epoch 29/100\n",
      "450/450 [==============================] - 0s 996us/step - loss: 0.1315 - binary_accuracy: 0.9438\n",
      "Epoch 30/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1353 - binary_accuracy: 0.9424\n",
      "Epoch 31/100\n",
      "450/450 [==============================] - 0s 967us/step - loss: 0.1335 - binary_accuracy: 0.9440\n",
      "Epoch 32/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1342 - binary_accuracy: 0.9396\n",
      "Epoch 33/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1317 - binary_accuracy: 0.9453\n",
      "Epoch 34/100\n",
      "450/450 [==============================] - 0s 993us/step - loss: 0.1331 - binary_accuracy: 0.9418\n",
      "Epoch 35/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1274 - binary_accuracy: 0.9462\n",
      "Epoch 36/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1316 - binary_accuracy: 0.9440\n",
      "Epoch 37/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1319 - binary_accuracy: 0.9440\n",
      "Epoch 38/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1273 - binary_accuracy: 0.9476\n",
      "Epoch 39/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1282 - binary_accuracy: 0.9469\n",
      "Epoch 40/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1306 - binary_accuracy: 0.9467\n",
      "Epoch 41/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1299 - binary_accuracy: 0.9469\n",
      "Epoch 42/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1294 - binary_accuracy: 0.9444\n",
      "Epoch 43/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1252 - binary_accuracy: 0.9504\n",
      "Epoch 44/100\n",
      "450/450 [==============================] - 0s 998us/step - loss: 0.1276 - binary_accuracy: 0.9436\n",
      "Epoch 45/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1350 - binary_accuracy: 0.9436\n",
      "Epoch 46/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1305 - binary_accuracy: 0.9440\n",
      "Epoch 47/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1286 - binary_accuracy: 0.9467\n",
      "Epoch 48/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1345 - binary_accuracy: 0.9400\n",
      "Epoch 49/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1308 - binary_accuracy: 0.9447\n",
      "Epoch 50/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1250 - binary_accuracy: 0.9487\n",
      "Epoch 51/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1320 - binary_accuracy: 0.9376\n",
      "Epoch 52/100\n",
      "450/450 [==============================] - 0s 995us/step - loss: 0.1332 - binary_accuracy: 0.9460\n",
      "Epoch 53/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1275 - binary_accuracy: 0.9489\n",
      "Epoch 54/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1365 - binary_accuracy: 0.9411\n",
      "Epoch 55/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1262 - binary_accuracy: 0.9491\n",
      "Epoch 56/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1323 - binary_accuracy: 0.9420\n",
      "Epoch 57/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1337 - binary_accuracy: 0.9400\n",
      "Epoch 58/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1275 - binary_accuracy: 0.9413\n",
      "Epoch 59/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1292 - binary_accuracy: 0.9471\n",
      "Epoch 60/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1257 - binary_accuracy: 0.9456\n",
      "Epoch 61/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1302 - binary_accuracy: 0.9429\n",
      "Epoch 62/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1316 - binary_accuracy: 0.9407\n",
      "Epoch 63/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1269 - binary_accuracy: 0.9453\n",
      "Epoch 64/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1308 - binary_accuracy: 0.9411\n",
      "Epoch 65/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1211 - binary_accuracy: 0.9487\n",
      "Epoch 66/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1383 - binary_accuracy: 0.9400\n",
      "Epoch 67/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1258 - binary_accuracy: 0.9458\n",
      "Epoch 68/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1328 - binary_accuracy: 0.9464\n",
      "Epoch 69/100\n",
      "450/450 [==============================] - 0s 997us/step - loss: 0.1357 - binary_accuracy: 0.9409\n",
      "Epoch 70/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1335 - binary_accuracy: 0.9404\n",
      "Epoch 71/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1310 - binary_accuracy: 0.9473\n",
      "Epoch 72/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1320 - binary_accuracy: 0.9436\n",
      "Epoch 73/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1276 - binary_accuracy: 0.9471\n",
      "Epoch 74/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1267 - binary_accuracy: 0.9478\n",
      "Epoch 75/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1349 - binary_accuracy: 0.9382\n",
      "Epoch 76/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1265 - binary_accuracy: 0.9438\n",
      "Epoch 77/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1248 - binary_accuracy: 0.9447\n",
      "Epoch 78/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1270 - binary_accuracy: 0.9449\n",
      "Epoch 79/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1335 - binary_accuracy: 0.9411\n",
      "Epoch 80/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1282 - binary_accuracy: 0.9469\n",
      "Epoch 81/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1291 - binary_accuracy: 0.9433\n",
      "Epoch 82/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1197 - binary_accuracy: 0.9522\n",
      "Epoch 83/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1320 - binary_accuracy: 0.9433\n",
      "Epoch 84/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1290 - binary_accuracy: 0.9500\n",
      "Epoch 85/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1284 - binary_accuracy: 0.9456\n",
      "Epoch 86/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1265 - binary_accuracy: 0.9471\n",
      "Epoch 87/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1347 - binary_accuracy: 0.9447\n",
      "Epoch 88/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1227 - binary_accuracy: 0.9520\n",
      "Epoch 89/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1299 - binary_accuracy: 0.9438\n",
      "Epoch 90/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1262 - binary_accuracy: 0.9469\n",
      "Epoch 91/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1255 - binary_accuracy: 0.9482\n",
      "Epoch 92/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1316 - binary_accuracy: 0.9451\n",
      "Epoch 93/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1287 - binary_accuracy: 0.9493\n",
      "Epoch 94/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1249 - binary_accuracy: 0.9442\n",
      "Epoch 95/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1247 - binary_accuracy: 0.9456\n",
      "Epoch 96/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1238 - binary_accuracy: 0.9524\n",
      "Epoch 97/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1282 - binary_accuracy: 0.9478\n",
      "Epoch 98/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1309 - binary_accuracy: 0.9460\n",
      "Epoch 99/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1292 - binary_accuracy: 0.9502\n",
      "Epoch 100/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1243 - binary_accuracy: 0.9493\n",
      "Epoch 1/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.3752 - binary_accuracy: 0.9022\n",
      "Epoch 2/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.2352 - binary_accuracy: 0.9036\n",
      "Epoch 3/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.2185 - binary_accuracy: 0.9036\n",
      "Epoch 4/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.2051 - binary_accuracy: 0.9036\n",
      "Epoch 5/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.2033 - binary_accuracy: 0.9036\n",
      "Epoch 6/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1949 - binary_accuracy: 0.9036\n",
      "Epoch 7/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1921 - binary_accuracy: 0.9036\n",
      "Epoch 8/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1917 - binary_accuracy: 0.9036\n",
      "Epoch 9/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1904 - binary_accuracy: 0.9036\n",
      "Epoch 10/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1821 - binary_accuracy: 0.9036\n",
      "Epoch 11/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1786 - binary_accuracy: 0.9036\n",
      "Epoch 12/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1735 - binary_accuracy: 0.9036\n",
      "Epoch 13/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1639 - binary_accuracy: 0.9036\n",
      "Epoch 14/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1630 - binary_accuracy: 0.9036\n",
      "Epoch 15/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1598 - binary_accuracy: 0.9036\n",
      "Epoch 16/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1592 - binary_accuracy: 0.9036\n",
      "Epoch 17/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1576 - binary_accuracy: 0.9036\n",
      "Epoch 18/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1517 - binary_accuracy: 0.9036\n",
      "Epoch 19/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1475 - binary_accuracy: 0.9036\n",
      "Epoch 20/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1501 - binary_accuracy: 0.9158\n",
      "Epoch 21/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1473 - binary_accuracy: 0.9278\n",
      "Epoch 22/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1495 - binary_accuracy: 0.9296\n",
      "Epoch 23/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1469 - binary_accuracy: 0.9333\n",
      "Epoch 24/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1416 - binary_accuracy: 0.9307\n",
      "Epoch 25/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1417 - binary_accuracy: 0.9353\n",
      "Epoch 26/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1407 - binary_accuracy: 0.9333\n",
      "Epoch 27/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1476 - binary_accuracy: 0.9282\n",
      "Epoch 28/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1424 - binary_accuracy: 0.9340\n",
      "Epoch 29/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1373 - binary_accuracy: 0.9349\n",
      "Epoch 30/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1375 - binary_accuracy: 0.9396\n",
      "Epoch 31/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1414 - binary_accuracy: 0.9353\n",
      "Epoch 32/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1374 - binary_accuracy: 0.9384\n",
      "Epoch 33/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1322 - binary_accuracy: 0.9400\n",
      "Epoch 34/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1436 - binary_accuracy: 0.9329\n",
      "Epoch 35/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1391 - binary_accuracy: 0.9382\n",
      "Epoch 36/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1355 - binary_accuracy: 0.9338\n",
      "Epoch 37/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1363 - binary_accuracy: 0.9376\n",
      "Epoch 38/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1391 - binary_accuracy: 0.9378\n",
      "Epoch 39/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1333 - binary_accuracy: 0.9360\n",
      "Epoch 40/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1365 - binary_accuracy: 0.9402\n",
      "Epoch 41/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1404 - binary_accuracy: 0.9382\n",
      "Epoch 42/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1337 - binary_accuracy: 0.9360\n",
      "Epoch 43/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1434 - binary_accuracy: 0.9378\n",
      "Epoch 44/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1397 - binary_accuracy: 0.9364\n",
      "Epoch 45/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1364 - binary_accuracy: 0.9387\n",
      "Epoch 46/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1413 - binary_accuracy: 0.9358\n",
      "Epoch 47/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1483 - binary_accuracy: 0.9298\n",
      "Epoch 48/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1368 - binary_accuracy: 0.9362\n",
      "Epoch 49/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1392 - binary_accuracy: 0.9384\n",
      "Epoch 50/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1333 - binary_accuracy: 0.9400\n",
      "Epoch 51/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1396 - binary_accuracy: 0.9378\n",
      "Epoch 52/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1376 - binary_accuracy: 0.9320\n",
      "Epoch 53/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1327 - binary_accuracy: 0.9409\n",
      "Epoch 54/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1362 - binary_accuracy: 0.9364\n",
      "Epoch 55/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1369 - binary_accuracy: 0.9389\n",
      "Epoch 56/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1332 - binary_accuracy: 0.9402\n",
      "Epoch 57/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1320 - binary_accuracy: 0.9393\n",
      "Epoch 58/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1384 - binary_accuracy: 0.9371\n",
      "Epoch 59/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1341 - binary_accuracy: 0.9376\n",
      "Epoch 60/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1307 - binary_accuracy: 0.9424\n",
      "Epoch 61/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1361 - binary_accuracy: 0.9344\n",
      "Epoch 62/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1367 - binary_accuracy: 0.9416\n",
      "Epoch 63/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1357 - binary_accuracy: 0.9344\n",
      "Epoch 64/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1424 - binary_accuracy: 0.9313\n",
      "Epoch 65/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1390 - binary_accuracy: 0.9298\n",
      "Epoch 66/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1415 - binary_accuracy: 0.9336\n",
      "Epoch 67/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1330 - binary_accuracy: 0.9451\n",
      "Epoch 68/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1342 - binary_accuracy: 0.9438\n",
      "Epoch 69/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1336 - binary_accuracy: 0.9391\n",
      "Epoch 70/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1303 - binary_accuracy: 0.9436\n",
      "Epoch 71/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1335 - binary_accuracy: 0.9356\n",
      "Epoch 72/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1336 - binary_accuracy: 0.9367\n",
      "Epoch 73/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1318 - binary_accuracy: 0.9420\n",
      "Epoch 74/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1385 - binary_accuracy: 0.9340\n",
      "Epoch 75/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1378 - binary_accuracy: 0.9336\n",
      "Epoch 76/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1383 - binary_accuracy: 0.9358\n",
      "Epoch 77/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1353 - binary_accuracy: 0.9387\n",
      "Epoch 78/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1370 - binary_accuracy: 0.9376\n",
      "Epoch 79/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1318 - binary_accuracy: 0.9409\n",
      "Epoch 80/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1337 - binary_accuracy: 0.9373\n",
      "Epoch 81/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1369 - binary_accuracy: 0.9378\n",
      "Epoch 82/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1359 - binary_accuracy: 0.9373\n",
      "Epoch 83/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1314 - binary_accuracy: 0.9400\n",
      "Epoch 84/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1352 - binary_accuracy: 0.9402\n",
      "Epoch 85/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1465 - binary_accuracy: 0.9329\n",
      "Epoch 86/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1375 - binary_accuracy: 0.9376\n",
      "Epoch 87/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1343 - binary_accuracy: 0.9380\n",
      "Epoch 88/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1347 - binary_accuracy: 0.9396\n",
      "Epoch 89/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1361 - binary_accuracy: 0.9349\n",
      "Epoch 90/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1429 - binary_accuracy: 0.9349\n",
      "Epoch 91/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1280 - binary_accuracy: 0.9416\n",
      "Epoch 92/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1404 - binary_accuracy: 0.9358\n",
      "Epoch 93/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1420 - binary_accuracy: 0.9329\n",
      "Epoch 94/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1298 - binary_accuracy: 0.9416\n",
      "Epoch 95/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1343 - binary_accuracy: 0.9400\n",
      "Epoch 96/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1377 - binary_accuracy: 0.9349\n",
      "Epoch 97/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1368 - binary_accuracy: 0.9349\n",
      "Epoch 98/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1357 - binary_accuracy: 0.9411\n",
      "Epoch 99/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1382 - binary_accuracy: 0.9360\n",
      "Epoch 100/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1335 - binary_accuracy: 0.9420\n",
      "Epoch 1/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.3972 - binary_accuracy: 0.9036\n",
      "Epoch 2/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.2372 - binary_accuracy: 0.9058\n",
      "Epoch 3/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.2183 - binary_accuracy: 0.9058\n",
      "Epoch 4/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.2079 - binary_accuracy: 0.9058\n",
      "Epoch 5/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.2002 - binary_accuracy: 0.9058\n",
      "Epoch 6/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1972 - binary_accuracy: 0.9058\n",
      "Epoch 7/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1980 - binary_accuracy: 0.9058\n",
      "Epoch 8/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1927 - binary_accuracy: 0.9058\n",
      "Epoch 9/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1913 - binary_accuracy: 0.9058\n",
      "Epoch 10/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1904 - binary_accuracy: 0.9058\n",
      "Epoch 11/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1859 - binary_accuracy: 0.9058\n",
      "Epoch 12/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1864 - binary_accuracy: 0.9058\n",
      "Epoch 13/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1843 - binary_accuracy: 0.9058\n",
      "Epoch 14/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1768 - binary_accuracy: 0.9058\n",
      "Epoch 15/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1751 - binary_accuracy: 0.9058\n",
      "Epoch 16/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1729 - binary_accuracy: 0.9058\n",
      "Epoch 17/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1678 - binary_accuracy: 0.9058\n",
      "Epoch 18/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1711 - binary_accuracy: 0.9058\n",
      "Epoch 19/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1644 - binary_accuracy: 0.9058\n",
      "Epoch 20/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1641 - binary_accuracy: 0.9058\n",
      "Epoch 21/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1592 - binary_accuracy: 0.9058\n",
      "Epoch 22/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1543 - binary_accuracy: 0.9058\n",
      "Epoch 23/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1541 - binary_accuracy: 0.9058\n",
      "Epoch 24/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1548 - binary_accuracy: 0.9058\n",
      "Epoch 25/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1540 - binary_accuracy: 0.9058\n",
      "Epoch 26/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1505 - binary_accuracy: 0.9058\n",
      "Epoch 27/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1448 - binary_accuracy: 0.9113\n",
      "Epoch 28/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1454 - binary_accuracy: 0.9324\n",
      "Epoch 29/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1448 - binary_accuracy: 0.9313\n",
      "Epoch 30/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1412 - binary_accuracy: 0.9302\n",
      "Epoch 31/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1456 - binary_accuracy: 0.9304\n",
      "Epoch 32/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1449 - binary_accuracy: 0.9278\n",
      "Epoch 33/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1396 - binary_accuracy: 0.9342\n",
      "Epoch 34/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1456 - binary_accuracy: 0.9284\n",
      "Epoch 35/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1433 - binary_accuracy: 0.9291\n",
      "Epoch 36/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1402 - binary_accuracy: 0.9338\n",
      "Epoch 37/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1440 - binary_accuracy: 0.9296\n",
      "Epoch 38/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1453 - binary_accuracy: 0.9311\n",
      "Epoch 39/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1400 - binary_accuracy: 0.9347\n",
      "Epoch 40/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1445 - binary_accuracy: 0.9284\n",
      "Epoch 41/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1430 - binary_accuracy: 0.9367\n",
      "Epoch 42/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1370 - binary_accuracy: 0.9320\n",
      "Epoch 43/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1345 - binary_accuracy: 0.9378\n",
      "Epoch 44/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1388 - binary_accuracy: 0.9338\n",
      "Epoch 45/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1327 - binary_accuracy: 0.9389\n",
      "Epoch 46/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1390 - binary_accuracy: 0.9356\n",
      "Epoch 47/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1362 - binary_accuracy: 0.9304\n",
      "Epoch 48/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1433 - binary_accuracy: 0.9347\n",
      "Epoch 49/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1371 - binary_accuracy: 0.9307\n",
      "Epoch 50/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1409 - binary_accuracy: 0.9280\n",
      "Epoch 51/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1424 - binary_accuracy: 0.9284\n",
      "Epoch 52/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1380 - binary_accuracy: 0.9360\n",
      "Epoch 53/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1452 - binary_accuracy: 0.9271\n",
      "Epoch 54/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1331 - binary_accuracy: 0.9409\n",
      "Epoch 55/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1343 - binary_accuracy: 0.9364\n",
      "Epoch 56/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1409 - binary_accuracy: 0.9311\n",
      "Epoch 57/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1293 - binary_accuracy: 0.9393\n",
      "Epoch 58/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1389 - binary_accuracy: 0.9356\n",
      "Epoch 59/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1418 - binary_accuracy: 0.9269\n",
      "Epoch 60/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1388 - binary_accuracy: 0.9329\n",
      "Epoch 61/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1363 - binary_accuracy: 0.9322\n",
      "Epoch 62/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1359 - binary_accuracy: 0.9391\n",
      "Epoch 63/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1386 - binary_accuracy: 0.9322\n",
      "Epoch 64/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1382 - binary_accuracy: 0.9302\n",
      "Epoch 65/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1418 - binary_accuracy: 0.9300\n",
      "Epoch 66/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1353 - binary_accuracy: 0.9376\n",
      "Epoch 67/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1364 - binary_accuracy: 0.9382\n",
      "Epoch 68/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1377 - binary_accuracy: 0.9362\n",
      "Epoch 69/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1421 - binary_accuracy: 0.9300\n",
      "Epoch 70/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1388 - binary_accuracy: 0.9309\n",
      "Epoch 71/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1401 - binary_accuracy: 0.9307\n",
      "Epoch 72/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1390 - binary_accuracy: 0.9284\n",
      "Epoch 73/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1358 - binary_accuracy: 0.9362\n",
      "Epoch 74/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1357 - binary_accuracy: 0.9320\n",
      "Epoch 75/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1290 - binary_accuracy: 0.9376\n",
      "Epoch 76/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1333 - binary_accuracy: 0.9336\n",
      "Epoch 77/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1350 - binary_accuracy: 0.9318\n",
      "Epoch 78/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1416 - binary_accuracy: 0.9311\n",
      "Epoch 79/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1394 - binary_accuracy: 0.9313\n",
      "Epoch 80/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1410 - binary_accuracy: 0.9302\n",
      "Epoch 81/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1389 - binary_accuracy: 0.9336\n",
      "Epoch 82/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1439 - binary_accuracy: 0.9296\n",
      "Epoch 83/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1413 - binary_accuracy: 0.9322\n",
      "Epoch 84/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1386 - binary_accuracy: 0.9340\n",
      "Epoch 85/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1349 - binary_accuracy: 0.9336\n",
      "Epoch 86/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1272 - binary_accuracy: 0.9382\n",
      "Epoch 87/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1363 - binary_accuracy: 0.9311\n",
      "Epoch 88/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1339 - binary_accuracy: 0.9338\n",
      "Epoch 89/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1353 - binary_accuracy: 0.9311\n",
      "Epoch 90/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1334 - binary_accuracy: 0.9367\n",
      "Epoch 91/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1363 - binary_accuracy: 0.9342\n",
      "Epoch 92/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1385 - binary_accuracy: 0.9338\n",
      "Epoch 93/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1371 - binary_accuracy: 0.9378\n",
      "Epoch 94/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1361 - binary_accuracy: 0.9376\n",
      "Epoch 95/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1352 - binary_accuracy: 0.9369\n",
      "Epoch 96/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1356 - binary_accuracy: 0.9384\n",
      "Epoch 97/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1389 - binary_accuracy: 0.9356\n",
      "Epoch 98/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1350 - binary_accuracy: 0.9327\n",
      "Epoch 99/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1364 - binary_accuracy: 0.9338\n",
      "Epoch 100/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1384 - binary_accuracy: 0.9356\n",
      "Epoch 1/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.3991 - binary_accuracy: 0.9027\n",
      "Epoch 2/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.2446 - binary_accuracy: 0.9040\n",
      "Epoch 3/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.2147 - binary_accuracy: 0.9040\n",
      "Epoch 4/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1944 - binary_accuracy: 0.9040\n",
      "Epoch 5/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1811 - binary_accuracy: 0.9040\n",
      "Epoch 6/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1735 - binary_accuracy: 0.9040\n",
      "Epoch 7/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1663 - binary_accuracy: 0.9040\n",
      "Epoch 8/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1631 - binary_accuracy: 0.9040\n",
      "Epoch 9/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1580 - binary_accuracy: 0.9040\n",
      "Epoch 10/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1608 - binary_accuracy: 0.9040\n",
      "Epoch 11/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1588 - binary_accuracy: 0.9040\n",
      "Epoch 12/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1559 - binary_accuracy: 0.9040\n",
      "Epoch 13/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1545 - binary_accuracy: 0.9040\n",
      "Epoch 14/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1537 - binary_accuracy: 0.9040\n",
      "Epoch 15/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1524 - binary_accuracy: 0.9040\n",
      "Epoch 16/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1525 - binary_accuracy: 0.9040\n",
      "Epoch 17/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1465 - binary_accuracy: 0.9080\n",
      "Epoch 18/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1528 - binary_accuracy: 0.9060\n",
      "Epoch 19/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1530 - binary_accuracy: 0.9142\n",
      "Epoch 20/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1515 - binary_accuracy: 0.9162\n",
      "Epoch 21/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1557 - binary_accuracy: 0.9144\n",
      "Epoch 22/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1494 - binary_accuracy: 0.9204\n",
      "Epoch 23/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1441 - binary_accuracy: 0.9240\n",
      "Epoch 24/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1532 - binary_accuracy: 0.9131\n",
      "Epoch 25/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1504 - binary_accuracy: 0.9187\n",
      "Epoch 26/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1479 - binary_accuracy: 0.9253\n",
      "Epoch 27/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1468 - binary_accuracy: 0.9207\n",
      "Epoch 28/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1516 - binary_accuracy: 0.9193\n",
      "Epoch 29/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1553 - binary_accuracy: 0.9138\n",
      "Epoch 30/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1514 - binary_accuracy: 0.9171\n",
      "Epoch 31/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1529 - binary_accuracy: 0.9164\n",
      "Epoch 32/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1503 - binary_accuracy: 0.9187\n",
      "Epoch 33/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1500 - binary_accuracy: 0.9173\n",
      "Epoch 34/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1475 - binary_accuracy: 0.9200\n",
      "Epoch 35/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1484 - binary_accuracy: 0.9196\n",
      "Epoch 36/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1439 - binary_accuracy: 0.9207\n",
      "Epoch 37/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1476 - binary_accuracy: 0.9178\n",
      "Epoch 38/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1435 - binary_accuracy: 0.9251\n",
      "Epoch 39/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1435 - binary_accuracy: 0.9242\n",
      "Epoch 40/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1421 - binary_accuracy: 0.9247\n",
      "Epoch 41/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1441 - binary_accuracy: 0.9251\n",
      "Epoch 42/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1449 - binary_accuracy: 0.9247\n",
      "Epoch 43/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1460 - binary_accuracy: 0.9258\n",
      "Epoch 44/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1462 - binary_accuracy: 0.9209\n",
      "Epoch 45/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1436 - binary_accuracy: 0.9264\n",
      "Epoch 46/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1475 - binary_accuracy: 0.9227\n",
      "Epoch 47/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1480 - binary_accuracy: 0.9231\n",
      "Epoch 48/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1438 - binary_accuracy: 0.9198\n",
      "Epoch 49/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1441 - binary_accuracy: 0.9198\n",
      "Epoch 50/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1447 - binary_accuracy: 0.9240\n",
      "Epoch 51/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1451 - binary_accuracy: 0.9191\n",
      "Epoch 52/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1516 - binary_accuracy: 0.9218\n",
      "Epoch 53/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1483 - binary_accuracy: 0.9182\n",
      "Epoch 54/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1459 - binary_accuracy: 0.9176\n",
      "Epoch 55/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1455 - binary_accuracy: 0.9231\n",
      "Epoch 56/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1424 - binary_accuracy: 0.9224\n",
      "Epoch 57/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1461 - binary_accuracy: 0.9213\n",
      "Epoch 58/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1490 - binary_accuracy: 0.9216\n",
      "Epoch 59/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1441 - binary_accuracy: 0.9238\n",
      "Epoch 60/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1480 - binary_accuracy: 0.9209\n",
      "Epoch 61/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1410 - binary_accuracy: 0.9240\n",
      "Epoch 62/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1455 - binary_accuracy: 0.9276\n",
      "Epoch 63/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1462 - binary_accuracy: 0.9184\n",
      "Epoch 64/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1348 - binary_accuracy: 0.9311\n",
      "Epoch 65/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1512 - binary_accuracy: 0.9160\n",
      "Epoch 66/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1474 - binary_accuracy: 0.9196\n",
      "Epoch 67/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1443 - binary_accuracy: 0.9273\n",
      "Epoch 68/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1442 - binary_accuracy: 0.9196\n",
      "Epoch 69/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1467 - binary_accuracy: 0.9227\n",
      "Epoch 70/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1392 - binary_accuracy: 0.9278\n",
      "Epoch 71/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1471 - binary_accuracy: 0.9233\n",
      "Epoch 72/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1444 - binary_accuracy: 0.9238\n",
      "Epoch 73/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1426 - binary_accuracy: 0.9262\n",
      "Epoch 74/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1443 - binary_accuracy: 0.9202\n",
      "Epoch 75/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1395 - binary_accuracy: 0.9311\n",
      "Epoch 76/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1467 - binary_accuracy: 0.9236\n",
      "Epoch 77/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1433 - binary_accuracy: 0.9291\n",
      "Epoch 78/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1473 - binary_accuracy: 0.9207\n",
      "Epoch 79/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1441 - binary_accuracy: 0.9276\n",
      "Epoch 80/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1427 - binary_accuracy: 0.9251\n",
      "Epoch 81/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1452 - binary_accuracy: 0.9233\n",
      "Epoch 82/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1421 - binary_accuracy: 0.9280\n",
      "Epoch 83/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1447 - binary_accuracy: 0.9258\n",
      "Epoch 84/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1498 - binary_accuracy: 0.9218\n",
      "Epoch 85/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1372 - binary_accuracy: 0.9349\n",
      "Epoch 86/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1437 - binary_accuracy: 0.9238\n",
      "Epoch 87/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1422 - binary_accuracy: 0.9307\n",
      "Epoch 88/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1414 - binary_accuracy: 0.9220\n",
      "Epoch 89/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1467 - binary_accuracy: 0.9247\n",
      "Epoch 90/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1414 - binary_accuracy: 0.9269\n",
      "Epoch 91/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1409 - binary_accuracy: 0.9296\n",
      "Epoch 92/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1385 - binary_accuracy: 0.9298\n",
      "Epoch 93/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1415 - binary_accuracy: 0.9309\n",
      "Epoch 94/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1429 - binary_accuracy: 0.9309\n",
      "Epoch 95/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1463 - binary_accuracy: 0.9267\n",
      "Epoch 96/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1400 - binary_accuracy: 0.9302\n",
      "Epoch 97/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1398 - binary_accuracy: 0.9347\n",
      "Epoch 98/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1429 - binary_accuracy: 0.9271\n",
      "Epoch 99/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1448 - binary_accuracy: 0.9296\n",
      "Epoch 100/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1417 - binary_accuracy: 0.9256\n",
      "Epoch 1/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.3983 - binary_accuracy: 0.9029\n",
      "Epoch 2/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.2362 - binary_accuracy: 0.9058\n",
      "Epoch 3/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.2093 - binary_accuracy: 0.9058\n",
      "Epoch 4/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1956 - binary_accuracy: 0.9058\n",
      "Epoch 5/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1898 - binary_accuracy: 0.9058\n",
      "Epoch 6/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1906 - binary_accuracy: 0.9058\n",
      "Epoch 7/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1826 - binary_accuracy: 0.9058\n",
      "Epoch 8/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1863 - binary_accuracy: 0.9058\n",
      "Epoch 9/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1830 - binary_accuracy: 0.9058\n",
      "Epoch 10/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1831 - binary_accuracy: 0.9058\n",
      "Epoch 11/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1804 - binary_accuracy: 0.9058\n",
      "Epoch 12/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1803 - binary_accuracy: 0.9058\n",
      "Epoch 13/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1756 - binary_accuracy: 0.9058\n",
      "Epoch 14/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1681 - binary_accuracy: 0.9058\n",
      "Epoch 15/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1606 - binary_accuracy: 0.9058\n",
      "Epoch 16/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1554 - binary_accuracy: 0.9058\n",
      "Epoch 17/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1525 - binary_accuracy: 0.9058\n",
      "Epoch 18/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1502 - binary_accuracy: 0.9058\n",
      "Epoch 19/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1432 - binary_accuracy: 0.9058\n",
      "Epoch 20/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1422 - binary_accuracy: 0.9320\n",
      "Epoch 21/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1379 - binary_accuracy: 0.9424\n",
      "Epoch 22/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1414 - binary_accuracy: 0.9358\n",
      "Epoch 23/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1313 - binary_accuracy: 0.9464\n",
      "Epoch 24/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1381 - binary_accuracy: 0.9393\n",
      "Epoch 25/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1298 - binary_accuracy: 0.9424\n",
      "Epoch 26/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1337 - binary_accuracy: 0.9433\n",
      "Epoch 27/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1367 - binary_accuracy: 0.9389\n",
      "Epoch 28/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1285 - binary_accuracy: 0.9522\n",
      "Epoch 29/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1341 - binary_accuracy: 0.9413\n",
      "Epoch 30/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1267 - binary_accuracy: 0.9473\n",
      "Epoch 31/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1298 - binary_accuracy: 0.9451\n",
      "Epoch 32/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1327 - binary_accuracy: 0.9449\n",
      "Epoch 33/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1333 - binary_accuracy: 0.9427\n",
      "Epoch 34/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1318 - binary_accuracy: 0.9473\n",
      "Epoch 35/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1332 - binary_accuracy: 0.9413\n",
      "Epoch 36/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1270 - binary_accuracy: 0.9453\n",
      "Epoch 37/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1296 - binary_accuracy: 0.9478\n",
      "Epoch 38/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1304 - binary_accuracy: 0.9407\n",
      "Epoch 39/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1270 - binary_accuracy: 0.9484\n",
      "Epoch 40/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1286 - binary_accuracy: 0.9420\n",
      "Epoch 41/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1289 - binary_accuracy: 0.9427\n",
      "Epoch 42/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1327 - binary_accuracy: 0.9427\n",
      "Epoch 43/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1339 - binary_accuracy: 0.9424\n",
      "Epoch 44/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1318 - binary_accuracy: 0.9416\n",
      "Epoch 45/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1375 - binary_accuracy: 0.9378\n",
      "Epoch 46/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1270 - binary_accuracy: 0.9467\n",
      "Epoch 47/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1269 - binary_accuracy: 0.9413\n",
      "Epoch 48/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1352 - binary_accuracy: 0.9407\n",
      "Epoch 49/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1307 - binary_accuracy: 0.9438\n",
      "Epoch 50/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1252 - binary_accuracy: 0.9476\n",
      "Epoch 51/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1295 - binary_accuracy: 0.9462\n",
      "Epoch 52/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1251 - binary_accuracy: 0.9447\n",
      "Epoch 53/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1325 - binary_accuracy: 0.9416\n",
      "Epoch 54/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1287 - binary_accuracy: 0.9467\n",
      "Epoch 55/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1257 - binary_accuracy: 0.9484\n",
      "Epoch 56/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1323 - binary_accuracy: 0.9424\n",
      "Epoch 57/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1254 - binary_accuracy: 0.9480\n",
      "Epoch 58/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1317 - binary_accuracy: 0.9438\n",
      "Epoch 59/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1233 - binary_accuracy: 0.9482\n",
      "Epoch 60/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1260 - binary_accuracy: 0.9482\n",
      "Epoch 61/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1283 - binary_accuracy: 0.9427\n",
      "Epoch 62/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1255 - binary_accuracy: 0.9482\n",
      "Epoch 63/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1241 - binary_accuracy: 0.9482\n",
      "Epoch 64/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1277 - binary_accuracy: 0.9440\n",
      "Epoch 65/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1340 - binary_accuracy: 0.9424\n",
      "Epoch 66/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1292 - binary_accuracy: 0.9418\n",
      "Epoch 67/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1312 - binary_accuracy: 0.9467\n",
      "Epoch 68/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1230 - binary_accuracy: 0.9456\n",
      "Epoch 69/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1253 - binary_accuracy: 0.9513\n",
      "Epoch 70/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1198 - binary_accuracy: 0.9471\n",
      "Epoch 71/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1279 - binary_accuracy: 0.9462\n",
      "Epoch 72/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1243 - binary_accuracy: 0.9467\n",
      "Epoch 73/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1284 - binary_accuracy: 0.9464\n",
      "Epoch 74/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1228 - binary_accuracy: 0.9440\n",
      "Epoch 75/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1250 - binary_accuracy: 0.9478\n",
      "Epoch 76/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1276 - binary_accuracy: 0.9444\n",
      "Epoch 77/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1262 - binary_accuracy: 0.9462\n",
      "Epoch 78/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1304 - binary_accuracy: 0.9460\n",
      "Epoch 79/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1195 - binary_accuracy: 0.9498\n",
      "Epoch 80/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1259 - binary_accuracy: 0.9493\n",
      "Epoch 81/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1295 - binary_accuracy: 0.9471\n",
      "Epoch 82/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1297 - binary_accuracy: 0.9422\n",
      "Epoch 83/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1227 - binary_accuracy: 0.9493\n",
      "Epoch 84/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1263 - binary_accuracy: 0.9456\n",
      "Epoch 85/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1262 - binary_accuracy: 0.9491\n",
      "Epoch 86/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1229 - binary_accuracy: 0.9482\n",
      "Epoch 87/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1261 - binary_accuracy: 0.9480\n",
      "Epoch 88/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1223 - binary_accuracy: 0.9467\n",
      "Epoch 89/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1257 - binary_accuracy: 0.9456\n",
      "Epoch 90/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1221 - binary_accuracy: 0.9473\n",
      "Epoch 91/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1241 - binary_accuracy: 0.9500\n",
      "Epoch 92/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1263 - binary_accuracy: 0.9469\n",
      "Epoch 93/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1187 - binary_accuracy: 0.9524\n",
      "Epoch 94/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1254 - binary_accuracy: 0.9436\n",
      "Epoch 95/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1234 - binary_accuracy: 0.9480\n",
      "Epoch 96/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1258 - binary_accuracy: 0.9451\n",
      "Epoch 97/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1205 - binary_accuracy: 0.9502\n",
      "Epoch 98/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1314 - binary_accuracy: 0.9420\n",
      "Epoch 99/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1204 - binary_accuracy: 0.9478\n",
      "Epoch 100/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1330 - binary_accuracy: 0.9431\n",
      "Epoch 1/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.3779 - binary_accuracy: 0.9031\n",
      "Epoch 2/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.2112 - binary_accuracy: 0.9051\n",
      "Epoch 3/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1962 - binary_accuracy: 0.9051\n",
      "Epoch 4/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1875 - binary_accuracy: 0.9051\n",
      "Epoch 5/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1789 - binary_accuracy: 0.9051\n",
      "Epoch 6/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1610 - binary_accuracy: 0.9051\n",
      "Epoch 7/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1504 - binary_accuracy: 0.9051\n",
      "Epoch 8/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1425 - binary_accuracy: 0.9078\n",
      "Epoch 9/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1398 - binary_accuracy: 0.9447\n",
      "Epoch 10/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1361 - binary_accuracy: 0.9471\n",
      "Epoch 11/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1319 - binary_accuracy: 0.9487\n",
      "Epoch 12/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1287 - binary_accuracy: 0.9547\n",
      "Epoch 13/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1286 - binary_accuracy: 0.9540\n",
      "Epoch 14/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1242 - binary_accuracy: 0.9524\n",
      "Epoch 15/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1207 - binary_accuracy: 0.9560\n",
      "Epoch 16/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1238 - binary_accuracy: 0.9516\n",
      "Epoch 17/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1187 - binary_accuracy: 0.9556\n",
      "Epoch 18/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1255 - binary_accuracy: 0.9571\n",
      "Epoch 19/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1193 - binary_accuracy: 0.9587\n",
      "Epoch 20/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1168 - binary_accuracy: 0.9536\n",
      "Epoch 21/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1191 - binary_accuracy: 0.9562\n",
      "Epoch 22/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1138 - binary_accuracy: 0.9580\n",
      "Epoch 23/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1245 - binary_accuracy: 0.9553\n",
      "Epoch 24/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1168 - binary_accuracy: 0.9591\n",
      "Epoch 25/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1147 - binary_accuracy: 0.9571\n",
      "Epoch 26/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1231 - binary_accuracy: 0.9533\n",
      "Epoch 27/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1194 - binary_accuracy: 0.9522\n",
      "Epoch 28/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1154 - binary_accuracy: 0.9573\n",
      "Epoch 29/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1139 - binary_accuracy: 0.9596\n",
      "Epoch 30/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1123 - binary_accuracy: 0.9642\n",
      "Epoch 31/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1057 - binary_accuracy: 0.9638\n",
      "Epoch 32/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1174 - binary_accuracy: 0.9596\n",
      "Epoch 33/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1108 - binary_accuracy: 0.9593\n",
      "Epoch 34/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1059 - binary_accuracy: 0.9604\n",
      "Epoch 35/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1072 - binary_accuracy: 0.9596\n",
      "Epoch 36/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1134 - binary_accuracy: 0.9578\n",
      "Epoch 37/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1091 - binary_accuracy: 0.9638\n",
      "Epoch 38/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1030 - binary_accuracy: 0.9620\n",
      "Epoch 39/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1091 - binary_accuracy: 0.9627\n",
      "Epoch 40/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1147 - binary_accuracy: 0.9584\n",
      "Epoch 41/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1126 - binary_accuracy: 0.9573\n",
      "Epoch 42/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1094 - binary_accuracy: 0.9609\n",
      "Epoch 43/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1070 - binary_accuracy: 0.9629\n",
      "Epoch 44/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1070 - binary_accuracy: 0.9644\n",
      "Epoch 45/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0993 - binary_accuracy: 0.9636\n",
      "Epoch 46/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1049 - binary_accuracy: 0.9629\n",
      "Epoch 47/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1098 - binary_accuracy: 0.9611\n",
      "Epoch 48/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1069 - binary_accuracy: 0.9589\n",
      "Epoch 49/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1002 - binary_accuracy: 0.9638\n",
      "Epoch 50/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0978 - binary_accuracy: 0.9700\n",
      "Epoch 51/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1001 - binary_accuracy: 0.9687\n",
      "Epoch 52/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1000 - binary_accuracy: 0.9658\n",
      "Epoch 53/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1011 - binary_accuracy: 0.9660\n",
      "Epoch 54/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1004 - binary_accuracy: 0.9669\n",
      "Epoch 55/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0987 - binary_accuracy: 0.9673\n",
      "Epoch 56/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0984 - binary_accuracy: 0.9682\n",
      "Epoch 57/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0915 - binary_accuracy: 0.9680\n",
      "Epoch 58/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0987 - binary_accuracy: 0.9671\n",
      "Epoch 59/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0970 - binary_accuracy: 0.9651\n",
      "Epoch 60/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1013 - binary_accuracy: 0.9660\n",
      "Epoch 61/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1045 - binary_accuracy: 0.9660\n",
      "Epoch 62/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1023 - binary_accuracy: 0.9649\n",
      "Epoch 63/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0962 - binary_accuracy: 0.9687\n",
      "Epoch 64/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0977 - binary_accuracy: 0.9651\n",
      "Epoch 65/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1034 - binary_accuracy: 0.9618\n",
      "Epoch 66/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0942 - binary_accuracy: 0.9662\n",
      "Epoch 67/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1035 - binary_accuracy: 0.9662\n",
      "Epoch 68/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1041 - binary_accuracy: 0.9640\n",
      "Epoch 69/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0985 - binary_accuracy: 0.9671\n",
      "Epoch 70/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1010 - binary_accuracy: 0.9669\n",
      "Epoch 71/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0997 - binary_accuracy: 0.9649\n",
      "Epoch 72/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0918 - binary_accuracy: 0.9676\n",
      "Epoch 73/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0965 - binary_accuracy: 0.9671\n",
      "Epoch 74/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0980 - binary_accuracy: 0.9664\n",
      "Epoch 75/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0960 - binary_accuracy: 0.9702\n",
      "Epoch 76/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0885 - binary_accuracy: 0.9722\n",
      "Epoch 77/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0876 - binary_accuracy: 0.9707\n",
      "Epoch 78/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0949 - binary_accuracy: 0.9700\n",
      "Epoch 79/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0961 - binary_accuracy: 0.9662\n",
      "Epoch 80/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0960 - binary_accuracy: 0.9656\n",
      "Epoch 81/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0922 - binary_accuracy: 0.9673\n",
      "Epoch 82/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0951 - binary_accuracy: 0.9678\n",
      "Epoch 83/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0961 - binary_accuracy: 0.9724\n",
      "Epoch 84/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0986 - binary_accuracy: 0.9696\n",
      "Epoch 85/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0917 - binary_accuracy: 0.9678\n",
      "Epoch 86/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0960 - binary_accuracy: 0.9700\n",
      "Epoch 87/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0905 - binary_accuracy: 0.9684\n",
      "Epoch 88/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0934 - binary_accuracy: 0.9713\n",
      "Epoch 89/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0958 - binary_accuracy: 0.9684\n",
      "Epoch 90/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0999 - binary_accuracy: 0.9687\n",
      "Epoch 91/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0936 - binary_accuracy: 0.9671\n",
      "Epoch 92/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0960 - binary_accuracy: 0.9696\n",
      "Epoch 93/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0907 - binary_accuracy: 0.9702\n",
      "Epoch 94/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0940 - binary_accuracy: 0.9682\n",
      "Epoch 95/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1015 - binary_accuracy: 0.9653\n",
      "Epoch 96/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0925 - binary_accuracy: 0.9700\n",
      "Epoch 97/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0978 - binary_accuracy: 0.9682\n",
      "Epoch 98/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0922 - binary_accuracy: 0.9727\n",
      "Epoch 99/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0972 - binary_accuracy: 0.9680\n",
      "Epoch 100/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0996 - binary_accuracy: 0.9709\n",
      "Epoch 1/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.3757 - binary_accuracy: 0.9022\n",
      "Epoch 2/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.2235 - binary_accuracy: 0.9033\n",
      "Epoch 3/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.2086 - binary_accuracy: 0.9033\n",
      "Epoch 4/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.2017 - binary_accuracy: 0.9033\n",
      "Epoch 5/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1948 - binary_accuracy: 0.9033\n",
      "Epoch 6/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1917 - binary_accuracy: 0.9033\n",
      "Epoch 7/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1886 - binary_accuracy: 0.9033\n",
      "Epoch 8/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1863 - binary_accuracy: 0.9033\n",
      "Epoch 9/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1810 - binary_accuracy: 0.9033\n",
      "Epoch 10/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1784 - binary_accuracy: 0.9033\n",
      "Epoch 11/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1665 - binary_accuracy: 0.9033\n",
      "Epoch 12/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1608 - binary_accuracy: 0.9033\n",
      "Epoch 13/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1536 - binary_accuracy: 0.9033\n",
      "Epoch 14/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1518 - binary_accuracy: 0.9033\n",
      "Epoch 15/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1444 - binary_accuracy: 0.9140\n",
      "Epoch 16/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1392 - binary_accuracy: 0.9422\n",
      "Epoch 17/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1417 - binary_accuracy: 0.9424\n",
      "Epoch 18/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1409 - binary_accuracy: 0.9453\n",
      "Epoch 19/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1401 - binary_accuracy: 0.9396\n",
      "Epoch 20/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1381 - binary_accuracy: 0.9467\n",
      "Epoch 21/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1380 - binary_accuracy: 0.9411\n",
      "Epoch 22/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1372 - binary_accuracy: 0.9449\n",
      "Epoch 23/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1333 - binary_accuracy: 0.9487\n",
      "Epoch 24/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1315 - binary_accuracy: 0.9449\n",
      "Epoch 25/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1324 - binary_accuracy: 0.9469\n",
      "Epoch 26/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1340 - binary_accuracy: 0.9453\n",
      "Epoch 27/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1330 - binary_accuracy: 0.9473\n",
      "Epoch 28/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1317 - binary_accuracy: 0.9487\n",
      "Epoch 29/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1356 - binary_accuracy: 0.9449\n",
      "Epoch 30/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1289 - binary_accuracy: 0.9444\n",
      "Epoch 31/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1287 - binary_accuracy: 0.9473\n",
      "Epoch 32/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1248 - binary_accuracy: 0.9476\n",
      "Epoch 33/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1338 - binary_accuracy: 0.9433\n",
      "Epoch 34/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1299 - binary_accuracy: 0.9467\n",
      "Epoch 35/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1271 - binary_accuracy: 0.9449\n",
      "Epoch 36/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1238 - binary_accuracy: 0.9476\n",
      "Epoch 37/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1305 - binary_accuracy: 0.9502\n",
      "Epoch 38/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1282 - binary_accuracy: 0.9484\n",
      "Epoch 39/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1307 - binary_accuracy: 0.9471\n",
      "Epoch 40/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1279 - binary_accuracy: 0.9482\n",
      "Epoch 41/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1258 - binary_accuracy: 0.9509\n",
      "Epoch 42/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1254 - binary_accuracy: 0.9496\n",
      "Epoch 43/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.1258 - binary_accuracy: 0.9460\n",
      "Epoch 44/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1282 - binary_accuracy: 0.9467\n",
      "Epoch 45/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1288 - binary_accuracy: 0.9467\n",
      "Epoch 46/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1311 - binary_accuracy: 0.9469\n",
      "Epoch 47/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1313 - binary_accuracy: 0.9480\n",
      "Epoch 48/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1225 - binary_accuracy: 0.9540\n",
      "Epoch 49/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1329 - binary_accuracy: 0.9464\n",
      "Epoch 50/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1296 - binary_accuracy: 0.9471\n",
      "Epoch 51/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1260 - binary_accuracy: 0.9489\n",
      "Epoch 52/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1256 - binary_accuracy: 0.9538\n",
      "Epoch 53/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1215 - binary_accuracy: 0.9549\n",
      "Epoch 54/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1227 - binary_accuracy: 0.9478\n",
      "Epoch 55/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1203 - binary_accuracy: 0.9569\n",
      "Epoch 56/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1204 - binary_accuracy: 0.9567\n",
      "Epoch 57/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1233 - binary_accuracy: 0.9567\n",
      "Epoch 58/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1224 - binary_accuracy: 0.9538\n",
      "Epoch 59/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1159 - binary_accuracy: 0.9600\n",
      "Epoch 60/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1210 - binary_accuracy: 0.9509\n",
      "Epoch 61/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1234 - binary_accuracy: 0.9558\n",
      "Epoch 62/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1164 - binary_accuracy: 0.9598\n",
      "Epoch 63/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1147 - binary_accuracy: 0.9584\n",
      "Epoch 64/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1186 - binary_accuracy: 0.9544\n",
      "Epoch 65/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1212 - binary_accuracy: 0.9544\n",
      "Epoch 66/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1172 - binary_accuracy: 0.9593\n",
      "Epoch 67/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1134 - binary_accuracy: 0.9616\n",
      "Epoch 68/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1157 - binary_accuracy: 0.9564\n",
      "Epoch 69/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1222 - binary_accuracy: 0.9531\n",
      "Epoch 70/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1153 - binary_accuracy: 0.9556\n",
      "Epoch 71/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1197 - binary_accuracy: 0.9569\n",
      "Epoch 72/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1181 - binary_accuracy: 0.9564\n",
      "Epoch 73/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1208 - binary_accuracy: 0.9524\n",
      "Epoch 74/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1103 - binary_accuracy: 0.9620\n",
      "Epoch 75/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1156 - binary_accuracy: 0.9587\n",
      "Epoch 76/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1143 - binary_accuracy: 0.9587\n",
      "Epoch 77/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1107 - binary_accuracy: 0.9576\n",
      "Epoch 78/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1214 - binary_accuracy: 0.9562\n",
      "Epoch 79/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1143 - binary_accuracy: 0.9611\n",
      "Epoch 80/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1156 - binary_accuracy: 0.9629\n",
      "Epoch 81/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1234 - binary_accuracy: 0.9558\n",
      "Epoch 82/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1146 - binary_accuracy: 0.9633\n",
      "Epoch 83/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1164 - binary_accuracy: 0.9596\n",
      "Epoch 84/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1137 - binary_accuracy: 0.9618\n",
      "Epoch 85/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1156 - binary_accuracy: 0.9600\n",
      "Epoch 86/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1147 - binary_accuracy: 0.9578\n",
      "Epoch 87/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1221 - binary_accuracy: 0.9576\n",
      "Epoch 88/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1194 - binary_accuracy: 0.9553\n",
      "Epoch 89/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1217 - binary_accuracy: 0.9582\n",
      "Epoch 90/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1129 - binary_accuracy: 0.9616\n",
      "Epoch 91/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1111 - binary_accuracy: 0.9616\n",
      "Epoch 92/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1150 - binary_accuracy: 0.9571\n",
      "Epoch 93/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1137 - binary_accuracy: 0.9629\n",
      "Epoch 94/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1174 - binary_accuracy: 0.9551\n",
      "Epoch 95/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1124 - binary_accuracy: 0.9638\n",
      "Epoch 96/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1181 - binary_accuracy: 0.9567\n",
      "Epoch 97/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1130 - binary_accuracy: 0.9589\n",
      "Epoch 98/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1125 - binary_accuracy: 0.9587\n",
      "Epoch 99/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1116 - binary_accuracy: 0.9627\n",
      "Epoch 100/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1209 - binary_accuracy: 0.9591\n",
      "Epoch 1/100\n",
      "450/450 [==============================] - 0s 1ms/step - loss: 0.3596 - binary_accuracy: 0.9020\n",
      "Epoch 2/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.2218 - binary_accuracy: 0.9029\n",
      "Epoch 3/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.2042 - binary_accuracy: 0.9029\n",
      "Epoch 4/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1935 - binary_accuracy: 0.9029\n",
      "Epoch 5/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1922 - binary_accuracy: 0.9029\n",
      "Epoch 6/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1935 - binary_accuracy: 0.9029\n",
      "Epoch 7/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1864 - binary_accuracy: 0.9029\n",
      "Epoch 8/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1793 - binary_accuracy: 0.9029\n",
      "Epoch 9/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1702 - binary_accuracy: 0.9029\n",
      "Epoch 10/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1669 - binary_accuracy: 0.9029\n",
      "Epoch 11/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1577 - binary_accuracy: 0.9029\n",
      "Epoch 12/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1551 - binary_accuracy: 0.9029\n",
      "Epoch 13/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1515 - binary_accuracy: 0.9029\n",
      "Epoch 14/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1493 - binary_accuracy: 0.9278\n",
      "Epoch 15/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1428 - binary_accuracy: 0.9422\n",
      "Epoch 16/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1440 - binary_accuracy: 0.9420\n",
      "Epoch 17/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1389 - binary_accuracy: 0.9453\n",
      "Epoch 18/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1405 - binary_accuracy: 0.9442\n",
      "Epoch 19/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1318 - binary_accuracy: 0.9484\n",
      "Epoch 20/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1336 - binary_accuracy: 0.9522\n",
      "Epoch 21/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1306 - binary_accuracy: 0.9489\n",
      "Epoch 22/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1315 - binary_accuracy: 0.9469\n",
      "Epoch 23/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1369 - binary_accuracy: 0.9440\n",
      "Epoch 24/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1312 - binary_accuracy: 0.9496\n",
      "Epoch 25/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1234 - binary_accuracy: 0.9542\n",
      "Epoch 26/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1293 - binary_accuracy: 0.9491\n",
      "Epoch 27/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1243 - binary_accuracy: 0.9524\n",
      "Epoch 28/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1291 - binary_accuracy: 0.9489\n",
      "Epoch 29/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1254 - binary_accuracy: 0.9542\n",
      "Epoch 30/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1221 - binary_accuracy: 0.9531\n",
      "Epoch 31/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1246 - binary_accuracy: 0.9518\n",
      "Epoch 32/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1262 - binary_accuracy: 0.9524\n",
      "Epoch 33/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1208 - binary_accuracy: 0.9520\n",
      "Epoch 34/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1254 - binary_accuracy: 0.9542\n",
      "Epoch 35/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1239 - binary_accuracy: 0.9540\n",
      "Epoch 36/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1227 - binary_accuracy: 0.9553\n",
      "Epoch 37/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1185 - binary_accuracy: 0.9576\n",
      "Epoch 38/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1208 - binary_accuracy: 0.9584\n",
      "Epoch 39/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1178 - binary_accuracy: 0.9591\n",
      "Epoch 40/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1185 - binary_accuracy: 0.9591\n",
      "Epoch 41/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1218 - binary_accuracy: 0.9620\n",
      "Epoch 42/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1137 - binary_accuracy: 0.9596\n",
      "Epoch 43/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1170 - binary_accuracy: 0.9600\n",
      "Epoch 44/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1119 - binary_accuracy: 0.9631\n",
      "Epoch 45/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1168 - binary_accuracy: 0.9587\n",
      "Epoch 46/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1124 - binary_accuracy: 0.9624\n",
      "Epoch 47/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1131 - binary_accuracy: 0.9598\n",
      "Epoch 48/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1135 - binary_accuracy: 0.9622\n",
      "Epoch 49/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1174 - binary_accuracy: 0.9609\n",
      "Epoch 50/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1111 - binary_accuracy: 0.9640\n",
      "Epoch 51/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1140 - binary_accuracy: 0.9633\n",
      "Epoch 52/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1163 - binary_accuracy: 0.9642\n",
      "Epoch 53/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1113 - binary_accuracy: 0.9644\n",
      "Epoch 54/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1150 - binary_accuracy: 0.9616\n",
      "Epoch 55/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1110 - binary_accuracy: 0.9622\n",
      "Epoch 56/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1091 - binary_accuracy: 0.9622\n",
      "Epoch 57/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1132 - binary_accuracy: 0.9638\n",
      "Epoch 58/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1058 - binary_accuracy: 0.9638\n",
      "Epoch 59/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1186 - binary_accuracy: 0.9607\n",
      "Epoch 60/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1119 - binary_accuracy: 0.9656\n",
      "Epoch 61/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1075 - binary_accuracy: 0.9667\n",
      "Epoch 62/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1062 - binary_accuracy: 0.9676\n",
      "Epoch 63/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1078 - binary_accuracy: 0.9664\n",
      "Epoch 64/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1120 - binary_accuracy: 0.9616\n",
      "Epoch 65/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1121 - binary_accuracy: 0.9620\n",
      "Epoch 66/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1141 - binary_accuracy: 0.9651\n",
      "Epoch 67/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1148 - binary_accuracy: 0.9624\n",
      "Epoch 68/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1140 - binary_accuracy: 0.9629\n",
      "Epoch 69/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1074 - binary_accuracy: 0.9658\n",
      "Epoch 70/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1070 - binary_accuracy: 0.9613\n",
      "Epoch 71/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1094 - binary_accuracy: 0.9636\n",
      "Epoch 72/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1112 - binary_accuracy: 0.9638\n",
      "Epoch 73/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1074 - binary_accuracy: 0.9658\n",
      "Epoch 74/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1198 - binary_accuracy: 0.9582\n",
      "Epoch 75/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1074 - binary_accuracy: 0.9627\n",
      "Epoch 76/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1055 - binary_accuracy: 0.9658\n",
      "Epoch 77/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1055 - binary_accuracy: 0.9656\n",
      "Epoch 78/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1144 - binary_accuracy: 0.9618\n",
      "Epoch 79/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1073 - binary_accuracy: 0.9636\n",
      "Epoch 80/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1082 - binary_accuracy: 0.9664\n",
      "Epoch 81/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1227 - binary_accuracy: 0.9584\n",
      "Epoch 82/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1127 - binary_accuracy: 0.9638\n",
      "Epoch 83/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1062 - binary_accuracy: 0.9642\n",
      "Epoch 84/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1145 - binary_accuracy: 0.9631\n",
      "Epoch 85/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1061 - binary_accuracy: 0.9656\n",
      "Epoch 86/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1111 - binary_accuracy: 0.9616\n",
      "Epoch 87/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1103 - binary_accuracy: 0.9656\n",
      "Epoch 88/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1094 - binary_accuracy: 0.9633\n",
      "Epoch 89/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1170 - binary_accuracy: 0.9622\n",
      "Epoch 90/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1064 - binary_accuracy: 0.9644\n",
      "Epoch 91/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1156 - binary_accuracy: 0.9616\n",
      "Epoch 92/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1052 - binary_accuracy: 0.9622\n",
      "Epoch 93/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1105 - binary_accuracy: 0.9671\n",
      "Epoch 94/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1095 - binary_accuracy: 0.9633\n",
      "Epoch 95/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1043 - binary_accuracy: 0.9658\n",
      "Epoch 96/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1110 - binary_accuracy: 0.9629\n",
      "Epoch 97/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1144 - binary_accuracy: 0.9629\n",
      "Epoch 98/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1110 - binary_accuracy: 0.9620\n",
      "Epoch 99/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1063 - binary_accuracy: 0.9653\n",
      "Epoch 100/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1033 - binary_accuracy: 0.9669\n",
      "Epoch 1/100\n",
      "  1/450 [..............................] - ETA: 0s - loss: 0.6908 - binary_accuracy: 0.9000WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0034s vs `on_train_batch_end` time: 0.0070s). Check your callbacks.\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.3323 - binary_accuracy: 0.9042\n",
      "Epoch 2/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.2081 - binary_accuracy: 0.9042\n",
      "Epoch 3/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1846 - binary_accuracy: 0.9042\n",
      "Epoch 4/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1714 - binary_accuracy: 0.9042\n",
      "Epoch 5/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1565 - binary_accuracy: 0.9042\n",
      "Epoch 6/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1514 - binary_accuracy: 0.9073\n",
      "Epoch 7/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1470 - binary_accuracy: 0.9396\n",
      "Epoch 8/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1408 - binary_accuracy: 0.9464\n",
      "Epoch 9/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1354 - binary_accuracy: 0.9491\n",
      "Epoch 10/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1343 - binary_accuracy: 0.9493\n",
      "Epoch 11/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1258 - binary_accuracy: 0.9522\n",
      "Epoch 12/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1297 - binary_accuracy: 0.9522\n",
      "Epoch 13/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1240 - binary_accuracy: 0.9602\n",
      "Epoch 14/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1262 - binary_accuracy: 0.9489\n",
      "Epoch 15/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1303 - binary_accuracy: 0.9502\n",
      "Epoch 16/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1239 - binary_accuracy: 0.9504\n",
      "Epoch 17/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1252 - binary_accuracy: 0.9529\n",
      "Epoch 18/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1195 - binary_accuracy: 0.9569\n",
      "Epoch 19/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1268 - binary_accuracy: 0.9498\n",
      "Epoch 20/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1265 - binary_accuracy: 0.9531\n",
      "Epoch 21/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1171 - binary_accuracy: 0.9562\n",
      "Epoch 22/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1228 - binary_accuracy: 0.9542\n",
      "Epoch 23/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1213 - binary_accuracy: 0.9531\n",
      "Epoch 24/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1184 - binary_accuracy: 0.9567\n",
      "Epoch 25/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1228 - binary_accuracy: 0.9489\n",
      "Epoch 26/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1186 - binary_accuracy: 0.9562\n",
      "Epoch 27/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1142 - binary_accuracy: 0.9582\n",
      "Epoch 28/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1191 - binary_accuracy: 0.9533\n",
      "Epoch 29/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1165 - binary_accuracy: 0.9580\n",
      "Epoch 30/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1166 - binary_accuracy: 0.9580\n",
      "Epoch 31/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1090 - binary_accuracy: 0.9618\n",
      "Epoch 32/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1102 - binary_accuracy: 0.9616\n",
      "Epoch 33/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1086 - binary_accuracy: 0.9631\n",
      "Epoch 34/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1148 - binary_accuracy: 0.9624\n",
      "Epoch 35/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1148 - binary_accuracy: 0.9629\n",
      "Epoch 36/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1126 - binary_accuracy: 0.9627\n",
      "Epoch 37/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1061 - binary_accuracy: 0.9653\n",
      "Epoch 38/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1059 - binary_accuracy: 0.9644\n",
      "Epoch 39/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1071 - binary_accuracy: 0.9620\n",
      "Epoch 40/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1085 - binary_accuracy: 0.9633\n",
      "Epoch 41/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1116 - binary_accuracy: 0.9636\n",
      "Epoch 42/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1115 - binary_accuracy: 0.9644\n",
      "Epoch 43/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1165 - binary_accuracy: 0.9604\n",
      "Epoch 44/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1123 - binary_accuracy: 0.9627\n",
      "Epoch 45/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1080 - binary_accuracy: 0.9624\n",
      "Epoch 46/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1147 - binary_accuracy: 0.9600\n",
      "Epoch 47/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1140 - binary_accuracy: 0.9611\n",
      "Epoch 48/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1009 - binary_accuracy: 0.9656\n",
      "Epoch 49/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1080 - binary_accuracy: 0.9620\n",
      "Epoch 50/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1111 - binary_accuracy: 0.9642\n",
      "Epoch 51/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1127 - binary_accuracy: 0.9609\n",
      "Epoch 52/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1048 - binary_accuracy: 0.9669\n",
      "Epoch 53/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1075 - binary_accuracy: 0.9636\n",
      "Epoch 54/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1074 - binary_accuracy: 0.9656\n",
      "Epoch 55/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1079 - binary_accuracy: 0.9664\n",
      "Epoch 56/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1088 - binary_accuracy: 0.9633\n",
      "Epoch 57/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1051 - binary_accuracy: 0.9682\n",
      "Epoch 58/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1073 - binary_accuracy: 0.9660\n",
      "Epoch 59/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1096 - binary_accuracy: 0.9618\n",
      "Epoch 60/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1049 - binary_accuracy: 0.9702\n",
      "Epoch 61/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1122 - binary_accuracy: 0.9644\n",
      "Epoch 62/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1030 - binary_accuracy: 0.9660\n",
      "Epoch 63/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1036 - binary_accuracy: 0.9651\n",
      "Epoch 64/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1053 - binary_accuracy: 0.9662\n",
      "Epoch 65/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1038 - binary_accuracy: 0.9656\n",
      "Epoch 66/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1101 - binary_accuracy: 0.9642\n",
      "Epoch 67/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1008 - binary_accuracy: 0.9678\n",
      "Epoch 68/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1027 - binary_accuracy: 0.9673\n",
      "Epoch 69/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1062 - binary_accuracy: 0.9642\n",
      "Epoch 70/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1075 - binary_accuracy: 0.9647\n",
      "Epoch 71/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1029 - binary_accuracy: 0.9682\n",
      "Epoch 72/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1121 - binary_accuracy: 0.9644\n",
      "Epoch 73/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1009 - binary_accuracy: 0.9667\n",
      "Epoch 74/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1117 - binary_accuracy: 0.9653\n",
      "Epoch 75/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1047 - binary_accuracy: 0.9638\n",
      "Epoch 76/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1062 - binary_accuracy: 0.9673\n",
      "Epoch 77/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1041 - binary_accuracy: 0.9629\n",
      "Epoch 78/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1042 - binary_accuracy: 0.9680\n",
      "Epoch 79/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1075 - binary_accuracy: 0.9658\n",
      "Epoch 80/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1013 - binary_accuracy: 0.9702\n",
      "Epoch 81/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1110 - binary_accuracy: 0.9618\n",
      "Epoch 82/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1078 - binary_accuracy: 0.9658\n",
      "Epoch 83/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0951 - binary_accuracy: 0.9689\n",
      "Epoch 84/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1115 - binary_accuracy: 0.9656\n",
      "Epoch 85/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1069 - binary_accuracy: 0.9658\n",
      "Epoch 86/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1089 - binary_accuracy: 0.9647\n",
      "Epoch 87/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1098 - binary_accuracy: 0.9629\n",
      "Epoch 88/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1033 - binary_accuracy: 0.9656\n",
      "Epoch 89/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1019 - binary_accuracy: 0.9680\n",
      "Epoch 90/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1127 - binary_accuracy: 0.9653\n",
      "Epoch 91/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1059 - binary_accuracy: 0.9673\n",
      "Epoch 92/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1018 - binary_accuracy: 0.9691\n",
      "Epoch 93/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1056 - binary_accuracy: 0.9673\n",
      "Epoch 94/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1026 - binary_accuracy: 0.9667\n",
      "Epoch 95/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0982 - binary_accuracy: 0.9698\n",
      "Epoch 96/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1077 - binary_accuracy: 0.9647\n",
      "Epoch 97/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1097 - binary_accuracy: 0.9616\n",
      "Epoch 98/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1045 - binary_accuracy: 0.9676\n",
      "Epoch 99/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1119 - binary_accuracy: 0.9636\n",
      "Epoch 100/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.0945 - binary_accuracy: 0.9713\n",
      "Epoch 1/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.3745 - binary_accuracy: 0.9002\n",
      "Epoch 2/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.2322 - binary_accuracy: 0.9009\n",
      "Epoch 3/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.2120 - binary_accuracy: 0.9009\n",
      "Epoch 4/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.2025 - binary_accuracy: 0.9009\n",
      "Epoch 5/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1988 - binary_accuracy: 0.9009\n",
      "Epoch 6/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1942 - binary_accuracy: 0.9009\n",
      "Epoch 7/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1901 - binary_accuracy: 0.9009\n",
      "Epoch 8/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1872 - binary_accuracy: 0.9009\n",
      "Epoch 9/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1860 - binary_accuracy: 0.9009\n",
      "Epoch 10/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1919 - binary_accuracy: 0.9009\n",
      "Epoch 11/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1892 - binary_accuracy: 0.9009\n",
      "Epoch 12/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1854 - binary_accuracy: 0.9009\n",
      "Epoch 13/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1841 - binary_accuracy: 0.9009\n",
      "Epoch 14/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1833 - binary_accuracy: 0.9009\n",
      "Epoch 15/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1802 - binary_accuracy: 0.9009\n",
      "Epoch 16/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1711 - binary_accuracy: 0.9009\n",
      "Epoch 17/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1627 - binary_accuracy: 0.9009\n",
      "Epoch 18/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1529 - binary_accuracy: 0.9009\n",
      "Epoch 19/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1540 - binary_accuracy: 0.9009\n",
      "Epoch 20/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1456 - binary_accuracy: 0.9260\n",
      "Epoch 21/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1425 - binary_accuracy: 0.9411\n",
      "Epoch 22/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1404 - binary_accuracy: 0.9473\n",
      "Epoch 23/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1358 - binary_accuracy: 0.9496\n",
      "Epoch 24/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1338 - binary_accuracy: 0.9511\n",
      "Epoch 25/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1340 - binary_accuracy: 0.9496\n",
      "Epoch 26/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1309 - binary_accuracy: 0.9533\n",
      "Epoch 27/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1383 - binary_accuracy: 0.9436\n",
      "Epoch 28/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1318 - binary_accuracy: 0.9480\n",
      "Epoch 29/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1314 - binary_accuracy: 0.9500\n",
      "Epoch 30/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1332 - binary_accuracy: 0.9471\n",
      "Epoch 31/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1252 - binary_accuracy: 0.9536\n",
      "Epoch 32/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1281 - binary_accuracy: 0.9500\n",
      "Epoch 33/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1290 - binary_accuracy: 0.9516\n",
      "Epoch 34/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1275 - binary_accuracy: 0.9542\n",
      "Epoch 35/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1271 - binary_accuracy: 0.9498\n",
      "Epoch 36/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1280 - binary_accuracy: 0.9513\n",
      "Epoch 37/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1281 - binary_accuracy: 0.9538\n",
      "Epoch 38/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1304 - binary_accuracy: 0.9469\n",
      "Epoch 39/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1306 - binary_accuracy: 0.9476\n",
      "Epoch 40/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1242 - binary_accuracy: 0.9531\n",
      "Epoch 41/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1259 - binary_accuracy: 0.9518\n",
      "Epoch 42/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1205 - binary_accuracy: 0.9560\n",
      "Epoch 43/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1213 - binary_accuracy: 0.9531\n",
      "Epoch 44/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1237 - binary_accuracy: 0.9536\n",
      "Epoch 45/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1247 - binary_accuracy: 0.9518\n",
      "Epoch 46/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1226 - binary_accuracy: 0.9573\n",
      "Epoch 47/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1179 - binary_accuracy: 0.9564\n",
      "Epoch 48/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1236 - binary_accuracy: 0.9540\n",
      "Epoch 49/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1194 - binary_accuracy: 0.9567\n",
      "Epoch 50/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1246 - binary_accuracy: 0.9533\n",
      "Epoch 51/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1181 - binary_accuracy: 0.9582\n",
      "Epoch 52/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1176 - binary_accuracy: 0.9576\n",
      "Epoch 53/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1192 - binary_accuracy: 0.9540\n",
      "Epoch 54/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1159 - binary_accuracy: 0.9589\n",
      "Epoch 55/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1228 - binary_accuracy: 0.9511\n",
      "Epoch 56/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1154 - binary_accuracy: 0.9609\n",
      "Epoch 57/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1212 - binary_accuracy: 0.9580\n",
      "Epoch 58/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1196 - binary_accuracy: 0.9564\n",
      "Epoch 59/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1111 - binary_accuracy: 0.9604\n",
      "Epoch 60/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1124 - binary_accuracy: 0.9576\n",
      "Epoch 61/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1128 - binary_accuracy: 0.9627\n",
      "Epoch 62/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1254 - binary_accuracy: 0.9536\n",
      "Epoch 63/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1106 - binary_accuracy: 0.9589\n",
      "Epoch 64/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1125 - binary_accuracy: 0.9591\n",
      "Epoch 65/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1188 - binary_accuracy: 0.9591\n",
      "Epoch 66/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1199 - binary_accuracy: 0.9591\n",
      "Epoch 67/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1122 - binary_accuracy: 0.9611\n",
      "Epoch 68/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1109 - binary_accuracy: 0.9607\n",
      "Epoch 69/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1172 - binary_accuracy: 0.9598\n",
      "Epoch 70/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1155 - binary_accuracy: 0.9580\n",
      "Epoch 71/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1088 - binary_accuracy: 0.9631\n",
      "Epoch 72/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1175 - binary_accuracy: 0.9616\n",
      "Epoch 73/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1111 - binary_accuracy: 0.9602\n",
      "Epoch 74/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1151 - binary_accuracy: 0.9604\n",
      "Epoch 75/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1163 - binary_accuracy: 0.9627\n",
      "Epoch 76/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1118 - binary_accuracy: 0.9607\n",
      "Epoch 77/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1169 - binary_accuracy: 0.9591\n",
      "Epoch 78/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1157 - binary_accuracy: 0.9584\n",
      "Epoch 79/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1173 - binary_accuracy: 0.9602\n",
      "Epoch 80/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1178 - binary_accuracy: 0.9576\n",
      "Epoch 81/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1190 - binary_accuracy: 0.9584\n",
      "Epoch 82/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1161 - binary_accuracy: 0.9576\n",
      "Epoch 83/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1199 - binary_accuracy: 0.9558\n",
      "Epoch 84/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1122 - binary_accuracy: 0.9598\n",
      "Epoch 85/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1194 - binary_accuracy: 0.9607\n",
      "Epoch 86/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1193 - binary_accuracy: 0.9573\n",
      "Epoch 87/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1153 - binary_accuracy: 0.9582\n",
      "Epoch 88/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1239 - binary_accuracy: 0.9598\n",
      "Epoch 89/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1205 - binary_accuracy: 0.9569\n",
      "Epoch 90/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1083 - binary_accuracy: 0.9616\n",
      "Epoch 91/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1132 - binary_accuracy: 0.9598\n",
      "Epoch 92/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1146 - binary_accuracy: 0.9582\n",
      "Epoch 93/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1194 - binary_accuracy: 0.9600\n",
      "Epoch 94/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1138 - binary_accuracy: 0.9616\n",
      "Epoch 95/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1127 - binary_accuracy: 0.9624\n",
      "Epoch 96/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1203 - binary_accuracy: 0.9576\n",
      "Epoch 97/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1197 - binary_accuracy: 0.9558\n",
      "Epoch 98/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1156 - binary_accuracy: 0.9600\n",
      "Epoch 99/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1190 - binary_accuracy: 0.9584\n",
      "Epoch 100/100\n",
      "450/450 [==============================] - 1s 1ms/step - loss: 0.1173 - binary_accuracy: 0.9558\n"
     ]
    }
   ],
   "source": [
    "modelo2_cv = KerasClassifier(build_fn=RedeNeural2, epochs=100, batch_size=10)\n",
    "resultados2 = cross_val_score(estimator = modelo2_cv, X = X2, y=y, cv=10, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N5e7PGSs-CWN"
   },
   "source": [
    "Na validação cruzada dessa nova rede neural a acurácia média ficou ligeiramente maior que a original e o desvio padrão foi maior dentre os modelos até agora."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104
    },
    "id": "D7JyQvC17OD1",
    "outputId": "d53e1bac-f1a3-4fe1-82ad-5680f204e935"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados da validação cruzada : [0.97  0.982 0.972 0.97  0.966 0.972 0.97  0.982 0.986 0.98 ]\n",
      "\n",
      "Média dos resultados da validação cruzada : 0.975\n",
      "\n",
      "Desvio padrão dos resultados da validação cruzada : 0.006465291950097852\n"
     ]
    }
   ],
   "source": [
    "print('Resultados da validação cruzada :',resultados2)\n",
    "print('')\n",
    "print('Média dos resultados da validação cruzada :',resultados2.mean())\n",
    "print('')\n",
    "print('Desvio padrão dos resultados da validação cruzada :',resultados2.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l7yZYtVroDoa"
   },
   "source": [
    "## Comparação entre os resultados\n",
    "\n",
    "Abaixo podemos ver uma tabela comparando o desempenho do nosso modelo inicial com os testes que realizamos (colocamos na tabela as métricas que dizem respeito a classe 1, pois queremos identificar os clientes que podem ser potenciais contratantes do empréstimo pessoal).\n",
    "\n",
    "|                                 ||   Acurácia     ||   Precisão (classe 1)  ||   *Recall* (classe 1)  ||   *F1-score* (Classe 1)  ||  Acurácia média CV  ||  Acurácia std CV  ||\n",
    "|:-------------------------------:||:-----------:||:------------:||:----------------------:||:------------:||:------------:||:------------:||\n",
    "|Modelo 1               || 98.1%|| 96%|| 86%  ||90% || **97.58%** || 0.00931 ||\n",
    "|Modelo 2 (com mais uma camada oculta)  || **98.6%**|| 94% || **92%** || **93%** || 97.4% || 0.02155 ||\n",
    "|Modelo 3 (Com *Dropout*) || 98.3% || **98%** || 86% || 91% || 97.5% || **0.00646** ||\n",
    "\n",
    "Não é possível dizer qual o melhor modelo, pois em cada resultado houve um métrica melhor do que a outra. Se levarmos em consideração o número de métricas o *modelo 2* seria o melhor, mas se levarmos em consideração o desempeho geral veremo que o modelo 1 foi melhor e, por fim, se levarmos em consideração evidência sobre a existência de *overfitting* no modelo, então o *modelo 3* será o melhor. Essa escolha do melhor modelo deverá ficar à cabo da equipe responsável pelo projeto e caso seja necessário realizar outros testes com outras combinações de redes neurais.\n",
    "\n",
    "## Conclusão\n",
    "\n",
    "Diferente de outros projetos feitos por mim, em que tive que rebalancear as classes, onde, geralmente, era necessário que eu utilizasse um algoritmo chamado *SMOTE* para gerar amostras sintética no meu *dataframe*; esse procedimento era bastante arriscado, pois o algoritmo poderia ficar sobreajustado aos dados. Com o uso de Redes Neurais consegui um desempenho bastante elevado para a nossa classe alvo, que foram aqueles que tomaram o empréstimo pessoal junto ao banco, sem precisar do artifício de rebalanceamento de classe e ainda vimos que o desvio padrão da acurácia com *cross validation* foi bem pequeno, o que exclui a possibilidade de *overfitting* do modelo.\n",
    "\n",
    "Nesse trabalho faltou aplicarmos o *GridSearch*, onde, de forma exaustiva, usarei uma combinação de parâmetros para a rede neural, mas iremos aplicar esse procedimento em outro *notebook* para que esse projeto não fique muito extenso."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Redes neurais aplicadas para problemas de classificação binária.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
